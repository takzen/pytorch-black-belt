{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n<a href=\"https://colab.research.google.com/github/takzen/pytorch-black-belt/blob/main/01_Storage_vs_View.ipynb\" target=\"_parent\">\n    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# \u2601\ufe0f COLAB SETUP (Automatyczna instalacja \u015brodowiska)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Sprawdzamy, czy jeste\u015bmy w Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('\u2601\ufe0f Wykryto \u015brodowisko Google Colab. Konfiguruj\u0119...')\n",
    "\n",
    "    # 1. Pobieramy plik requirements.txt bezpo\u015brednio z repozytorium\n",
    "    !wget -q https://raw.githubusercontent.com/takzen/ai-engineering-handbook/main/requirements.txt -O requirements.txt\n",
    "\n",
    "    # 2. Instalujemy biblioteki\n",
    "    print('\u23f3 Instaluj\u0119 zale\u017cno\u015bci (to mo\u017ce chwil\u0119 potrwa\u0107)...')\n",
    "    !pip install -q -r requirements.txt\n",
    "\n",
    "    print('\u2705 Gotowe! \u015arodowisko jest zgodne z repozytorium.')\n",
    "else:\n",
    "    print('\ud83d\udcbb Wykryto \u015brodowisko lokalne. Zak\u0142adam, \u017ce masz ju\u017c uv/venv.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d64c10",
   "metadata": {},
   "source": [
    "# \ud83e\udd4b Lekcja 1: Storage vs Tensor (Prawda o Pami\u0119ci)\n",
    "\n",
    "W PyTorch **Tensor to tylko iluzja**. To nak\u0142adka (interfejs) na prawdziwe dane.\n",
    "Prawdziwe dane \u017cyj\u0105 w obiekcie zwanym **Storage**.\n",
    "\n",
    "*   **Storage:** Ci\u0105g\u0142y, jednowymiarowy blok bajt\u00f3w w pami\u0119ci (np. `[1, 2, 3, 4, 5, 6]`).\n",
    "*   **Tensor:** Zestaw metadanych (Kszta\u0142t, Stride, Offset), kt\u00f3ry m\u00f3wi, jak \"czyta\u0107\" ten blok.\n",
    "\n",
    "**Dlaczego to kluczowe?**\n",
    "Operacje takie jak `transpose`, `permute`, `narrow` czy `expand` **nie ruszaj\u0105 danych w pami\u0119ci**. Zmieniaj\u0105 tylko metadane. S\u0105 b\u0142yskawiczne ($O(1)$).\n",
    "Ale maj\u0105 swoj\u0105 cen\u0119: trac\u0105 **ci\u0105g\u0142o\u015b\u0107 (contiguity)**, co powoduje b\u0142\u0119dy przy pr\u00f3bie u\u017cycia `.view()`.\n",
    "\n",
    "W tej lekcji zhakujemy pami\u0119\u0107 PyTorcha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9723106d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TENSOR ---\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Kszta\u0142t: torch.Size([2, 3])\n",
      "Adres danych (data_ptr): 5829008883840\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ctypes\n",
    "\n",
    "# Funkcja pomocnicza do podgl\u0105dania adresu pami\u0119ci\n",
    "def print_memory_address(tensor):\n",
    "    print(f\"Adres danych (data_ptr): {tensor.data_ptr()}\")\n",
    "\n",
    "# 1. TWORZYMY TENSOR\n",
    "t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(\"--- TENSOR ---\")\n",
    "print(t)\n",
    "print(f\"Kszta\u0142t: {t.shape}\")\n",
    "print_memory_address(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdd3b6f",
   "metadata": {},
   "source": [
    "## Storage: To, co jest pod mask\u0105\n",
    "\n",
    "Zobaczmy, jak te dane wygl\u0105daj\u0105 naprawd\u0119.\n",
    "Mimo \u017ce tensor jest 2D (wiersze i kolumny), w pami\u0119ci komputera jest to **p\u0142aska lista**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a945687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STORAGE (Surowe dane) ---\n",
      "Rozmiar storage: 48 bajt\u00f3w (6 liczb int64 * 8 bajt\u00f3w = 48)\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "--- HACKOWANIE PAMI\u0118CI ---\n",
      "Tensor po zmianie storage'a:\n",
      "tensor([[99,  2,  3],\n",
      "        [ 4,  5,  6]])\n",
      "Widzisz? Zmieni\u0142a si\u0119 liczba w tensorze, cho\u0107 go nie dotykali\u015bmy.\n"
     ]
    }
   ],
   "source": [
    "# Dost\u0119p do surowego magazynu danych\n",
    "storage = t.untyped_storage()\n",
    "\n",
    "print(\"--- STORAGE (Surowe dane) ---\")\n",
    "print(f\"Rozmiar storage: {len(storage)} bajt\u00f3w (6 liczb int64 * 8 bajt\u00f3w = 48)\")\n",
    "# Podgl\u0105d zawarto\u015bci (jako lista)\n",
    "print(storage.tolist())\n",
    "\n",
    "# DOW\u00d3D: Zmiana w Storage zmienia Tensor!\n",
    "print(\"\\n--- HACKOWANIE PAMI\u0118CI ---\")\n",
    "# Zmieniamy pierwszy element w storage (fizycznej pami\u0119ci)\n",
    "# Uwaga: Storage jest p\u0142aski, wi\u0119c indeksujemy liniowo\n",
    "t.untyped_storage()[0] = 99 \n",
    "\n",
    "print(\"Tensor po zmianie storage'a:\")\n",
    "print(t)\n",
    "print(\"Widzisz? Zmieni\u0142a si\u0119 liczba w tensorze, cho\u0107 go nie dotykali\u015bmy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15f401d",
   "metadata": {},
   "source": [
    "## Metadane: Shape, Offset i Stride\n",
    "\n",
    "Sk\u0105d PyTorch wie, \u017ce `t[1, 0]` to liczba `4`?\n",
    "U\u017cywa do tego **Stride (Kroku)**.\n",
    "\n",
    "*   **Stride:** Ile element\u00f3w musz\u0119 przeskoczy\u0107 w pami\u0119ci, \u017ceby zmieni\u0107 indeks o 1 w danym wymiarze?\n",
    "\n",
    "Dla tensora `[[1, 2, 3], [4, 5, 6]]`:\n",
    "*   \u017beby przej\u015b\u0107 do nast\u0119pnego wiersza (d\u00f3\u0142), musz\u0119 przeskoczy\u0107 3 liczby.\n",
    "*   \u017beby przej\u015b\u0107 do nast\u0119pnej kolumny (prawo), musz\u0119 przeskoczy\u0107 1 liczb\u0119.\n",
    "*   Stride = `(3, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02eee5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Stride: (3, 1)\n",
      "\n",
      "--- PO TRANSPOZYCJI ---\n",
      "Tensor:\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "Stride: (1, 3)\n",
      "\n",
      "--- CZY DANE SI\u0118 PRZESUN\u0118\u0141Y? ---\n",
      "Adres danych (data_ptr): 5829008883968\n",
      "Adres danych (data_ptr): 5829008883968\n",
      "\u2705 Adresy s\u0105 IDENTYCZNE! Transpozycja nie skopiowa\u0142a ani jednego bajta.\n"
     ]
    }
   ],
   "source": [
    "# Resetujemy tensor\n",
    "t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(f\"Tensor:\\n{t}\")\n",
    "print(f\"Stride: {t.stride()}\") \n",
    "# (3, 1) -> Skocz o 3, \u017ceby zmieni\u0107 wiersz. Skocz o 1, \u017ceby zmieni\u0107 kolumn\u0119.\n",
    "\n",
    "# MAGIA: Transpozycja\n",
    "t_transposed = t.t()\n",
    "\n",
    "print(\"\\n--- PO TRANSPOZYCJI ---\")\n",
    "print(f\"Tensor:\\n{t_transposed}\")\n",
    "print(f\"Stride: {t_transposed.stride()}\")\n",
    "# (1, 3) -> Teraz skocz o 1, \u017ceby zmieni\u0107 wiersz!\n",
    "\n",
    "print(\"\\n--- CZY DANE SI\u0118 PRZESUN\u0118\u0141Y? ---\")\n",
    "print_memory_address(t)\n",
    "print_memory_address(t_transposed)\n",
    "\n",
    "if t.data_ptr() == t_transposed.data_ptr():\n",
    "    print(\"\u2705 Adresy s\u0105 IDENTYCZNE! Transpozycja nie skopiowa\u0142a ani jednego bajta.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115cacd8",
   "metadata": {},
   "source": [
    "## Pu\u0142apka: Contiguous vs Non-Contiguous\n",
    "\n",
    "Transpozycja by\u0142a \"darmowa\", ale zap\u0142acili\u015bmy za ni\u0105 cen\u0119.\n",
    "Oryginalny tensor w pami\u0119ci wygl\u0105da tak: `1, 2, 3, 4, 5, 6`.\n",
    "Czytaj\u0105c go wierszami (po transpozycji): `1, 4, 2, 5, 3, 6`.\n",
    "\n",
    "To oznacza, \u017ce logiczne nast\u0119pstwo element\u00f3w **nie pokrywa si\u0119** z ich fizycznym u\u0142o\u017ceniem w pami\u0119ci.\n",
    "Tensor jest **nieci\u0105g\u0142y (Non-Contiguous)**.\n",
    "\n",
    "Metoda `.view()` dzia\u0142a TYLKO na ci\u0105g\u0142ych tensorach. Sprawd\u017amy to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca89fcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czy orygina\u0142 jest ci\u0105g\u0142y? True\n",
      "Czy transponowany jest ci\u0105g\u0142y? False\n",
      "\n",
      "--- PR\u00d3BA U\u017bYCIA .view() ---\n",
      "\ud83d\udeab B\u0141\u0104D: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
      "\n",
      "--- ROZWI\u0104ZANIE 1: .contiguous() ---\n",
      "Czy teraz ci\u0105g\u0142y? True\n",
      "Nowy adres pami\u0119ci: 5829008884160 (Inny ni\u017c orygina\u0142!)\n",
      "View dzia\u0142a: tensor([1, 4, 2, 5, 3, 6])\n",
      "\n",
      "--- ROZWI\u0104ZANIE 2: .reshape() ---\n",
      "Reshape dzia\u0142a: tensor([1, 4, 2, 5, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Czy orygina\u0142 jest ci\u0105g\u0142y? {t.is_contiguous()}\")\n",
    "print(f\"Czy transponowany jest ci\u0105g\u0142y? {t_transposed.is_contiguous()}\")\n",
    "\n",
    "print(\"\\n--- PR\u00d3BA U\u017bYCIA .view() ---\")\n",
    "try:\n",
    "    # Pr\u00f3bujemy sp\u0142aszczy\u0107 transponowany tensor\n",
    "    flat = t_transposed.view(-1)\n",
    "except RuntimeError as e:\n",
    "    print(f\"\ud83d\udeab B\u0141\u0104D: {e}\")\n",
    "\n",
    "print(\"\\n--- ROZWI\u0104ZANIE 1: .contiguous() ---\")\n",
    "# To fizycznie kopiuje dane i uk\u0142ada je poprawnie w nowym miejscu pami\u0119ci\n",
    "t_cont = t_transposed.contiguous()\n",
    "print(f\"Czy teraz ci\u0105g\u0142y? {t_cont.is_contiguous()}\")\n",
    "print(f\"Nowy adres pami\u0119ci: {t_cont.data_ptr()} (Inny ni\u017c orygina\u0142!)\")\n",
    "print(\"View dzia\u0142a:\", t_cont.view(-1))\n",
    "\n",
    "print(\"\\n--- ROZWI\u0104ZANIE 2: .reshape() ---\")\n",
    "# reshape() jest m\u0105dre: je\u015bli mo\u017ce zrobi\u0107 view, robi view. Je\u015bli nie, robi contiguous() + view.\n",
    "print(\"Reshape dzia\u0142a:\", t_transposed.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddab6be",
   "metadata": {},
   "source": [
    "## Hardcore: as_strided (Magia Splot\u00f3w)\n",
    "\n",
    "Mo\u017cemy stworzy\u0107 tensor \"z powietrza\", manipuluj\u0105c stride'ami r\u0119cznie.\n",
    "To jest technika u\u017cywana do implementacji **Conv2d** (tzw. `im2col`).\n",
    "\n",
    "Stworzymy \"okna\" (sliding windows) bez p\u0119tli i bez kopiowania pami\u0119ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06dbaf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SLIDING WINDOWS (Zero Copy) ---\n",
      "tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3],\n",
      "        [3, 4]])\n",
      "Adres danych (data_ptr): 5829008884416\n",
      "Adres danych (data_ptr): 5829008884416\n",
      "To ten sam obszar pami\u0119ci! Stworzyli\u015bmy wirtualn\u0105 macierz.\n"
     ]
    }
   ],
   "source": [
    "# Wektor 1D: [0, 1, 2, 3, 4]\n",
    "x = torch.arange(5)\n",
    "\n",
    "# Chcemy uzyska\u0107 okna o rozmiarze 2:\n",
    "# [0, 1]\n",
    "# [1, 2]\n",
    "# [2, 3]\n",
    "# [3, 4]\n",
    "\n",
    "# Fizycznie w pami\u0119ci mamy 5 liczb.\n",
    "# Stride (1): \u017beby przej\u015b\u0107 w d\u00f3\u0142 (do nast. okna), przesu\u0144 si\u0119 o 1 (0->1).\n",
    "# Stride (2): \u017beby przej\u015b\u0107 w prawo (wewn\u0105trz okna), przesu\u0144 si\u0119 o 1 (0->1).\n",
    "\n",
    "windows = x.as_strided(size=(4, 2), stride=(1, 1))\n",
    "\n",
    "print(\"--- SLIDING WINDOWS (Zero Copy) ---\")\n",
    "print(windows)\n",
    "print_memory_address(x)\n",
    "print_memory_address(windows)\n",
    "print(\"To ten sam obszar pami\u0119ci! Stworzyli\u015bmy wirtualn\u0105 macierz.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4174c184",
   "metadata": {},
   "source": [
    "## \ud83e\udd4b Black Belt Summary\n",
    "\n",
    "1.  **Tensor $\\neq$ Pami\u0119\u0107.** Tensor to tylko \"okulary\", przez kt\u00f3re patrzymy na pami\u0119\u0107 (Storage).\n",
    "2.  **Operacje Metadata-only:** `t()`, `permute()`, `transpose()` s\u0105 super szybkie, bo nie ruszaj\u0105 danych. Zmieniaj\u0105 tylko `stride`.\n",
    "3.  **Pu\u0142apka View:** `.view()` wymaga, \u017ceby dane w pami\u0119ci le\u017ca\u0142y w takiej kolejno\u015bci, jak sugeruje kszta\u0142t tensora. Je\u015bli zrobisz `transpose`, psujesz t\u0119 kolejno\u015b\u0107.\n",
    "4.  **Naprawa:**\n",
    "    *   `.contiguous()`: \"Uporz\u0105dkuj mi to fizycznie w pami\u0119ci\" (Kopiowanie = Wolne).\n",
    "    *   `.reshape()`: \"Zr\u00f3b co trzeba, \u017ceby zadzia\u0142a\u0142o\" (Bezpieczne).\n",
    "\n",
    "Wydajny kod PyTorch unika `.contiguous()`, je\u015bli to mo\u017cliwe, i operuje na widokach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}