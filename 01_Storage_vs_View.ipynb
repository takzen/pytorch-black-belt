{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5d64c10",
   "metadata": {},
   "source": [
    "# ğŸ¥‹ Lekcja 1: Storage vs Tensor (Prawda o PamiÄ™ci)\n",
    "\n",
    "W PyTorch **Tensor to tylko iluzja**. To nakÅ‚adka (interfejs) na prawdziwe dane.\n",
    "Prawdziwe dane Å¼yjÄ… w obiekcie zwanym **Storage**.\n",
    "\n",
    "*   **Storage:** CiÄ…gÅ‚y, jednowymiarowy blok bajtÃ³w w pamiÄ™ci (np. `[1, 2, 3, 4, 5, 6]`).\n",
    "*   **Tensor:** Zestaw metadanych (KsztaÅ‚t, Stride, Offset), ktÃ³ry mÃ³wi, jak \"czytaÄ‡\" ten blok.\n",
    "\n",
    "**Dlaczego to kluczowe?**\n",
    "Operacje takie jak `transpose`, `permute`, `narrow` czy `expand` **nie ruszajÄ… danych w pamiÄ™ci**. ZmieniajÄ… tylko metadane. SÄ… bÅ‚yskawiczne ($O(1)$).\n",
    "Ale majÄ… swojÄ… cenÄ™: tracÄ… **ciÄ…gÅ‚oÅ›Ä‡ (contiguity)**, co powoduje bÅ‚Ä™dy przy prÃ³bie uÅ¼ycia `.view()`.\n",
    "\n",
    "W tej lekcji zhakujemy pamiÄ™Ä‡ PyTorcha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9723106d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TENSOR ---\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "KsztaÅ‚t: torch.Size([2, 3])\n",
      "Adres danych (data_ptr): 5829008883840\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ctypes\n",
    "\n",
    "# Funkcja pomocnicza do podglÄ…dania adresu pamiÄ™ci\n",
    "def print_memory_address(tensor):\n",
    "    print(f\"Adres danych (data_ptr): {tensor.data_ptr()}\")\n",
    "\n",
    "# 1. TWORZYMY TENSOR\n",
    "t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(\"--- TENSOR ---\")\n",
    "print(t)\n",
    "print(f\"KsztaÅ‚t: {t.shape}\")\n",
    "print_memory_address(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdd3b6f",
   "metadata": {},
   "source": [
    "## Storage: To, co jest pod maskÄ…\n",
    "\n",
    "Zobaczmy, jak te dane wyglÄ…dajÄ… naprawdÄ™.\n",
    "Mimo Å¼e tensor jest 2D (wiersze i kolumny), w pamiÄ™ci komputera jest to **pÅ‚aska lista**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a945687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STORAGE (Surowe dane) ---\n",
      "Rozmiar storage: 48 bajtÃ³w (6 liczb int64 * 8 bajtÃ³w = 48)\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "--- HACKOWANIE PAMIÄ˜CI ---\n",
      "Tensor po zmianie storage'a:\n",
      "tensor([[99,  2,  3],\n",
      "        [ 4,  5,  6]])\n",
      "Widzisz? ZmieniÅ‚a siÄ™ liczba w tensorze, choÄ‡ go nie dotykaliÅ›my.\n"
     ]
    }
   ],
   "source": [
    "# DostÄ™p do surowego magazynu danych\n",
    "storage = t.untyped_storage()\n",
    "\n",
    "print(\"--- STORAGE (Surowe dane) ---\")\n",
    "print(f\"Rozmiar storage: {len(storage)} bajtÃ³w (6 liczb int64 * 8 bajtÃ³w = 48)\")\n",
    "# PodglÄ…d zawartoÅ›ci (jako lista)\n",
    "print(storage.tolist())\n",
    "\n",
    "# DOWÃ“D: Zmiana w Storage zmienia Tensor!\n",
    "print(\"\\n--- HACKOWANIE PAMIÄ˜CI ---\")\n",
    "# Zmieniamy pierwszy element w storage (fizycznej pamiÄ™ci)\n",
    "# Uwaga: Storage jest pÅ‚aski, wiÄ™c indeksujemy liniowo\n",
    "t.untyped_storage()[0] = 99 \n",
    "\n",
    "print(\"Tensor po zmianie storage'a:\")\n",
    "print(t)\n",
    "print(\"Widzisz? ZmieniÅ‚a siÄ™ liczba w tensorze, choÄ‡ go nie dotykaliÅ›my.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15f401d",
   "metadata": {},
   "source": [
    "## Metadane: Shape, Offset i Stride\n",
    "\n",
    "SkÄ…d PyTorch wie, Å¼e `t[1, 0]` to liczba `4`?\n",
    "UÅ¼ywa do tego **Stride (Kroku)**.\n",
    "\n",
    "*   **Stride:** Ile elementÃ³w muszÄ™ przeskoczyÄ‡ w pamiÄ™ci, Å¼eby zmieniÄ‡ indeks o 1 w danym wymiarze?\n",
    "\n",
    "Dla tensora `[[1, 2, 3], [4, 5, 6]]`:\n",
    "*   Å»eby przejÅ›Ä‡ do nastÄ™pnego wiersza (dÃ³Å‚), muszÄ™ przeskoczyÄ‡ 3 liczby.\n",
    "*   Å»eby przejÅ›Ä‡ do nastÄ™pnej kolumny (prawo), muszÄ™ przeskoczyÄ‡ 1 liczbÄ™.\n",
    "*   Stride = `(3, 1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02eee5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Stride: (3, 1)\n",
      "\n",
      "--- PO TRANSPOZYCJI ---\n",
      "Tensor:\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "Stride: (1, 3)\n",
      "\n",
      "--- CZY DANE SIÄ˜ PRZESUNÄ˜ÅY? ---\n",
      "Adres danych (data_ptr): 5829008883968\n",
      "Adres danych (data_ptr): 5829008883968\n",
      "âœ… Adresy sÄ… IDENTYCZNE! Transpozycja nie skopiowaÅ‚a ani jednego bajta.\n"
     ]
    }
   ],
   "source": [
    "# Resetujemy tensor\n",
    "t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(f\"Tensor:\\n{t}\")\n",
    "print(f\"Stride: {t.stride()}\") \n",
    "# (3, 1) -> Skocz o 3, Å¼eby zmieniÄ‡ wiersz. Skocz o 1, Å¼eby zmieniÄ‡ kolumnÄ™.\n",
    "\n",
    "# MAGIA: Transpozycja\n",
    "t_transposed = t.t()\n",
    "\n",
    "print(\"\\n--- PO TRANSPOZYCJI ---\")\n",
    "print(f\"Tensor:\\n{t_transposed}\")\n",
    "print(f\"Stride: {t_transposed.stride()}\")\n",
    "# (1, 3) -> Teraz skocz o 1, Å¼eby zmieniÄ‡ wiersz!\n",
    "\n",
    "print(\"\\n--- CZY DANE SIÄ˜ PRZESUNÄ˜ÅY? ---\")\n",
    "print_memory_address(t)\n",
    "print_memory_address(t_transposed)\n",
    "\n",
    "if t.data_ptr() == t_transposed.data_ptr():\n",
    "    print(\"âœ… Adresy sÄ… IDENTYCZNE! Transpozycja nie skopiowaÅ‚a ani jednego bajta.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115cacd8",
   "metadata": {},
   "source": [
    "## PuÅ‚apka: Contiguous vs Non-Contiguous\n",
    "\n",
    "Transpozycja byÅ‚a \"darmowa\", ale zapÅ‚aciliÅ›my za niÄ… cenÄ™.\n",
    "Oryginalny tensor w pamiÄ™ci wyglÄ…da tak: `1, 2, 3, 4, 5, 6`.\n",
    "CzytajÄ…c go wierszami (po transpozycji): `1, 4, 2, 5, 3, 6`.\n",
    "\n",
    "To oznacza, Å¼e logiczne nastÄ™pstwo elementÃ³w **nie pokrywa siÄ™** z ich fizycznym uÅ‚oÅ¼eniem w pamiÄ™ci.\n",
    "Tensor jest **nieciÄ…gÅ‚y (Non-Contiguous)**.\n",
    "\n",
    "Metoda `.view()` dziaÅ‚a TYLKO na ciÄ…gÅ‚ych tensorach. SprawdÅºmy to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca89fcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czy oryginaÅ‚ jest ciÄ…gÅ‚y? True\n",
      "Czy transponowany jest ciÄ…gÅ‚y? False\n",
      "\n",
      "--- PRÃ“BA UÅ»YCIA .view() ---\n",
      "ğŸš« BÅÄ„D: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.\n",
      "\n",
      "--- ROZWIÄ„ZANIE 1: .contiguous() ---\n",
      "Czy teraz ciÄ…gÅ‚y? True\n",
      "Nowy adres pamiÄ™ci: 5829008884160 (Inny niÅ¼ oryginaÅ‚!)\n",
      "View dziaÅ‚a: tensor([1, 4, 2, 5, 3, 6])\n",
      "\n",
      "--- ROZWIÄ„ZANIE 2: .reshape() ---\n",
      "Reshape dziaÅ‚a: tensor([1, 4, 2, 5, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Czy oryginaÅ‚ jest ciÄ…gÅ‚y? {t.is_contiguous()}\")\n",
    "print(f\"Czy transponowany jest ciÄ…gÅ‚y? {t_transposed.is_contiguous()}\")\n",
    "\n",
    "print(\"\\n--- PRÃ“BA UÅ»YCIA .view() ---\")\n",
    "try:\n",
    "    # PrÃ³bujemy spÅ‚aszczyÄ‡ transponowany tensor\n",
    "    flat = t_transposed.view(-1)\n",
    "except RuntimeError as e:\n",
    "    print(f\"ğŸš« BÅÄ„D: {e}\")\n",
    "\n",
    "print(\"\\n--- ROZWIÄ„ZANIE 1: .contiguous() ---\")\n",
    "# To fizycznie kopiuje dane i ukÅ‚ada je poprawnie w nowym miejscu pamiÄ™ci\n",
    "t_cont = t_transposed.contiguous()\n",
    "print(f\"Czy teraz ciÄ…gÅ‚y? {t_cont.is_contiguous()}\")\n",
    "print(f\"Nowy adres pamiÄ™ci: {t_cont.data_ptr()} (Inny niÅ¼ oryginaÅ‚!)\")\n",
    "print(\"View dziaÅ‚a:\", t_cont.view(-1))\n",
    "\n",
    "print(\"\\n--- ROZWIÄ„ZANIE 2: .reshape() ---\")\n",
    "# reshape() jest mÄ…dre: jeÅ›li moÅ¼e zrobiÄ‡ view, robi view. JeÅ›li nie, robi contiguous() + view.\n",
    "print(\"Reshape dziaÅ‚a:\", t_transposed.reshape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddab6be",
   "metadata": {},
   "source": [
    "## Hardcore: as_strided (Magia SplotÃ³w)\n",
    "\n",
    "MoÅ¼emy stworzyÄ‡ tensor \"z powietrza\", manipulujÄ…c stride'ami rÄ™cznie.\n",
    "To jest technika uÅ¼ywana do implementacji **Conv2d** (tzw. `im2col`).\n",
    "\n",
    "Stworzymy \"okna\" (sliding windows) bez pÄ™tli i bez kopiowania pamiÄ™ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06dbaf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SLIDING WINDOWS (Zero Copy) ---\n",
      "tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3],\n",
      "        [3, 4]])\n",
      "Adres danych (data_ptr): 5829008884416\n",
      "Adres danych (data_ptr): 5829008884416\n",
      "To ten sam obszar pamiÄ™ci! StworzyliÅ›my wirtualnÄ… macierz.\n"
     ]
    }
   ],
   "source": [
    "# Wektor 1D: [0, 1, 2, 3, 4]\n",
    "x = torch.arange(5)\n",
    "\n",
    "# Chcemy uzyskaÄ‡ okna o rozmiarze 2:\n",
    "# [0, 1]\n",
    "# [1, 2]\n",
    "# [2, 3]\n",
    "# [3, 4]\n",
    "\n",
    "# Fizycznie w pamiÄ™ci mamy 5 liczb.\n",
    "# Stride (1): Å»eby przejÅ›Ä‡ w dÃ³Å‚ (do nast. okna), przesuÅ„ siÄ™ o 1 (0->1).\n",
    "# Stride (2): Å»eby przejÅ›Ä‡ w prawo (wewnÄ…trz okna), przesuÅ„ siÄ™ o 1 (0->1).\n",
    "\n",
    "windows = x.as_strided(size=(4, 2), stride=(1, 1))\n",
    "\n",
    "print(\"--- SLIDING WINDOWS (Zero Copy) ---\")\n",
    "print(windows)\n",
    "print_memory_address(x)\n",
    "print_memory_address(windows)\n",
    "print(\"To ten sam obszar pamiÄ™ci! StworzyliÅ›my wirtualnÄ… macierz.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4174c184",
   "metadata": {},
   "source": [
    "## ğŸ¥‹ Black Belt Summary\n",
    "\n",
    "1.  **Tensor $\\neq$ PamiÄ™Ä‡.** Tensor to tylko \"okulary\", przez ktÃ³re patrzymy na pamiÄ™Ä‡ (Storage).\n",
    "2.  **Operacje Metadata-only:** `t()`, `permute()`, `transpose()` sÄ… super szybkie, bo nie ruszajÄ… danych. ZmieniajÄ… tylko `stride`.\n",
    "3.  **PuÅ‚apka View:** `.view()` wymaga, Å¼eby dane w pamiÄ™ci leÅ¼aÅ‚y w takiej kolejnoÅ›ci, jak sugeruje ksztaÅ‚t tensora. JeÅ›li zrobisz `transpose`, psujesz tÄ™ kolejnoÅ›Ä‡.\n",
    "4.  **Naprawa:**\n",
    "    *   `.contiguous()`: \"UporzÄ…dkuj mi to fizycznie w pamiÄ™ci\" (Kopiowanie = Wolne).\n",
    "    *   `.reshape()`: \"ZrÃ³b co trzeba, Å¼eby zadziaÅ‚aÅ‚o\" (Bezpieczne).\n",
    "\n",
    "Wydajny kod PyTorch unika `.contiguous()`, jeÅ›li to moÅ¼liwe, i operuje na widokach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
