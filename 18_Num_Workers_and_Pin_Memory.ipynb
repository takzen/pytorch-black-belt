{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "576d9ece",
   "metadata": {},
   "source": [
    "# ðŸ¥‹ Lekcja 18: Optymalizacja Transferu Danych (num_workers & pin_memory)\n",
    "\n",
    "Trening sieci to sztafeta.\n",
    "1.  **CPU (Dysk/RAM):** Czyta plik -> Dekoduje JPG -> Augmentacja -> Tensor.\n",
    "2.  **Transfer:** Kopiowanie z RAM do VRAM.\n",
    "3.  **GPU:** Obliczenia (Forward/Backward).\n",
    "\n",
    "JeÅ›li krok 1 i 2 sÄ… wolniejsze niÅ¼ 3, Twoje drogocenne GPU leÅ¼y odÅ‚ogiem.\n",
    "\n",
    "**RozwiÄ…zania:**\n",
    "1.  **`num_workers > 0`**:\n",
    "    *   DomyÅ›lnie (`0`) gÅ‚Ã³wny proces robi wszystko: Wczytaj -> Trenuj -> Wczytaj.\n",
    "    *   Z workerami (`4`): Workery Å‚adujÄ… kolejkÄ™ w tle. GÅ‚Ã³wny proces tylko bierze gotowe.\n",
    "2.  **`pin_memory=True`**:\n",
    "    *   PamiÄ™Ä‡ RAM dzieli siÄ™ na **Pageable** (zwykÅ‚a) i **Pinned** (sztywna).\n",
    "    *   Transfer: Pageable RAM -> Pinned RAM -> GPU VRAM.\n",
    "    *   UstawiajÄ…c `pin_memory=True`, wrzucamy dane od razu do Pinned RAM. OszczÄ™dzamy jedno kopiowanie CPU-CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73b9c46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mamy GPU! pin_memory ma sens.\n",
      "Dataset gotowy: 10000 prÃ³bek.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "\n",
    "# SprawdÅºmy sprzÄ™t\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"âœ… Mamy GPU! pin_memory ma sens.\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"âš ï¸ Brak GPU. pin_memory nic nie da, ale num_workers nadal dziaÅ‚a.\")\n",
    "\n",
    "# Generujemy spory dataset (100MB)\n",
    "data_size = 10000\n",
    "features = 1000\n",
    "dataset = TensorDataset(torch.randn(data_size, features), torch.randn(data_size, 1))\n",
    "\n",
    "print(f\"Dataset gotowy: {data_size} prÃ³bek.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dab5eb",
   "metadata": {},
   "source": [
    "## 1. Pin Memory (Autostrada)\n",
    "\n",
    "Standardowy tensor w PyTorch Å¼yje w pamiÄ™ci stronicowanej (Pageable). System operacyjny moÅ¼e go przesuwaÄ‡ lub zrzuciÄ‡ na dysk (Swap).\n",
    "Karta graficzna (DMA - Direct Memory Access) nie moÅ¼e czytaÄ‡ z takiej pamiÄ™ci. Wymaga pamiÄ™ci \"przypiÄ™tej\" (Pinned), ktÃ³ra fizycznie nie zmienia adresu.\n",
    "\n",
    "Ustawienie `pin_memory=True` w DataLoaderze sprawia, Å¼e PyTorch alokuje specjalny bufor w RAM, co przyspiesza transfer `to(device)` nawet o **2-3 razy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e40e8eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czy jest przypiÄ™ty? False\n",
      "Czy teraz jest przypiÄ™ty? True\n",
      "Czas Pageable -> GPU: 0.0065s\n",
      "Czas Pinned -> GPU:   0.0010s\n",
      "(Przy maÅ‚ych tensorach rÃ³Å¼nica jest maÅ‚a, przy Gigabajtach - ogromna).\n"
     ]
    }
   ],
   "source": [
    "# Tworzymy tensor w zwykÅ‚ym RAM\n",
    "x = torch.randn(5, 5)\n",
    "print(f\"Czy jest przypiÄ™ty? {x.is_pinned()}\")\n",
    "\n",
    "# Przypinamy go rÄ™cznie (to robi DataLoader pod spodem)\n",
    "x_pinned = x.pin_memory()\n",
    "print(f\"Czy teraz jest przypiÄ™ty? {x_pinned.is_pinned()}\")\n",
    "\n",
    "# Benchmark transferu (tylko jeÅ›li masz GPU)\n",
    "if device == \"cuda\":\n",
    "    # 1. Bez Pinningu\n",
    "    start = time.time()\n",
    "    for _ in range(100):\n",
    "        _ = x.to(device)\n",
    "    print(f\"Czas Pageable -> GPU: {time.time() - start:.4f}s\")\n",
    "    \n",
    "    # 2. Z Pinningiem\n",
    "    start = time.time()\n",
    "    for _ in range(100):\n",
    "        _ = x_pinned.to(device, non_blocking=True) # non_blocking pozwala na asynchronicznoÅ›Ä‡!\n",
    "    print(f\"Czas Pinned -> GPU:   {time.time() - start:.4f}s\")\n",
    "    print(\"(Przy maÅ‚ych tensorach rÃ³Å¼nica jest maÅ‚a, przy Gigabajtach - ogromna).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3339ae3",
   "metadata": {},
   "source": [
    "## 2. Num Workers (WielowÄ…tkowoÅ›Ä‡)\n",
    "\n",
    "To parametr, ktÃ³ry decyduje, ile podprocesÃ³w \"przygotowuje posiÅ‚ki\" dla GPU.\n",
    "\n",
    "**Zasada kciuka:**\n",
    "*   `0`: Debugowanie (najbezpieczniej, dziaÅ‚a na Windows w Jupyterze).\n",
    "*   `2-4`: Zazwyczaj optymalne.\n",
    "*   `>8`: CzÄ™sto spowalnia (zbyt duÅ¼y narzut na zarzÄ…dzanie procesami).\n",
    "\n",
    "**âš ï¸ UWAGA DLA UÅ»YTKOWNIKÃ“W WINDOWS:**\n",
    "JesteÅ›my w Jupyter Notebook na Windows. Ustawienie `num_workers > 0` tutaj czÄ™sto powoduje bÅ‚Ä™dy (BrokenPipeError, RuntimeError), o ktÃ³rych rozmawialiÅ›my wczeÅ›niej.\n",
    "Dlatego w poniÅ¼szym teÅ›cie **zostawimy 0**, ale kod jest gotowy, by zmieniÄ‡ tÄ™ liczbÄ™ na serwerze Linuxowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "651c7708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BENCHMARK (Symulacja) ---\n",
      "Workers=0, Pin=False: 0.1539s\n",
      "Workers=0, Pin=True:  0.0782s\n",
      "Zysk z samego Pinningu: 1.97x\n",
      "Workers=4: (PominiÄ™to ze wzglÄ™du na stabilnoÅ›Ä‡ kernela na Windows)\n"
     ]
    }
   ],
   "source": [
    "def benchmark_loader(num_workers, pin_memory):\n",
    "    # Tworzymy loader z zadanymi parametrami\n",
    "    # UWAGA: Na Windows w Jupyterze num_workers > 0 moÅ¼e zawiesiÄ‡ kernel!\n",
    "    # JeÅ›li to uruchamiasz u siebie, zachowaj ostroÅ¼noÅ›Ä‡.\n",
    "    loader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=128, \n",
    "        num_workers=num_workers, \n",
    "        pin_memory=pin_memory,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    for batch_x, batch_y in loader:\n",
    "        # Symulacja transferu na GPU\n",
    "        if device == \"cuda\":\n",
    "            batch_x = batch_x.to(device, non_blocking=pin_memory)\n",
    "            batch_y = batch_y.to(device, non_blocking=pin_memory)\n",
    "            \n",
    "        # Symulacja obliczeÅ„ (krÃ³tka)\n",
    "        _ = batch_x * 2 \n",
    "        \n",
    "    return time.time() - start\n",
    "\n",
    "print(\"--- BENCHMARK (Symulacja) ---\")\n",
    "\n",
    "# Test 1: Baza (Jeden proces, zwykÅ‚a pamiÄ™Ä‡) - Bezpieczne na Windows\n",
    "t1 = benchmark_loader(num_workers=0, pin_memory=False)\n",
    "print(f\"Workers=0, Pin=False: {t1:.4f}s\")\n",
    "\n",
    "# Test 2: Tylko Pin Memory (Bezpieczne na Windows i GPU)\n",
    "if device == \"cuda\":\n",
    "    t2 = benchmark_loader(num_workers=0, pin_memory=True)\n",
    "    print(f\"Workers=0, Pin=True:  {t2:.4f}s\")\n",
    "    print(f\"Zysk z samego Pinningu: {t1/t2:.2f}x\")\n",
    "\n",
    "# Test 3: Workers > 0 (RYZYKOWNE W NOTATNIKU NA WINDOWS - POMIJAMY)\n",
    "# Na Linuxie/Produkcji ustawiÅ‚byÅ› tu np. num_workers=4\n",
    "# t3 = benchmark_loader(num_workers=4, pin_memory=True) \n",
    "print(\"Workers=4: (PominiÄ™to ze wzglÄ™du na stabilnoÅ›Ä‡ kernela na Windows)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1dc6d",
   "metadata": {},
   "source": [
    "## ðŸ¥‹ Black Belt Summary\n",
    "\n",
    "Jak konfigurowaÄ‡ `DataLoader` na produkcji?\n",
    "\n",
    "1.  **`pin_memory=True`**: ZAWSZE, jeÅ›li uÅ¼ywasz GPU. To darmowe przyspieszenie.\n",
    "2.  **`num_workers`**:\n",
    "    *   Zacznij od `4`.\n",
    "    *   JeÅ›li masz szybki dysk (NVMe) i proste dane, CPU nie jest wÄ…skim gardÅ‚em.\n",
    "    *   JeÅ›li robisz ciÄ™Å¼kÄ… augmentacjÄ™ w locie (obracanie, skalowanie), zwiÄ™ksz liczbÄ™ workerÃ³w, Å¼eby GPU nie czekaÅ‚o.\n",
    "3.  **`non_blocking=True`**: Przy `x.to(device)` uÅ¼ywaj tej flagi razem z `pin_memory`. Pozwala to GPU wykonywaÄ‡ obliczenia na poprzednim batchu w tym samym czasie, gdy CPU przesyÅ‚a nastÄ™pny batch."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
