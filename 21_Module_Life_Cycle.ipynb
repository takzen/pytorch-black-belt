{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b55fb5a2",
   "metadata": {},
   "source": [
    "# ü•ã Lekcja 21: Cykl ≈ºycia nn.Module (__call__ vs forward)\n",
    "\n",
    "Ka≈ºda sieƒá w PyTorch dziedziczy po `nn.Module`. To nie jest zwyk≈Ça klasa Pythona.\n",
    "To **kontener**, kt√≥ry u≈ºywa \"czarnej magii\" Pythona (`__setattr__`, `__call__`), ≈ºeby ≈õledziƒá Twoje wagi.\n",
    "\n",
    "**Kluczowa zasada:**\n",
    "NIGDY nie wywo≈Çuj `model.forward(x)` rƒôcznie.\n",
    "ZAWSZE wywo≈Çuj `model(x)`.\n",
    "\n",
    "Dlaczego?\n",
    "`__call__` (kt√≥re jest wywo≈Çywane przez `model()`) robi mn√≥stwo rzeczy w tle:\n",
    "1.  Uruchamia `_forward_pre_hooks`.\n",
    "2.  Uruchamia `forward()`.\n",
    "3.  Uruchamia `_forward_hooks`.\n",
    "\n",
    "Je≈õli wywo≈Çasz `forward` bezpo≈õrednio, ominiesz system hook√≥w (co zepsuje np. Profiling, Quantization i biblioteki typu Captum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c98c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gotowy.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. Definiujemy prosty modu≈Ç\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"   -> WewnƒÖtrz forward()\")\n",
    "        return self.fc(x)\n",
    "\n",
    "model = MyModule()\n",
    "x = torch.randn(1, 10)\n",
    "\n",
    "print(\"Model gotowy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29df5c80",
   "metadata": {},
   "source": [
    "## Eksperyment: Call vs Forward\n",
    "\n",
    "Zarejestrujemy \"Hooka\" (funkcjƒô, kt√≥ra odpala siƒô automatycznie przy ka≈ºdym przej≈õciu danych).\n",
    "Zobaczymy, ≈ºe `forward()` go ignoruje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f19212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. U≈ºycie poprawne: model(x) ---\n",
      "   -> WewnƒÖtrz forward()\n",
      "üïµÔ∏è HOOK: Kto≈õ u≈ºywa modelu!\n",
      "\n",
      "--- 2. U≈ºycie b≈Çƒôdne: model.forward(x) ---\n",
      "   -> WewnƒÖtrz forward()\n",
      "\n",
      "Wniosek: Widzisz? W drugim przypadku szpieg (Hook) nie zadzia≈Ça≈Ç!\n"
     ]
    }
   ],
   "source": [
    "# Funkcja-szpieg (Hook)\n",
    "def spy_hook(module, input, output):\n",
    "    print(\"üïµÔ∏è HOOK: Kto≈õ u≈ºywa modelu!\")\n",
    "\n",
    "# Rejestrujemy hooka\n",
    "handle = model.register_forward_hook(spy_hook)\n",
    "\n",
    "print(\"--- 1. U≈ºycie poprawne: model(x) ---\")\n",
    "# To wywo≈Çuje __call__\n",
    "out1 = model(x)\n",
    "\n",
    "print(\"\\n--- 2. U≈ºycie b≈Çƒôdne: model.forward(x) ---\")\n",
    "# To omija __call__\n",
    "out2 = model.forward(x)\n",
    "\n",
    "print(\"\\nWniosek: Widzisz? W drugim przypadku szpieg (Hook) nie zadzia≈Ça≈Ç!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6869c2",
   "metadata": {},
   "source": [
    "## Magia Rejestracji (`__setattr__`)\n",
    "\n",
    "W zwyk≈Çym Pythonie: `self.a = 5` po prostu przypisuje liczbƒô do obiektu.\n",
    "W `nn.Module`: `self.layer = nn.Linear(...)` robi co≈õ wiƒôcej.\n",
    "\n",
    "PyTorch przechwytuje ka≈ºde przypisanie (`__setattr__`).\n",
    "1.  Sprawdza: \"Czy to, co przypisujesz, to `Parameter` lub `Module`?\".\n",
    "2.  Je≈õli tak: Dodaje to do specjalnej listy `_parameters` lub `_modules`.\n",
    "3.  Dziƒôki temu `model.parameters()` lub `model.to('cuda')` wie, co ma przenie≈õƒá, bez Twojej ingerencji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94f852e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CO WIDZI PYTORCH? (model.state_dict()) ---\n",
      "odict_keys(['parametr', 'warstwa.weight', 'warstwa.bias'])\n",
      "\n",
      "--- ANALIZA ---\n",
      "Widzisz 'parametr'? TAK.\n",
      "Widzisz 'warstwa.weight'? TAK.\n",
      "Widzisz 'zwykly_tensor'? NIE! (Nie zostanie zapisany przy save_model!)\n"
     ]
    }
   ],
   "source": [
    "class MagicModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. Zwyk≈Ça zmienna Pythonowa (Ignorowana przez PyTorch)\n",
    "        self.zwykla_zmienna = [1, 2, 3]\n",
    "        \n",
    "        # 2. Tensor (Te≈º ignorowany! To czƒôsty b≈ÇƒÖd!)\n",
    "        self.zwykly_tensor = torch.randn(3, 3)\n",
    "        \n",
    "        # 3. nn.Parameter (To jest ≈õledzone!)\n",
    "        self.parametr = nn.Parameter(torch.randn(3, 3))\n",
    "        \n",
    "        # 4. Podmodu≈Ç (To te≈º jest ≈õledzone!)\n",
    "        self.warstwa = nn.Linear(3, 3)\n",
    "\n",
    "model_magic = MagicModule()\n",
    "\n",
    "print(\"--- CO WIDZI PYTORCH? (model.state_dict()) ---\")\n",
    "# state_dict() zwraca tylko to, co PyTorch uzna≈Ç za \"swoje\"\n",
    "print(model_magic.state_dict().keys())\n",
    "\n",
    "print(\"\\n--- ANALIZA ---\")\n",
    "print(\"Widzisz 'parametr'? TAK.\")\n",
    "print(\"Widzisz 'warstwa.weight'? TAK.\")\n",
    "print(\"Widzisz 'zwykly_tensor'? NIE! (Nie zostanie zapisany przy save_model!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b7b39",
   "metadata": {},
   "source": [
    "## Pu≈Çapka Listy (`list` vs `nn.ModuleList`)\n",
    "\n",
    "To jest b≈ÇƒÖd, kt√≥ry pope≈Çnia ka≈ºdy junior.\n",
    "Chcesz mieƒá listƒô 10 warstw. Piszesz:\n",
    "`self.layers = [nn.Linear(...) for _ in range(10)]`\n",
    "\n",
    "To **nie zadzia≈Ça**. PyTorch nie zaglƒÖda do ≈õrodka zwyk≈Çych list Pythona.\n",
    "Te warstwy nie bƒôdƒÖ trenowane, nie trafiƒÖ na GPU.\n",
    "\n",
    "Musisz u≈ºyƒá **`nn.ModuleList`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7502cf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba parametr√≥w w BrokenNet: 0\n",
      "Wynik: 0. PyTorch 'nie widzi' warstw w li≈õcie.\n",
      "Liczba parametr√≥w w FixedNet:  6\n",
      "Wynik: 6 (3 wagi + 3 biasy). Dzia≈Ça.\n"
     ]
    }
   ],
   "source": [
    "class BrokenNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Z≈ÅE: Zwyk≈Ça lista\n",
    "        self.layers = [nn.Linear(10, 10) for _ in range(3)]\n",
    "\n",
    "class FixedNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # DOBRE: ModuleList\n",
    "        self.layers = nn.ModuleList([nn.Linear(10, 10) for _ in range(3)])\n",
    "\n",
    "bad = BrokenNet()\n",
    "good = FixedNet()\n",
    "\n",
    "print(f\"Liczba parametr√≥w w BrokenNet: {len(list(bad.parameters()))}\")\n",
    "print(\"Wynik: 0. PyTorch 'nie widzi' warstw w li≈õcie.\")\n",
    "\n",
    "print(f\"Liczba parametr√≥w w FixedNet:  {len(list(good.parameters()))}\")\n",
    "print(\"Wynik: 6 (3 wagi + 3 biasy). Dzia≈Ça.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b5014c",
   "metadata": {},
   "source": [
    "## ü•ã Black Belt Summary\n",
    "\n",
    "1.  **Zasada nr 1:** Zawsze u≈ºywaj `model(x)`, nigdy `model.forward(x)`.\n",
    "2.  **Rejestracja:** ≈ªeby tensor by≈Ç \"widziany\" przez PyTorch (trening, save/load, GPU), musi byƒá typu `nn.Parameter` lub byƒá przypisany do `nn.Module`.\n",
    "3.  **Kontenery:** Zwyk≈Ça lista `[]` lub s≈Çownik `{}` ukrywajƒÖ warstwy przed PyTorchem. U≈ºywaj `nn.ModuleList` i `nn.ModuleDict`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
