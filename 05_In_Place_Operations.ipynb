{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22ece28b",
   "metadata": {},
   "source": [
    "# ğŸ¥‹ Lekcja 5: In-Place Operations (OszczÄ™dnoÅ›Ä‡ vs Ryzyko)\n",
    "\n",
    "W PyTorch operacje zakoÅ„czone podkreÅ›lnikiem `_` (np. `add_`, `scatter_`, `relu_`) lub operatory przypisania (`+=`, `*=`) dziaÅ‚ajÄ… **In-Place**.\n",
    "\n",
    "**Zaleta:** Nie alokujÄ… nowej pamiÄ™ci. DziaÅ‚ajÄ… na istniejÄ…cym buforze.\n",
    "**Wada:** NadpisujÄ… dane, ktÃ³re mogÄ… byÄ‡ potrzebne do obliczenia gradientu.\n",
    "\n",
    "JeÅ›li nadpiszesz tensor, ktÃ³ry byÅ‚ potrzebny do `backward()`, PyTorch wykryje to i rzuci sÅ‚ynnym bÅ‚Ä™dem:\n",
    "`RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation`.\n",
    "\n",
    "W tej lekcji nauczymy siÄ™, kiedy moÅ¼na, a kiedy nie wolno tego robiÄ‡."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f189f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startowy adres: 5292439961600\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Funkcja do sprawdzania adresu pamiÄ™ci\n",
    "def check_memory(name, old_ptr, tensor):\n",
    "    new_ptr = tensor.untyped_storage().data_ptr()\n",
    "    if old_ptr == new_ptr:\n",
    "        print(f\"âœ… {name}: Adres BEZ ZMIAN (In-Place). OszczÄ™dzamy pamiÄ™Ä‡.\")\n",
    "    else:\n",
    "        print(f\"âŒ {name}: Nowy adres (Out-of-Place). Alokacja pamiÄ™ci.\")\n",
    "    return new_ptr\n",
    "\n",
    "# Baza\n",
    "t = torch.ones(1000, 1000)\n",
    "ptr = t.untyped_storage().data_ptr()\n",
    "print(f\"Startowy adres: {ptr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ed244b",
   "metadata": {},
   "source": [
    "## Test PamiÄ™ci: `x = x + 1` vs `x += 1`\n",
    "\n",
    "SprawdÅºmy, co dzieje siÄ™ w pamiÄ™ci RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dfcb85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ x = x + 1: Nowy adres (Out-of-Place). Alokacja pamiÄ™ci.\n",
      "âœ… x += 1: Adres BEZ ZMIAN (In-Place). OszczÄ™dzamy pamiÄ™Ä‡.\n",
      "âœ… x.add_(1): Adres BEZ ZMIAN (In-Place). OszczÄ™dzamy pamiÄ™Ä‡.\n",
      "âŒ x.add(1): Nowy adres (Out-of-Place). Alokacja pamiÄ™ci.\n"
     ]
    }
   ],
   "source": [
    "# 1. Out-of-place (Standard)\n",
    "t = t + 1\n",
    "ptr = check_memory(\"x = x + 1\", ptr, t)\n",
    "\n",
    "# 2. In-place (Pythonowy operator)\n",
    "t += 1\n",
    "ptr = check_memory(\"x += 1\", ptr, t)\n",
    "\n",
    "# 3. In-place (Metoda PyTorch z _)\n",
    "t.add_(1)\n",
    "ptr = check_memory(\"x.add_(1)\", ptr, t)\n",
    "\n",
    "# 4. Out-of-place (Metoda PyTorch bez _)\n",
    "t = t.add(1)\n",
    "ptr = check_memory(\"x.add(1)\", ptr, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a169b6",
   "metadata": {},
   "source": [
    "## The Dark Side: Autograd i Version Counter\n",
    "\n",
    "KaÅ¼dy tensor w PyTorch ma licznik wersji (`_version`).\n",
    "*   Przy kaÅ¼dej operacji In-Place licznik roÅ›nie.\n",
    "*   Autograd zapisuje sobie: \"PotrzebujÄ™ tensora X w wersji 0, Å¼eby policzyÄ‡ pochodnÄ…\".\n",
    "*   JeÅ›li przy `backward()` okaÅ¼e siÄ™, Å¼e tensor X ma teraz wersjÄ™ 1 (bo go nadpisaÅ‚eÅ›), PyTorch rzuca bÅ‚Ä™dem, zamiast liczyÄ‡ gÅ‚upoty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96629d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WartoÅ›Ä‡ y przed zmianÄ…: tensor([10.], grad_fn=<MulBackward0>)\n",
      "WartoÅ›Ä‡ w (zmieniona): tensor([500.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Symulacja bÅ‚Ä™du w treningu\n",
    "\n",
    "# Wagi (wymagajÄ… gradientu) - to jest \"Leaf Variable\"\n",
    "w = torch.tensor([5.0], requires_grad=True)\n",
    "\n",
    "# Krok 1: Forward\n",
    "# y = w * 2\n",
    "y = w * 2\n",
    "\n",
    "print(f\"WartoÅ›Ä‡ y przed zmianÄ…: {y}\")\n",
    "\n",
    "# Krok 2: Operacja In-Place na 'w' (PSUCIE DANYCH!)\n",
    "# UÅ¼ywamy no_grad(), Å¼eby zmusiÄ‡ PyTorch do wykonania operacji na LiÅ›ciu.\n",
    "# To symuluje np. aktualizacjÄ™ wag przez optymalizator w zÅ‚ym momencie.\n",
    "with torch.no_grad():\n",
    "    w *= 100 \n",
    "\n",
    "print(f\"WartoÅ›Ä‡ w (zmieniona): {w}\")\n",
    "\n",
    "# Krok 3: Backward\n",
    "# Teraz PyTorch sprÃ³buje policzyÄ‡ pochodnÄ….\n",
    "# Powinien zauwaÅ¼yÄ‡, Å¼e 'w' (ktÃ³re byÅ‚o potrzebne do obliczeÅ„) zmieniÅ‚o siÄ™ pod jego nosem.\n",
    "try:\n",
    "    y.backward()\n",
    "except RuntimeError as e:\n",
    "    print(\"\\nğŸš« ZÅAPANO BÅÄ„D AUTOGRADU:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1efade",
   "metadata": {},
   "source": [
    "## Bezpieczne In-Place (ReLU)\n",
    "\n",
    "SÄ… operacje, ktÃ³re **moÅ¼na** robiÄ‡ In-Place.\n",
    "Klasycznym przykÅ‚adem jest `ReLU`.\n",
    "$$ f(x) = \\max(0, x) $$\n",
    "\n",
    "Pochodna ReLU zaleÅ¼y od tego, czy $x > 0$.\n",
    "MoÅ¼emy nadpisaÄ‡ $x$ wynikiem, bo informacja o znaku (czy byÅ‚o > 0) jest zachowana w wyniku (jeÅ›li wynik > 0, to wejÅ›cie teÅ¼ byÅ‚o > 0).\n",
    "Dlatego `nn.ReLU(inplace=True)` jest bezpieczne i zalecane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d19aedc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wynik po ReLU: tensor([0., 2.], grad_fn=<ReluBackward0>)\n",
      "âœ… ReLU in-place przeszÅ‚o backward!\n",
      "Gradient x: tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "# 1. Dane wejÅ›ciowe (Leaf)\n",
    "x = torch.tensor([-5.0, 2.0], requires_grad=True)\n",
    "\n",
    "# 2. Symulacja warstwy (Operacja poÅ›rednia)\n",
    "# Klonujemy x. Teraz 'h' to nie jest liÅ›Ä‡, to jest \"wynik operacji clone\".\n",
    "# Na wynikach operacji MOÅ»NA robiÄ‡ in-place!\n",
    "h = x.clone()\n",
    "\n",
    "# 3. Bezpieczne In-Place (ReLU) na zmiennej poÅ›redniej\n",
    "# Modyfikujemy 'h' bezpoÅ›rednio w pamiÄ™ci\n",
    "torch.relu_(h) \n",
    "\n",
    "print(f\"Wynik po ReLU: {h}\")\n",
    "\n",
    "# 4. Backward\n",
    "try:\n",
    "    h.sum().backward()\n",
    "    print(\"âœ… ReLU in-place przeszÅ‚o backward!\")\n",
    "except Exception as e:\n",
    "    print(f\"BÅ‚Ä…d: {e}\")\n",
    "\n",
    "# SprawdÅºmy gradient na oryginale\n",
    "# Dla -5.0 gradient powinien byÄ‡ 0.\n",
    "# Dla 2.0 gradient powinien byÄ‡ 1.\n",
    "print(f\"Gradient x: {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f755df7",
   "metadata": {},
   "source": [
    "## ğŸ¥‹ Black Belt Summary\n",
    "\n",
    "1.  **Dla optymalizacji:** UÅ¼ywaj `+=`, `*=`, `add_()`, `scatter_()` tam, gdzie **nie potrzebujesz gradientÃ³w** (np. przy aktualizacji wag w optymalizatorze `w -= lr * grad`).\n",
    "2.  **Dla bezpieczeÅ„stwa:** Unikaj In-Place na tensorach, ktÃ³re sÄ… czÄ™Å›ciÄ… grafu obliczeniowego (miÄ™dzy wejÅ›ciem a Loss), chyba Å¼e wiesz, co robisz (np. ReLU).\n",
    "3.  **Debugowanie:** JeÅ›li widzisz bÅ‚Ä…d `modified by an inplace operation`, zamieÅ„ `x += y` na `x = x + y`. To zazwyczaj naprawia problem (kosztem pamiÄ™ci)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
