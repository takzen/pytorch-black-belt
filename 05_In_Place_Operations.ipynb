{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n<a href=\"https://colab.research.google.com/github/takzen/pytorch-black-belt/blob/main/05_In_Place_Operations.ipynb\" target=\"_parent\">\n    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# \u2601\ufe0f COLAB SETUP (Automatyczna instalacja \u015brodowiska)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Sprawdzamy, czy jeste\u015bmy w Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('\u2601\ufe0f Wykryto \u015brodowisko Google Colab. Konfiguruj\u0119...')\n",
    "\n",
    "    # 1. Pobieramy plik requirements.txt bezpo\u015brednio z repozytorium\n",
    "    !wget -q https://raw.githubusercontent.com/takzen/ai-engineering-handbook/main/requirements.txt -O requirements.txt\n",
    "\n",
    "    # 2. Instalujemy biblioteki\n",
    "    print('\u23f3 Instaluj\u0119 zale\u017cno\u015bci (to mo\u017ce chwil\u0119 potrwa\u0107)...')\n",
    "    !pip install -q -r requirements.txt\n",
    "\n",
    "    print('\u2705 Gotowe! \u015arodowisko jest zgodne z repozytorium.')\n",
    "else:\n",
    "    print('\ud83d\udcbb Wykryto \u015brodowisko lokalne. Zak\u0142adam, \u017ce masz ju\u017c uv/venv.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ece28b",
   "metadata": {},
   "source": [
    "# \ud83e\udd4b Lekcja 5: In-Place Operations (Oszcz\u0119dno\u015b\u0107 vs Ryzyko)\n",
    "\n",
    "W PyTorch operacje zako\u0144czone podkre\u015blnikiem `_` (np. `add_`, `scatter_`, `relu_`) lub operatory przypisania (`+=`, `*=`) dzia\u0142aj\u0105 **In-Place**.\n",
    "\n",
    "**Zaleta:** Nie alokuj\u0105 nowej pami\u0119ci. Dzia\u0142aj\u0105 na istniej\u0105cym buforze.\n",
    "**Wada:** Nadpisuj\u0105 dane, kt\u00f3re mog\u0105 by\u0107 potrzebne do obliczenia gradientu.\n",
    "\n",
    "Je\u015bli nadpiszesz tensor, kt\u00f3ry by\u0142 potrzebny do `backward()`, PyTorch wykryje to i rzuci s\u0142ynnym b\u0142\u0119dem:\n",
    "`RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation`.\n",
    "\n",
    "W tej lekcji nauczymy si\u0119, kiedy mo\u017cna, a kiedy nie wolno tego robi\u0107."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f189f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startowy adres: 5292439961600\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Funkcja do sprawdzania adresu pami\u0119ci\n",
    "def check_memory(name, old_ptr, tensor):\n",
    "    new_ptr = tensor.untyped_storage().data_ptr()\n",
    "    if old_ptr == new_ptr:\n",
    "        print(f\"\u2705 {name}: Adres BEZ ZMIAN (In-Place). Oszcz\u0119dzamy pami\u0119\u0107.\")\n",
    "    else:\n",
    "        print(f\"\u274c {name}: Nowy adres (Out-of-Place). Alokacja pami\u0119ci.\")\n",
    "    return new_ptr\n",
    "\n",
    "# Baza\n",
    "t = torch.ones(1000, 1000)\n",
    "ptr = t.untyped_storage().data_ptr()\n",
    "print(f\"Startowy adres: {ptr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ed244b",
   "metadata": {},
   "source": [
    "## Test Pami\u0119ci: `x = x + 1` vs `x += 1`\n",
    "\n",
    "Sprawd\u017amy, co dzieje si\u0119 w pami\u0119ci RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dfcb85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u274c x = x + 1: Nowy adres (Out-of-Place). Alokacja pami\u0119ci.\n",
      "\u2705 x += 1: Adres BEZ ZMIAN (In-Place). Oszcz\u0119dzamy pami\u0119\u0107.\n",
      "\u2705 x.add_(1): Adres BEZ ZMIAN (In-Place). Oszcz\u0119dzamy pami\u0119\u0107.\n",
      "\u274c x.add(1): Nowy adres (Out-of-Place). Alokacja pami\u0119ci.\n"
     ]
    }
   ],
   "source": [
    "# 1. Out-of-place (Standard)\n",
    "t = t + 1\n",
    "ptr = check_memory(\"x = x + 1\", ptr, t)\n",
    "\n",
    "# 2. In-place (Pythonowy operator)\n",
    "t += 1\n",
    "ptr = check_memory(\"x += 1\", ptr, t)\n",
    "\n",
    "# 3. In-place (Metoda PyTorch z _)\n",
    "t.add_(1)\n",
    "ptr = check_memory(\"x.add_(1)\", ptr, t)\n",
    "\n",
    "# 4. Out-of-place (Metoda PyTorch bez _)\n",
    "t = t.add(1)\n",
    "ptr = check_memory(\"x.add(1)\", ptr, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a169b6",
   "metadata": {},
   "source": [
    "## The Dark Side: Autograd i Version Counter\n",
    "\n",
    "Ka\u017cdy tensor w PyTorch ma licznik wersji (`_version`).\n",
    "*   Przy ka\u017cdej operacji In-Place licznik ro\u015bnie.\n",
    "*   Autograd zapisuje sobie: \"Potrzebuj\u0119 tensora X w wersji 0, \u017ceby policzy\u0107 pochodn\u0105\".\n",
    "*   Je\u015bli przy `backward()` oka\u017ce si\u0119, \u017ce tensor X ma teraz wersj\u0119 1 (bo go nadpisa\u0142e\u015b), PyTorch rzuca b\u0142\u0119dem, zamiast liczy\u0107 g\u0142upoty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96629d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warto\u015b\u0107 y przed zmian\u0105: tensor([10.], grad_fn=<MulBackward0>)\n",
      "Warto\u015b\u0107 w (zmieniona): tensor([500.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Symulacja b\u0142\u0119du w treningu\n",
    "\n",
    "# Wagi (wymagaj\u0105 gradientu) - to jest \"Leaf Variable\"\n",
    "w = torch.tensor([5.0], requires_grad=True)\n",
    "\n",
    "# Krok 1: Forward\n",
    "# y = w * 2\n",
    "y = w * 2\n",
    "\n",
    "print(f\"Warto\u015b\u0107 y przed zmian\u0105: {y}\")\n",
    "\n",
    "# Krok 2: Operacja In-Place na 'w' (PSUCIE DANYCH!)\n",
    "# U\u017cywamy no_grad(), \u017ceby zmusi\u0107 PyTorch do wykonania operacji na Li\u015bciu.\n",
    "# To symuluje np. aktualizacj\u0119 wag przez optymalizator w z\u0142ym momencie.\n",
    "with torch.no_grad():\n",
    "    w *= 100 \n",
    "\n",
    "print(f\"Warto\u015b\u0107 w (zmieniona): {w}\")\n",
    "\n",
    "# Krok 3: Backward\n",
    "# Teraz PyTorch spr\u00f3buje policzy\u0107 pochodn\u0105.\n",
    "# Powinien zauwa\u017cy\u0107, \u017ce 'w' (kt\u00f3re by\u0142o potrzebne do oblicze\u0144) zmieni\u0142o si\u0119 pod jego nosem.\n",
    "try:\n",
    "    y.backward()\n",
    "except RuntimeError as e:\n",
    "    print(\"\\n\ud83d\udeab Z\u0141APANO B\u0141\u0104D AUTOGRADU:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1efade",
   "metadata": {},
   "source": [
    "## Bezpieczne In-Place (ReLU)\n",
    "\n",
    "S\u0105 operacje, kt\u00f3re **mo\u017cna** robi\u0107 In-Place.\n",
    "Klasycznym przyk\u0142adem jest `ReLU`.\n",
    "$$ f(x) = \\max(0, x) $$\n",
    "\n",
    "Pochodna ReLU zale\u017cy od tego, czy $x > 0$.\n",
    "Mo\u017cemy nadpisa\u0107 $x$ wynikiem, bo informacja o znaku (czy by\u0142o > 0) jest zachowana w wyniku (je\u015bli wynik > 0, to wej\u015bcie te\u017c by\u0142o > 0).\n",
    "Dlatego `nn.ReLU(inplace=True)` jest bezpieczne i zalecane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d19aedc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wynik po ReLU: tensor([0., 2.], grad_fn=<ReluBackward0>)\n",
      "\u2705 ReLU in-place przesz\u0142o backward!\n",
      "Gradient x: tensor([0., 1.])\n"
     ]
    }
   ],
   "source": [
    "# 1. Dane wej\u015bciowe (Leaf)\n",
    "x = torch.tensor([-5.0, 2.0], requires_grad=True)\n",
    "\n",
    "# 2. Symulacja warstwy (Operacja po\u015brednia)\n",
    "# Klonujemy x. Teraz 'h' to nie jest li\u015b\u0107, to jest \"wynik operacji clone\".\n",
    "# Na wynikach operacji MO\u017bNA robi\u0107 in-place!\n",
    "h = x.clone()\n",
    "\n",
    "# 3. Bezpieczne In-Place (ReLU) na zmiennej po\u015bredniej\n",
    "# Modyfikujemy 'h' bezpo\u015brednio w pami\u0119ci\n",
    "torch.relu_(h) \n",
    "\n",
    "print(f\"Wynik po ReLU: {h}\")\n",
    "\n",
    "# 4. Backward\n",
    "try:\n",
    "    h.sum().backward()\n",
    "    print(\"\u2705 ReLU in-place przesz\u0142o backward!\")\n",
    "except Exception as e:\n",
    "    print(f\"B\u0142\u0105d: {e}\")\n",
    "\n",
    "# Sprawd\u017amy gradient na oryginale\n",
    "# Dla -5.0 gradient powinien by\u0107 0.\n",
    "# Dla 2.0 gradient powinien by\u0107 1.\n",
    "print(f\"Gradient x: {x.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f755df7",
   "metadata": {},
   "source": [
    "## \ud83e\udd4b Black Belt Summary\n",
    "\n",
    "1.  **Dla optymalizacji:** U\u017cywaj `+=`, `*=`, `add_()`, `scatter_()` tam, gdzie **nie potrzebujesz gradient\u00f3w** (np. przy aktualizacji wag w optymalizatorze `w -= lr * grad`).\n",
    "2.  **Dla bezpiecze\u0144stwa:** Unikaj In-Place na tensorach, kt\u00f3re s\u0105 cz\u0119\u015bci\u0105 grafu obliczeniowego (mi\u0119dzy wej\u015bciem a Loss), chyba \u017ce wiesz, co robisz (np. ReLU).\n",
    "3.  **Debugowanie:** Je\u015bli widzisz b\u0142\u0105d `modified by an inplace operation`, zamie\u0144 `x += y` na `x = x + y`. To zazwyczaj naprawia problem (kosztem pami\u0119ci)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}