{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "874b3bda",
   "metadata": {},
   "source": [
    "# ðŸ¥‹ Lekcja 44: FSDP (Jak trenowaÄ‡ giganty?)\n",
    "\n",
    "W DDP pamiÄ™Ä‡ jest ograniczona przez najsÅ‚abszÄ… kartÄ™.\n",
    "W FSDP pamiÄ™Ä‡ to **suma VRAM wszystkich kart**.\n",
    "\n",
    "**Koncepcja ZeRO (Zero Redundancy Optimizer):**\n",
    "Standardowy trening (Adam) zuÅ¼ywa pamiÄ™Ä‡ na:\n",
    "1.  **Parametry (Wagi):** fp32 (4 bajty).\n",
    "2.  **Gradienty:** fp32 (4 bajty).\n",
    "3.  **Stan Optymalizatora (Momentum + Variance):** fp32 (8 bajtÃ³w).\n",
    "\n",
    "Razem: **16 bajtÃ³w na jeden parametr**.\n",
    "Model 1B parametrÃ³w wymaga **16 GB VRAM** (tylko na \"statykÄ™\", bez aktywacji!).\n",
    "\n",
    "**RozwiÄ…zanie FSDP:**\n",
    "Podzielmy te 16GB na 8 kart graficznych. KaÅ¼da trzyma tylko 2GB.\n",
    "Kiedy potrzebujemy wag do obliczeÅ„, robimy **All-Gather** (pobieramy resztÄ™), a po obliczeniach natychmiast je kasujemy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d8184b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba parametrÃ³w: 104,960,000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Symulacja wielkiego modelu (Transformer)\n",
    "# 100 milionÃ³w parametrÃ³w to maÅ‚o dla LLM, ale duÅ¼o dla laptopa\n",
    "class BigTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 12 warstw, model dimension 1024\n",
    "        self.layers = nn.Sequential(*[\n",
    "            nn.Linear(1024, 4096) for _ in range(25) # DuÅ¼o duÅ¼ych warstw\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model = BigTransformer()\n",
    "\n",
    "# Liczymy parametry\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Liczba parametrÃ³w: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab8ada4",
   "metadata": {},
   "source": [
    "## Kalkulator PamiÄ™ci VRAM\n",
    "\n",
    "Zanim kupisz karty graficzne, musisz umieÄ‡ policzyÄ‡, czy model siÄ™ zmieÅ›ci.\n",
    "Napiszmy funkcjÄ™ inÅ¼ynierskÄ…, ktÃ³ra to szacuje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c7e817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SZACUNEK PAMIÄ˜CI (Dla modelu 100M) ---\n",
      "1 GPU (DDP):    1.56 GB VRAM\n",
      "4 GPU (DDP):    1.56 GB VRAM (Brak zysku pamiÄ™ci!)\n",
      "4 GPU (FSDP):   0.39 GB VRAM (Zysk!)\n",
      "\n",
      "--- GPT-3 (175B) ---\n",
      "Wymagane VRAM (1 GPU): 2607.70 GB\n",
      "Å»adna karta tyle nie ma (A100 ma 80GB).\n",
      "Wymagane na kartÄ™ przy 64 GPU (FSDP): 40.75 GB (To siÄ™ zmieÅ›ci!)\n"
     ]
    }
   ],
   "source": [
    "def estimate_memory(params_count, num_gpus=1, use_fsdp=False):\n",
    "    # 1. Wagi (FP32) - 4 bajty\n",
    "    weights_mem = params_count * 4\n",
    "    \n",
    "    # 2. Gradienty (FP32) - 4 bajty\n",
    "    grads_mem = params_count * 4\n",
    "    \n",
    "    # 3. Optimizer (Adam trzyma 2 stany: momentum i variance) - 8 bajtÃ³w\n",
    "    opt_mem = params_count * 8\n",
    "    \n",
    "    total_mem = weights_mem + grads_mem + opt_mem\n",
    "    \n",
    "    if use_fsdp:\n",
    "        # FSDP dzieli to wszystko przez liczbÄ™ GPU!\n",
    "        # (Teoretycznie idealne skalowanie)\n",
    "        total_mem /= num_gpus\n",
    "        \n",
    "    # Konwersja na GB\n",
    "    return total_mem / (1024**3)\n",
    "\n",
    "print(\"--- SZACUNEK PAMIÄ˜CI (Dla modelu 100M) ---\")\n",
    "print(f\"1 GPU (DDP):    {estimate_memory(total_params, 1):.2f} GB VRAM\")\n",
    "print(f\"4 GPU (DDP):    {estimate_memory(total_params, 4, use_fsdp=False):.2f} GB VRAM (Brak zysku pamiÄ™ci!)\")\n",
    "print(f\"4 GPU (FSDP):   {estimate_memory(total_params, 4, use_fsdp=True):.2f} GB VRAM (Zysk!)\")\n",
    "\n",
    "# A co z modelem GPT-3 (175 miliardÃ³w parametrÃ³w)?\n",
    "gpt3_params = 175_000_000_000\n",
    "print(f\"\\n--- GPT-3 (175B) ---\")\n",
    "print(f\"Wymagane VRAM (1 GPU): {estimate_memory(gpt3_params, 1):.2f} GB\")\n",
    "print(\"Å»adna karta tyle nie ma (A100 ma 80GB).\")\n",
    "print(f\"Wymagane na kartÄ™ przy 64 GPU (FSDP): {estimate_memory(gpt3_params, 64, True):.2f} GB (To siÄ™ zmieÅ›ci!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71a8223",
   "metadata": {},
   "source": [
    "## SkÅ‚adnia FSDP (Wrapper)\n",
    "\n",
    "W PyTorch FSDP dziaÅ‚a podobnie do DDP â€“ owijamy model klasÄ….\n",
    "Ale jest haczyk: **`auto_wrap_policy`**.\n",
    "\n",
    "Nie chcemy shardingowaÄ‡ byle jak (np. przeciÄ…Ä‡ pojedynczy neuron na pÃ³Å‚).\n",
    "Chcemy shardingowaÄ‡ caÅ‚e bloki Transformera.\n",
    "Policy mÃ³wi: *\"JeÅ›li warstwa ma wiÄ™cej niÅ¼ 10mln parametrÃ³w, potnij jÄ… i rozdziel na GPU\"*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a9dd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kod FSDP gotowy (do uÅ¼ycia w skrypcie torchrun).\n"
     ]
    }
   ],
   "source": [
    "# To jest kod poglÄ…dowy (wymaga Å›rodowiska rozproszonego do uruchomienia)\n",
    "from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n",
    "from torch.distributed.fsdp.wrap import size_based_auto_wrap_policy\n",
    "\n",
    "def fsdp_wrapper_example(model):\n",
    "    # Polityka: Owijaj (tnij) warstwy wiÄ™ksze niÅ¼ 10 milionÃ³w parametrÃ³w\n",
    "    my_policy = lambda module, recurse, **kwargs: size_based_auto_wrap_policy(\n",
    "        module, recurse, min_num_params=10_000_000, **kwargs\n",
    "    )\n",
    "    \n",
    "    # Owijanie (na CPU przed wysÅ‚aniem na GPU, Å¼eby oszczÄ™dziÄ‡ pamiÄ™Ä‡ przy starcie!)\n",
    "    sharded_model = FSDP(\n",
    "        model,\n",
    "        auto_wrap_policy=my_policy,\n",
    "        cpu_offload=None # MoÅ¼na ustawiÄ‡ na True, Å¼eby zrzuciÄ‡ wagi do RAMu zwykÅ‚ego!\n",
    "    )\n",
    "    \n",
    "    return sharded_model\n",
    "\n",
    "print(\"Kod FSDP gotowy (do uÅ¼ycia w skrypcie torchrun).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d915cf6e",
   "metadata": {},
   "source": [
    "## CPU Offloading (Ostatnia deska ratunku)\n",
    "\n",
    "Co jeÅ›li FSDP na 8 kartach to wciÄ…Å¼ za maÅ‚o?\n",
    "FSDP ma asa w rÄ™kawie: **CPU Offload**.\n",
    "\n",
    "Wagi leÅ¼Ä… w tanim RAM-ie komputera (CPU).\n",
    "SÄ… przesyÅ‚ane na GPU tylko w momencie, gdy sÄ… potrzebne do obliczeÅ„ (Forward/Backward), a potem natychmiast wracajÄ… do RAM.\n",
    "*   **Zaleta:** MoÅ¼esz trenowaÄ‡ gigantyczne modele na sÅ‚abych kartach.\n",
    "*   **Wada:** Jest to wolne (wÄ…skim gardÅ‚em jest szyna PCIe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22a100f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Offload skonfigurowany: Wagi bÄ™dÄ… Å¼yÅ‚y w RAMie, odwiedzajÄ…c GPU tylko na chwilÄ™.\n"
     ]
    }
   ],
   "source": [
    "from torch.distributed.fsdp import CPUOffload\n",
    "\n",
    "# WÅ‚Ä…czenie tej flagi pozwala trenowaÄ‡ modele wiÄ™ksze niÅ¼ VRAM\n",
    "offload = CPUOffload(offload_params=True)\n",
    "\n",
    "print(\"CPU Offload skonfigurowany: Wagi bÄ™dÄ… Å¼yÅ‚y w RAMie, odwiedzajÄ…c GPU tylko na chwilÄ™.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fdfdec",
   "metadata": {},
   "source": [
    "## ðŸ¥‹ Black Belt Summary\n",
    "\n",
    "1.  **DDP vs FSDP:**\n",
    "    *   **DDP:** Szybkie, ale kaÅ¼dy GPU musi pomieÅ›ciÄ‡ caÅ‚y model. (Dobre do ResNet50).\n",
    "    *   **FSDP:** Wolniejsze (duÅ¼o komunikacji sieciowej), ale pozwala trenowaÄ‡ modele wiÄ™ksze niÅ¼ pamiÄ™Ä‡ GPU. (Konieczne do LLM).\n",
    "2.  **ZeRO Stages (Odpowiedniki w DeepSpeed):**\n",
    "    *   Stage 1: Sharding Stanu Optymalizatora (NajwiÄ™kszy zysk, maÅ‚y narzut).\n",
    "    *   Stage 2: Sharding GradientÃ³w.\n",
    "    *   Stage 3: Sharding ParametrÃ³w (PeÅ‚ne FSDP).\n",
    "3.  **Koszty:** FSDP wymaga szybkiej sieci miÄ™dzy kartami (NVLink), inaczej karty bÄ™dÄ… czekaÄ‡ na przesyÅ‚anie kawaÅ‚kÃ³w modelu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
