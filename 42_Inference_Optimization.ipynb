{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acf4a1a1",
   "metadata": {},
   "source": [
    "# ü•ã Lekcja 42: Inference Optimization (Fuzja Conv + BN)\n",
    "\n",
    "Wiƒôkszo≈õƒá architektur (ResNet, YOLO) sk≈Çada siƒô z blok√≥w: `Conv -> BN -> ReLU`.\n",
    "Na produkcji `BN` jest zbƒôdnym narzutem obliczeniowym.\n",
    "\n",
    "**Matematyka:**\n",
    "1.  Konwolucja: $y = Wx + b$\n",
    "2.  Batch Norm: $z = \\frac{y - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\cdot \\gamma + \\beta$\n",
    "\n",
    "Mo≈ºemy to przekszta≈Çciƒá w **jednƒÖ nowƒÖ Konwolucjƒô**:\n",
    "$$ z = W_{new}x + b_{new} $$\n",
    "\n",
    "Gdzie:\n",
    "$$ W_{new} = W \\cdot \\frac{\\gamma}{\\sqrt{\\sigma^2 + \\epsilon}} $$\n",
    "$$ b_{new} = (b - \\mu) \\cdot \\frac{\\gamma}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta $$\n",
    "\n",
    "W tej lekcji napiszemy funkcjƒô, kt√≥ra \"po≈Çyka\" Batchnorma i wypluwa zoptymalizowanƒÖ warstwƒô Conv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff93e6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model oryginalny:\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import time\n",
    "\n",
    "# Konfiguracja\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 1. TWORZYMY MODEL \"NIEZOPTYMALIZOWANY\"\n",
    "# Conv + BN to standardowy blok\n",
    "model_orig = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(inplace=True)\n",
    ").to(DEVICE)\n",
    "\n",
    "# Musimy prze≈ÇƒÖczyƒá w tryb eval(), ≈ºeby BN u≈ºywa≈Ç zapisanych statystyk (running_mean/var),\n",
    "# a nie liczy≈Ç ich z batcha. Fuzja dzia≈Ça tylko w eval!\n",
    "model_orig.eval()\n",
    "\n",
    "print(\"Model oryginalny:\")\n",
    "print(model_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e85763",
   "metadata": {},
   "source": [
    "## Rƒôczna Implementacja Fuzji\n",
    "\n",
    "To jest kod \"Black Belt\". WyciƒÖgamy wagi z obu warstw i tworzymy nowe wagi metodƒÖ algebraicznƒÖ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3311eb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model po fuzji (ZniknƒÖ≈Ç BatchNorm!):\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def fuse_conv_bn(conv, bn):\n",
    "    \"\"\"\n",
    "    ≈ÅƒÖczy wagi Conv2d i BatchNorm2d w jednƒÖ warstwƒô Conv2d.\n",
    "    \"\"\"\n",
    "    # 1. Pobieramy parametry\n",
    "    with torch.no_grad():\n",
    "        # Wagi konwolucji\n",
    "        w_conv = conv.weight.clone()\n",
    "        # Bias konwolucji (mo≈ºe byƒá None)\n",
    "        b_conv = conv.bias.clone() if conv.bias is not None else torch.zeros_like(bn.running_mean)\n",
    "        \n",
    "        # Parametry BN\n",
    "        mean = bn.running_mean\n",
    "        var_sqrt = torch.sqrt(bn.running_var + bn.eps)\n",
    "        gamma = bn.weight # scale\n",
    "        beta = bn.bias    # shift\n",
    "        \n",
    "        # 2. Obliczamy nowe wagi (W_new)\n",
    "        # Musimy dopasowaƒá wymiary do mno≈ºenia (C_out, 1, 1, 1)\n",
    "        scale_factor = gamma / var_sqrt\n",
    "        w_new = w_conv * scale_factor.view(-1, 1, 1, 1)\n",
    "        \n",
    "        # 3. Obliczamy nowy bias (b_new)\n",
    "        b_new = (b_conv - mean) * scale_factor + beta\n",
    "        \n",
    "        # 4. Tworzymy nowƒÖ warstwƒô\n",
    "        fused_conv = nn.Conv2d(\n",
    "            in_channels=conv.in_channels,\n",
    "            out_channels=conv.out_channels,\n",
    "            kernel_size=conv.kernel_size,\n",
    "            stride=conv.stride,\n",
    "            padding=conv.padding,\n",
    "            bias=True # Teraz bias jest obowiƒÖzkowy (nawet jak wcze≈õniej go nie by≈Ço)\n",
    "        )\n",
    "        \n",
    "        # Wgrywamy obliczone parametry\n",
    "        fused_conv.weight.copy_(w_new)\n",
    "        fused_conv.bias.copy_(b_new)\n",
    "        \n",
    "        return fused_conv\n",
    "\n",
    "# Zastosujmy to\n",
    "fused_conv_layer = fuse_conv_bn(model_orig[0], model_orig[1])\n",
    "\n",
    "# Budujemy nowy model (bez BN!)\n",
    "model_fused = nn.Sequential(\n",
    "    fused_conv_layer,\n",
    "    model_orig[2] # ReLU zostaje\n",
    ").to(DEVICE)\n",
    "\n",
    "model_fused.eval()\n",
    "\n",
    "print(\"\\nModel po fuzji (ZniknƒÖ≈Ç BatchNorm!):\")\n",
    "print(model_fused)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6041f126",
   "metadata": {},
   "source": [
    "## Weryfikacja Numeryczna\n",
    "\n",
    "Czy matematyka nie k≈Çamie? Sprawd≈∫my, czy dla tego samego wej≈õcia oba modele dajƒÖ **identyczny** wynik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a445751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maksymalna r√≥≈ºnica w wynikach: 0.00000119\n",
      "‚úÖ SUKCES! Modele sƒÖ matematycznie r√≥wnowa≈ºne.\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 224, 224).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_orig = model_orig(x)\n",
    "    out_fused = model_fused(x)\n",
    "\n",
    "# Sprawdzamy r√≥≈ºnicƒô\n",
    "diff = (out_orig - out_fused).abs().max().item()\n",
    "\n",
    "print(f\"Maksymalna r√≥≈ºnica w wynikach: {diff:.8f}\")\n",
    "\n",
    "if diff < 1e-5:\n",
    "    print(\"‚úÖ SUKCES! Modele sƒÖ matematycznie r√≥wnowa≈ºne.\")\n",
    "else:\n",
    "    print(\"‚ùå CO≈ö POSZ≈ÅO NIE TAK. R√≥≈ºnica jest zbyt du≈ºa.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ac3dc",
   "metadata": {},
   "source": [
    "## Benchmark: Ile zyskali≈õmy?\n",
    "\n",
    "W ma≈Çym modelu r√≥≈ºnica mo≈ºe byƒá znikoma (narzut Pythona). Ale w du≈ºym ResNet, gdzie takich blok√≥w jest 50, zyskujemy brak 50 operacji odczytu/zapisu pamiƒôci dla BN.\n",
    "\n",
    "*Uwaga: Na ma≈Çym tensorze i w Pythonie narzut pƒôtli pomiarowej mo≈ºe ukryƒá zysk, ale na poziomie CUDA kernel to jest czysty zysk.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60828e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orygina≈Ç (Conv+BN): 0.7202 s\n",
      "Fused (Conv):       0.4779 s\n",
      "üöÄ Przyspieszenie: 1.51x\n"
     ]
    }
   ],
   "source": [
    "# BENCHMARK\n",
    "# Musimy zrobiƒá du≈ºo powt√≥rze≈Ñ, ≈ºeby zobaczyƒá r√≥≈ºnicƒô (mikrosekundy)\n",
    "iters = 5000\n",
    "\n",
    "# 1. Warmup (Rozgrzewka GPU)\n",
    "for _ in range(100):\n",
    "    _ = model_orig(x)\n",
    "    _ = model_fused(x)\n",
    "\n",
    "torch.cuda.synchronize() if DEVICE == \"cuda\" else None\n",
    "\n",
    "# 2. Pomiar Orygina≈Çu\n",
    "start = time.time()\n",
    "for _ in range(iters):\n",
    "    _ = model_orig(x)\n",
    "torch.cuda.synchronize() if DEVICE == \"cuda\" else None\n",
    "end = time.time()\n",
    "time_orig = end - start\n",
    "\n",
    "# 3. Pomiar Zoptymalizowanego\n",
    "start = time.time()\n",
    "for _ in range(iters):\n",
    "    _ = model_fused(x)\n",
    "torch.cuda.synchronize() if DEVICE == \"cuda\" else None\n",
    "end = time.time()\n",
    "time_fused = end - start\n",
    "\n",
    "print(f\"Orygina≈Ç (Conv+BN): {time_orig:.4f} s\")\n",
    "print(f\"Fused (Conv):       {time_fused:.4f} s\")\n",
    "print(f\"üöÄ Przyspieszenie: {time_orig / time_fused:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4295c324",
   "metadata": {},
   "source": [
    "## ü•ã Black Belt Summary\n",
    "\n",
    "1.  **Dlaczego warto?**\n",
    "    *   **Mniej operacji:** Usuwamy BN z grafu obliczeniowego.\n",
    "    *   **Mniej pamiƒôci:** Nie musimy wczytywaƒá parametr√≥w BN (≈õrednia, wariancja, gamma, beta) z VRAM.\n",
    "    *   **Mniejszy plik:** Model zajmuje mniej miejsca na dysku.\n",
    "2.  **Kiedy to robiƒá?**\n",
    "    *   **Zawsze** przed eksportem do ONNX lub deploymentem na urzƒÖdzenia mobilne.\n",
    "    *   W PyTorch Lightning i bibliotece `torchvision` sƒÖ czƒôsto gotowe funkcje (np. `torch.nn.utils.fuse_conv_bn_eval`), ale teraz wiesz, jak dzia≈ÇajƒÖ matematycznie.\n",
    "3.  **Wym√≥g:** Model musi byƒá w trybie `.eval()`. Fuzja podczas treningu (`.train()`) jest niemo≈ºliwa, bo BN musi wtedy dynamicznie aktualizowaƒá statystyki."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
