{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bd300fb",
   "metadata": {},
   "source": [
    "# ðŸ¥‹ Lekcja 31: Mixed Precision (AMP) & GradScaler\n",
    "\n",
    "Standardowo PyTorch uÅ¼ywa `float32` (4 bajty na liczbÄ™).\n",
    "Karty NVIDIA (Volta, Turing, Ampere) majÄ… **Tensor Cores**, ktÃ³re liczÄ… macierze w `float16` (2 bajty) niesamowicie szybko.\n",
    "\n",
    "**Problem z FP16:**\n",
    "Zakres liczb jest maÅ‚y.\n",
    "*   Najmniejsza liczba dodatnia w FP16 to ok. `6e-5`.\n",
    "*   Gradienty w sieciach czÄ™sto sÄ… rzÄ™du `1e-7`. W FP16 stajÄ… siÄ™ zerem (**Underflow**). SieÄ‡ przestaje siÄ™ uczyÄ‡.\n",
    "\n",
    "**RozwiÄ…zanie (AMP Pipeline):**\n",
    "1.  **Autocast:** PyTorch automatycznie decyduje, ktÃ³re operacje (Conv, MatMul) zrobiÄ‡ w FP16 (szybkie), a ktÃ³re (Softmax, Sum) zostawiÄ‡ w FP32 (stabilne).\n",
    "2.  **GradScaler:** MnoÅ¼y Loss przez duÅ¼Ä… liczbÄ™ (np. 65536), Å¼eby \"nadmuchaÄ‡\" maÅ‚e gradienty, by nie zniknÄ™Å‚y w FP16. Przed aktualizacjÄ… wag dzieli je z powrotem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7caa2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GPU: NVIDIA GeForce RTX 4060\n",
      "Liczba w FP32: 0.00001000\n",
      "Liczba w FP16: 0.00001001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# SprawdÅºmy sprzÄ™t\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(f\"âœ… GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"âš ï¸ Brak GPU. AMP zadziaÅ‚a (bfloat16 na CPU), ale zysk bÄ™dzie mniejszy.\")\n",
    "\n",
    "# Symulacja problemu Underflow\n",
    "small_grad = torch.tensor(1e-5, dtype=torch.float32)\n",
    "print(f\"Liczba w FP32: {small_grad.item():.8f}\")\n",
    "print(f\"Liczba w FP16: {small_grad.half().item():.8f}\") \n",
    "# 1e-5 w FP16 jest bezpieczne, ale 1e-8 staÅ‚oby siÄ™ zerem!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c7daa4",
   "metadata": {},
   "source": [
    "## Wzorzec Projektowy AMP\n",
    "\n",
    "Kod treningowy zmienia siÄ™ minimalnie.\n",
    "Zamiast:\n",
    "```python\n",
    "loss = criterion(model(x), y)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "```\n",
    "Robimy:\n",
    "```python\n",
    "with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "    loss = criterion(model(x), y)\n",
    "\n",
    "scaler.scale(loss).backward() # Skalowanie + Backward\n",
    "scaler.step(optimizer)        # Odskalowanie + Update\n",
    "scaler.update()               # Aktualizacja wspÃ³Å‚czynnika skali\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e859f033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup gotowy. Skaler zainicjowany (Nowe API bez ostrzeÅ¼eÅ„).\n"
     ]
    }
   ],
   "source": [
    "# Prosty model, ale z duÅ¼ymi macierzami, Å¼eby poczuÄ‡ rÃ³Å¼nicÄ™ w pamiÄ™ci\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4096, 4096)\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Inicjalizacja Skalera (Nowoczesne API PyTorch 2.x)\n",
    "# Zamiast torch.cuda.amp.GradScaler, uÅ¼ywamy torch.amp.GradScaler\n",
    "# Pierwszy argument to typ urzÄ…dzenia ('cuda').\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=(device == \"cuda\"))\n",
    "\n",
    "# Dane\n",
    "data = torch.randn(64, 4096, device=device)\n",
    "target = torch.randn(64, 4096, device=device)\n",
    "\n",
    "print(\"Setup gotowy. Skaler zainicjowany (Nowe API bez ostrzeÅ¼eÅ„).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21becd6e",
   "metadata": {},
   "source": [
    "## PÄ™tla Treningowa z AMP\n",
    "\n",
    "ZwrÃ³Ä‡ uwagÄ™ na `scaler.update()`. Skaler jest inteligentny:\n",
    "*   JeÅ›li wykryje `NaN` lub `Inf` (co oznacza, Å¼e skala byÅ‚a za duÅ¼a i nastÄ…piÅ‚ Overflow) -> **Pominie ten krok** (nie zaktualizuje wag) i zmniejszy skalÄ™.\n",
    "*   JeÅ›li przez X krokÃ³w nie ma bÅ‚Ä™dÃ³w -> ZwiÄ™kszy skalÄ™, Å¼eby zyskaÄ‡ na precyzji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0c56fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startowa skala: 65536.0\n",
      "Krok 0: Loss=1.0529, Skala=65536.0\n",
      "Krok 2: Loss=1.0524, Skala=65536.0\n",
      "Krok 4: Loss=1.0518, Skala=65536.0\n",
      "Krok 6: Loss=1.0513, Skala=65536.0\n",
      "Krok 8: Loss=1.0507, Skala=65536.0\n",
      "Czas: 0.4104s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Startowa skala: {scaler.get_scale()}\")\n",
    "\n",
    "start = time.time()\n",
    "for step in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 1. Autocast (Tu dzieje siÄ™ magia mieszania typÃ³w)\n",
    "    # dtype=torch.float16 dla GPU NVIDIA\n",
    "    with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "        output = model(data)\n",
    "        loss = (output - target).pow(2).mean() # MSE\n",
    "    \n",
    "    # 2. Backward ze skalowaniem\n",
    "    # Zamiast loss.backward()\n",
    "    scaler.scale(loss).backward()\n",
    "    \n",
    "    # 3. Step ze skalowaniem\n",
    "    # Zamiast optimizer.step()\n",
    "    # To odskalowuje gradienty (dzieli przez scale factor) przed aktualizacjÄ… wag\n",
    "    scaler.step(optimizer)\n",
    "    \n",
    "    # 4. Aktualizacja samej skali\n",
    "    scaler.update()\n",
    "    \n",
    "    if step % 2 == 0:\n",
    "        print(f\"Krok {step}: Loss={loss.item():.4f}, Skala={scaler.get_scale()}\")\n",
    "\n",
    "print(f\"Czas: {time.time() - start:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690950c",
   "metadata": {},
   "source": [
    "## PuÅ‚apka: Gradient Clipping i Unscale\n",
    "\n",
    "Co jeÅ›li uÅ¼ywasz `clip_grad_norm_` (Lekcja 32)?\n",
    "Nie moÅ¼esz przyciÄ…Ä‡ gradientÃ³w, ktÃ³re sÄ… przeskalowane (pomnoÅ¼one przez 65536), bo to bez sensu.\n",
    "Musisz je najpierw **rÄ™cznie odskalowaÄ‡**.\n",
    "\n",
    "KolejnoÅ›Ä‡ jest krytyczna:\n",
    "1.  `scaler.scale(loss).backward()`\n",
    "2.  `scaler.unscale_(optimizer)`  <-- WAÅ»NE\n",
    "3.  `clip_grad_norm_(...)`\n",
    "4.  `scaler.step(optimizer)`\n",
    "5.  `scaler.update()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02618363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krok z Clippingiem wykonany pomyÅ›lnie.\n"
     ]
    }
   ],
   "source": [
    "# Demonstracja z Clippingiem\n",
    "optimizer.zero_grad()\n",
    "\n",
    "with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "    output = model(data)\n",
    "    loss = (output - target).pow(2).mean()\n",
    "\n",
    "# Backward\n",
    "scaler.scale(loss).backward()\n",
    "\n",
    "# --- MANEWR Z CLIPPINGIEM ---\n",
    "# Musimy najpierw odskalowaÄ‡ gradienty w miejscu, Å¼eby policzyÄ‡ ich prawdziwÄ… normÄ™\n",
    "scaler.unscale_(optimizer)\n",
    "\n",
    "# Teraz gradienty sÄ… normalnymi liczbami FP32, moÅ¼emy je ciÄ…Ä‡\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "# Step (skaler wie, Å¼e juÅ¼ zrobiliÅ›my unscale, wiÄ™c nie zrobi tego drugi raz)\n",
    "scaler.step(optimizer)\n",
    "scaler.update()\n",
    "\n",
    "print(\"Krok z Clippingiem wykonany pomyÅ›lnie.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2339c424",
   "metadata": {},
   "source": [
    "## ðŸ¥‹ Black Belt Summary\n",
    "\n",
    "1.  **Zawsze uÅ¼ywaj AMP na GPU.** To darmowa wydajnoÅ›Ä‡. Nie ma powodu, by trenowaÄ‡ w czystym FP32 (chyba Å¼e masz bardzo specyficzne problemy numeryczne).\n",
    "2.  **`bfloat16` (Brain Float):** Na najnowszych kartach (Ampere A100, Hopper H100) zamiast `float16` moÅ¼na uÅ¼ywaÄ‡ `bfloat16`. Ma on taki sam zakres jak `float32`, tylko mniejszÄ… precyzjÄ™. DziÄ™ki temu **nie potrzebuje GradScalera**! (Wystarczy samo `autocast`).\n",
    "3.  **OszczÄ™dnoÅ›Ä‡:** DziÄ™ki AMP, tensory aktywacji (zapisywane do backwardu) zajmujÄ… poÅ‚owÄ™ miejsca. MoÅ¼esz podwoiÄ‡ Batch Size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
