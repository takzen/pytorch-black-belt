{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/takzen/pytorch-black-belt/blob/main/notebooks/42_Inference_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# \u2601\ufe0f COLAB SETUP (Automatyczna instalacja \u015brodowiska)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Sprawdzamy, czy jeste\u015bmy w Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('\u2601\ufe0f Wykryto \u015brodowisko Google Colab. Konfiguruj\u0119...')\n",
    "\n",
    "    # 1. Pobieramy plik requirements.txt bezpo\u015brednio z repozytorium\n",
    "    !wget -q https://raw.githubusercontent.com/takzen/ai-engineering-handbook/main/requirements.txt -O requirements.txt\n",
    "\n",
    "    # 2. Instalujemy biblioteki\n",
    "    print('\u23f3 Instaluj\u0119 zale\u017cno\u015bci (to mo\u017ce chwil\u0119 potrwa\u0107)...')\n",
    "    !pip install -q -r requirements.txt\n",
    "\n",
    "    print('\u2705 Gotowe! \u015arodowisko jest zgodne z repozytorium.')\n",
    "else:\n",
    "    print('\ud83d\udcbb Wykryto \u015brodowisko lokalne. Zak\u0142adam, \u017ce masz ju\u017c uv/venv.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf4a1a1",
   "metadata": {},
   "source": [
    "# \ud83e\udd4b Lekcja 42: Inference Optimization (Fuzja Conv + BN)\n",
    "\n",
    "Wi\u0119kszo\u015b\u0107 architektur (ResNet, YOLO) sk\u0142ada si\u0119 z blok\u00f3w: `Conv -> BN -> ReLU`.\n",
    "Na produkcji `BN` jest zb\u0119dnym narzutem obliczeniowym.\n",
    "\n",
    "**Matematyka:**\n",
    "1.  Konwolucja: $y = Wx + b$\n",
    "2.  Batch Norm: $z = \\frac{y - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\cdot \\gamma + \\beta$\n",
    "\n",
    "Mo\u017cemy to przekszta\u0142ci\u0107 w **jedn\u0105 now\u0105 Konwolucj\u0119**:\n",
    "$$ z = W_{new}x + b_{new} $$\n",
    "\n",
    "Gdzie:\n",
    "$$ W_{new} = W \\cdot \\frac{\\gamma}{\\sqrt{\\sigma^2 + \\epsilon}} $$\n",
    "$$ b_{new} = (b - \\mu) \\cdot \\frac{\\gamma}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta $$\n",
    "\n",
    "W tej lekcji napiszemy funkcj\u0119, kt\u00f3ra \"po\u0142yka\" Batchnorma i wypluwa zoptymalizowan\u0105 warstw\u0119 Conv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff93e6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model oryginalny:\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import time\n",
    "\n",
    "# Konfiguracja\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 1. TWORZYMY MODEL \"NIEZOPTYMALIZOWANY\"\n",
    "# Conv + BN to standardowy blok\n",
    "model_orig = nn.Sequential(\n",
    "    nn.Conv2d(3, 64, kernel_size=3, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(inplace=True)\n",
    ").to(DEVICE)\n",
    "\n",
    "# Musimy prze\u0142\u0105czy\u0107 w tryb eval(), \u017ceby BN u\u017cywa\u0142 zapisanych statystyk (running_mean/var),\n",
    "# a nie liczy\u0142 ich z batcha. Fuzja dzia\u0142a tylko w eval!\n",
    "model_orig.eval()\n",
    "\n",
    "print(\"Model oryginalny:\")\n",
    "print(model_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e85763",
   "metadata": {},
   "source": [
    "## R\u0119czna Implementacja Fuzji\n",
    "\n",
    "To jest kod \"Black Belt\". Wyci\u0105gamy wagi z obu warstw i tworzymy nowe wagi metod\u0105 algebraiczn\u0105."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3311eb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model po fuzji (Znikn\u0105\u0142 BatchNorm!):\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def fuse_conv_bn(conv, bn):\n",
    "    \"\"\"\n",
    "    \u0141\u0105czy wagi Conv2d i BatchNorm2d w jedn\u0105 warstw\u0119 Conv2d.\n",
    "    \"\"\"\n",
    "    # 1. Pobieramy parametry\n",
    "    with torch.no_grad():\n",
    "        # Wagi konwolucji\n",
    "        w_conv = conv.weight.clone()\n",
    "        # Bias konwolucji (mo\u017ce by\u0107 None)\n",
    "        b_conv = conv.bias.clone() if conv.bias is not None else torch.zeros_like(bn.running_mean)\n",
    "        \n",
    "        # Parametry BN\n",
    "        mean = bn.running_mean\n",
    "        var_sqrt = torch.sqrt(bn.running_var + bn.eps)\n",
    "        gamma = bn.weight # scale\n",
    "        beta = bn.bias    # shift\n",
    "        \n",
    "        # 2. Obliczamy nowe wagi (W_new)\n",
    "        # Musimy dopasowa\u0107 wymiary do mno\u017cenia (C_out, 1, 1, 1)\n",
    "        scale_factor = gamma / var_sqrt\n",
    "        w_new = w_conv * scale_factor.view(-1, 1, 1, 1)\n",
    "        \n",
    "        # 3. Obliczamy nowy bias (b_new)\n",
    "        b_new = (b_conv - mean) * scale_factor + beta\n",
    "        \n",
    "        # 4. Tworzymy now\u0105 warstw\u0119\n",
    "        fused_conv = nn.Conv2d(\n",
    "            in_channels=conv.in_channels,\n",
    "            out_channels=conv.out_channels,\n",
    "            kernel_size=conv.kernel_size,\n",
    "            stride=conv.stride,\n",
    "            padding=conv.padding,\n",
    "            bias=True # Teraz bias jest obowi\u0105zkowy (nawet jak wcze\u015bniej go nie by\u0142o)\n",
    "        )\n",
    "        \n",
    "        # Wgrywamy obliczone parametry\n",
    "        fused_conv.weight.copy_(w_new)\n",
    "        fused_conv.bias.copy_(b_new)\n",
    "        \n",
    "        return fused_conv\n",
    "\n",
    "# Zastosujmy to\n",
    "fused_conv_layer = fuse_conv_bn(model_orig[0], model_orig[1])\n",
    "\n",
    "# Budujemy nowy model (bez BN!)\n",
    "model_fused = nn.Sequential(\n",
    "    fused_conv_layer,\n",
    "    model_orig[2] # ReLU zostaje\n",
    ").to(DEVICE)\n",
    "\n",
    "model_fused.eval()\n",
    "\n",
    "print(\"\\nModel po fuzji (Znikn\u0105\u0142 BatchNorm!):\")\n",
    "print(model_fused)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6041f126",
   "metadata": {},
   "source": [
    "## Weryfikacja Numeryczna\n",
    "\n",
    "Czy matematyka nie k\u0142amie? Sprawd\u017amy, czy dla tego samego wej\u015bcia oba modele daj\u0105 **identyczny** wynik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a445751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maksymalna r\u00f3\u017cnica w wynikach: 0.00000119\n",
      "\u2705 SUKCES! Modele s\u0105 matematycznie r\u00f3wnowa\u017cne.\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 224, 224).to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out_orig = model_orig(x)\n",
    "    out_fused = model_fused(x)\n",
    "\n",
    "# Sprawdzamy r\u00f3\u017cnic\u0119\n",
    "diff = (out_orig - out_fused).abs().max().item()\n",
    "\n",
    "print(f\"Maksymalna r\u00f3\u017cnica w wynikach: {diff:.8f}\")\n",
    "\n",
    "if diff < 1e-5:\n",
    "    print(\"\u2705 SUKCES! Modele s\u0105 matematycznie r\u00f3wnowa\u017cne.\")\n",
    "else:\n",
    "    print(\"\u274c CO\u015a POSZ\u0141O NIE TAK. R\u00f3\u017cnica jest zbyt du\u017ca.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ac3dc",
   "metadata": {},
   "source": [
    "## Benchmark: Ile zyskali\u015bmy?\n",
    "\n",
    "W ma\u0142ym modelu r\u00f3\u017cnica mo\u017ce by\u0107 znikoma (narzut Pythona). Ale w du\u017cym ResNet, gdzie takich blok\u00f3w jest 50, zyskujemy brak 50 operacji odczytu/zapisu pami\u0119ci dla BN.\n",
    "\n",
    "*Uwaga: Na ma\u0142ym tensorze i w Pythonie narzut p\u0119tli pomiarowej mo\u017ce ukry\u0107 zysk, ale na poziomie CUDA kernel to jest czysty zysk.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60828e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orygina\u0142 (Conv+BN): 0.7202 s\n",
      "Fused (Conv):       0.4779 s\n",
      "\ud83d\ude80 Przyspieszenie: 1.51x\n"
     ]
    }
   ],
   "source": [
    "# BENCHMARK\n",
    "# Musimy zrobi\u0107 du\u017co powt\u00f3rze\u0144, \u017ceby zobaczy\u0107 r\u00f3\u017cnic\u0119 (mikrosekundy)\n",
    "iters = 5000\n",
    "\n",
    "# 1. Warmup (Rozgrzewka GPU)\n",
    "for _ in range(100):\n",
    "    _ = model_orig(x)\n",
    "    _ = model_fused(x)\n",
    "\n",
    "torch.cuda.synchronize() if DEVICE == \"cuda\" else None\n",
    "\n",
    "# 2. Pomiar Orygina\u0142u\n",
    "start = time.time()\n",
    "for _ in range(iters):\n",
    "    _ = model_orig(x)\n",
    "torch.cuda.synchronize() if DEVICE == \"cuda\" else None\n",
    "end = time.time()\n",
    "time_orig = end - start\n",
    "\n",
    "# 3. Pomiar Zoptymalizowanego\n",
    "start = time.time()\n",
    "for _ in range(iters):\n",
    "    _ = model_fused(x)\n",
    "torch.cuda.synchronize() if DEVICE == \"cuda\" else None\n",
    "end = time.time()\n",
    "time_fused = end - start\n",
    "\n",
    "print(f\"Orygina\u0142 (Conv+BN): {time_orig:.4f} s\")\n",
    "print(f\"Fused (Conv):       {time_fused:.4f} s\")\n",
    "print(f\"\ud83d\ude80 Przyspieszenie: {time_orig / time_fused:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4295c324",
   "metadata": {},
   "source": [
    "## \ud83e\udd4b Black Belt Summary\n",
    "\n",
    "1.  **Dlaczego warto?**\n",
    "    *   **Mniej operacji:** Usuwamy BN z grafu obliczeniowego.\n",
    "    *   **Mniej pami\u0119ci:** Nie musimy wczytywa\u0107 parametr\u00f3w BN (\u015brednia, wariancja, gamma, beta) z VRAM.\n",
    "    *   **Mniejszy plik:** Model zajmuje mniej miejsca na dysku.\n",
    "2.  **Kiedy to robi\u0107?**\n",
    "    *   **Zawsze** przed eksportem do ONNX lub deploymentem na urz\u0105dzenia mobilne.\n",
    "    *   W PyTorch Lightning i bibliotece `torchvision` s\u0105 cz\u0119sto gotowe funkcje (np. `torch.nn.utils.fuse_conv_bn_eval`), ale teraz wiesz, jak dzia\u0142aj\u0105 matematycznie.\n",
    "3.  **Wym\u00f3g:** Model musi by\u0107 w trybie `.eval()`. Fuzja podczas treningu (`.train()`) jest niemo\u017cliwa, bo BN musi wtedy dynamicznie aktualizowa\u0107 statystyki."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}