{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/takzen/pytorch-black-belt/blob/main/notebooks/43_DDP_Concepts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# \u2601\ufe0f COLAB SETUP (Automatyczna instalacja \u015brodowiska)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Sprawdzamy, czy jeste\u015bmy w Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('\u2601\ufe0f Wykryto \u015brodowisko Google Colab. Konfiguruj\u0119...')\n",
    "\n",
    "    # 1. Pobieramy plik requirements.txt bezpo\u015brednio z repozytorium\n",
    "    !wget -q https://raw.githubusercontent.com/takzen/ai-engineering-handbook/main/requirements.txt -O requirements.txt\n",
    "\n",
    "    # 2. Instalujemy biblioteki\n",
    "    print('\u23f3 Instaluj\u0119 zale\u017cno\u015bci (to mo\u017ce chwil\u0119 potrwa\u0107)...')\n",
    "    !pip install -q -r requirements.txt\n",
    "\n",
    "    print('\u2705 Gotowe! \u015arodowisko jest zgodne z repozytorium.')\n",
    "else:\n",
    "    print('\ud83d\udcbb Wykryto \u015brodowisko lokalne. Zak\u0142adam, \u017ce masz ju\u017c uv/venv.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956d764e",
   "metadata": {},
   "source": [
    "# \ud83e\udd4b Lekcja 43: DDP (Distributed Data Parallel) - Anatomia Synchronizacji\n",
    "\n",
    "Dlaczego `nn.DataParallel` (DP) jest z\u0142e?\n",
    "Bo kopiuje model do VRAM przy ka\u017cdym kroku (Forward), a potem go kasuje. Narzut komunikacyjny jest gigantyczny.\n",
    "\n",
    "**DDP (Distributed Data Parallel)** jest inne:\n",
    "1.  Model jest kopiowany raz (na starcie).\n",
    "2.  Procesy \u017cyj\u0105 niezale\u017cnie (nie blokuj\u0105 si\u0119 przez GIL).\n",
    "3.  Jedyny moment komunikacji to **U\u015brednianie Gradient\u00f3w (AllReduce)**.\n",
    "\n",
    "**Matematyka DDP:**\n",
    "*   GPU 0: Obliczy\u0142 gradient $g_0 = 10$.\n",
    "*   GPU 1: Obliczy\u0142 gradient $g_1 = 12$.\n",
    "*   **AllReduce:** Oba GPU ustalaj\u0105: \"Nasz wsp\u00f3lny gradient to $(10+12)/2 = 11$\".\n",
    "*   Update: Oba GPU odejmuj\u0105 $11$ od wag. Pozostaj\u0105 identyczne.\n",
    "\n",
    "Zasymulujemy to r\u0119cznie na dw\u00f3ch \"wirtualnych\" GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d569ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symulacja: Dwa procesy wystartowa\u0142y z identycznym modelem.\n",
      "Waga GPU0 (pierwsza): 1.0\n",
      "Waga GPU1 (pierwsza): 1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "\n",
    "# Konfiguracja\n",
    "# Udajemy, \u017ce mamy 2 urz\u0105dzenia (nawet je\u015bli to CPU)\n",
    "RANK_0_DEVICE = \"cpu\"\n",
    "RANK_1_DEVICE = \"cpu\"\n",
    "\n",
    "# 1. TWORZYMY MODEL (Baza)\n",
    "# nn.Linear(10, 1) tworzy wagi o kszta\u0142cie [1, 10]\n",
    "base_model = nn.Linear(10, 1, bias=False)\n",
    "\n",
    "# Ustawiamy wagi na sztywno, \u017ceby start by\u0142 identyczny\n",
    "with torch.no_grad():\n",
    "    base_model.weight.fill_(1.0)\n",
    "\n",
    "# 2. Rozsy\u0142amy model na \"GPU\" (Repliki)\n",
    "model_gpu0 = copy.deepcopy(base_model).to(RANK_0_DEVICE)\n",
    "model_gpu1 = copy.deepcopy(base_model).to(RANK_1_DEVICE)\n",
    "\n",
    "# Ka\u017cdy ma sw\u00f3j optymalizator\n",
    "opt_gpu0 = optim.SGD(model_gpu0.parameters(), lr=0.1)\n",
    "opt_gpu1 = optim.SGD(model_gpu1.parameters(), lr=0.1)\n",
    "\n",
    "print(\"Symulacja: Dwa procesy wystartowa\u0142y z identycznym modelem.\")\n",
    "\n",
    "# --- POPRAWKA ---\n",
    "# Zamiast .item() na ca\u0142ym tensorze, bierzemy pierwszy element [0, 0]\n",
    "print(f\"Waga GPU0 (pierwsza): {model_gpu0.weight[0, 0].item()}\")\n",
    "print(f\"Waga GPU1 (pierwsza): {model_gpu1.weight[0, 0].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2340e3",
   "metadata": {},
   "source": [
    "## Krok 1: Forward/Backward (Desynchronizacja)\n",
    "\n",
    "Ka\u017cdy proces dostaje **inne dane** (dzi\u0119ki `DistributedSampler`).\n",
    "Dlatego ka\u017cdy wyliczy **inny gradient**.\n",
    "Je\u015bli zrobimy `step()` teraz, modele si\u0119 \"rozjad\u0105\" i trening p\u00f3jdzie do kosza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "081b2e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GRADIENTY LOKALNE ---\n",
      "Grad GPU0: -180.00\n",
      "Grad GPU1: -720.00\n",
      "Modele chc\u0105 i\u015b\u0107 w r\u00f3\u017cnych kierunkach!\n"
     ]
    }
   ],
   "source": [
    "# Dane dla GPU 0 (np. pierwsza po\u0142owa batcha)\n",
    "data_0 = torch.tensor([[1.0] * 10]).to(RANK_0_DEVICE) # Same jedynki\n",
    "target_0 = torch.tensor([[100.0]]).to(RANK_0_DEVICE)\n",
    "\n",
    "# Dane dla GPU 1 (np. druga po\u0142owa batcha)\n",
    "data_1 = torch.tensor([[2.0] * 10]).to(RANK_1_DEVICE) # Same dw\u00f3jki\n",
    "target_1 = torch.tensor([[200.0]]).to(RANK_1_DEVICE)\n",
    "\n",
    "# --- PROCES GPU 0 ---\n",
    "opt_gpu0.zero_grad()\n",
    "pred_0 = model_gpu0(data_0)\n",
    "loss_0 = (pred_0 - target_0)**2\n",
    "loss_0.backward()\n",
    "\n",
    "# --- PROCES GPU 1 ---\n",
    "opt_gpu1.zero_grad()\n",
    "pred_1 = model_gpu1(data_1)\n",
    "loss_1 = (pred_1 - target_1)**2\n",
    "loss_1.backward()\n",
    "\n",
    "print(\"--- GRADIENTY LOKALNE ---\")\n",
    "# Gradienty s\u0105 r\u00f3\u017cne, bo dane by\u0142y r\u00f3\u017cne!\n",
    "grad_0 = model_gpu0.weight.grad\n",
    "grad_1 = model_gpu1.weight.grad\n",
    "\n",
    "print(f\"Grad GPU0: {grad_0[0,0].item():.2f}\")\n",
    "print(f\"Grad GPU1: {grad_1[0,0].item():.2f}\")\n",
    "print(\"Modele chc\u0105 i\u015b\u0107 w r\u00f3\u017cnych kierunkach!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd25152",
   "metadata": {},
   "source": [
    "## Krok 2: AllReduce (Synchronizacja)\n",
    "\n",
    "To jest ten moment, kt\u00f3ry DDP robi automatycznie (poprzez backend `nccl` na NVIDIA lub `gloo` na CPU).\n",
    "Musimy u\u015bredni\u0107 gradienty ze wszystkich GPU.\n",
    "\n",
    "$$ G_{global} = \\frac{G_0 + G_1 + ... + G_k}{K} $$\n",
    "\n",
    "Nast\u0119pnie nadpisujemy lokalne gradienty tym globalnym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc1d771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PO ALL-REDUCE ---\n",
      "Grad GPU0: -450.00\n",
      "Grad GPU1: -450.00\n",
      "Gradienty s\u0105 teraz identyczne. Jeste\u015bmy zsynchronizowani.\n"
     ]
    }
   ],
   "source": [
    "# Symulacja operacji DIST.ALL_REDUCE\n",
    "with torch.no_grad():\n",
    "    # 1. Sumujemy (Reduce)\n",
    "    global_grad = grad_0 + grad_1\n",
    "    \n",
    "    # 2. Dzielimy przez liczb\u0119 GPU (Average)\n",
    "    global_grad = global_grad / 2.0\n",
    "    \n",
    "    # 3. Rozsy\u0142amy z powrotem do modeli (Broadcast)\n",
    "    # Nadpisujemy lokalny .grad\n",
    "    model_gpu0.weight.grad.copy_(global_grad)\n",
    "    model_gpu1.weight.grad.copy_(global_grad)\n",
    "\n",
    "print(\"--- PO ALL-REDUCE ---\")\n",
    "print(f\"Grad GPU0: {model_gpu0.weight.grad[0,0].item():.2f}\")\n",
    "print(f\"Grad GPU1: {model_gpu1.weight.grad[0,0].item():.2f}\")\n",
    "print(\"Gradienty s\u0105 teraz identyczne. Jeste\u015bmy zsynchronizowani.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c894099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- WAGI PO KROKU ---\n",
      "Waga GPU0: 46.0000\n",
      "Waga GPU1: 46.0000\n",
      "\u2705 SUKCES! Modele pozosta\u0142y bli\u017aniakami.\n"
     ]
    }
   ],
   "source": [
    "# Krok 3: Optimizer Step\n",
    "opt_gpu0.step()\n",
    "opt_gpu1.step()\n",
    "\n",
    "print(\"\\n--- WAGI PO KROKU ---\")\n",
    "# POPRAWKA: Indeksowanie [0, 0]\n",
    "w0 = model_gpu0.weight[0, 0].item()\n",
    "w1 = model_gpu1.weight[0, 0].item()\n",
    "\n",
    "print(f\"Waga GPU0: {w0:.4f}\")\n",
    "print(f\"Waga GPU1: {w1:.4f}\")\n",
    "\n",
    "if w0 == w1:\n",
    "    print(\"\u2705 SUKCES! Modele pozosta\u0142y bli\u017aniakami.\")\n",
    "else:\n",
    "    print(\"\u274c B\u0141\u0104D! Modele si\u0119 rozjecha\u0142y.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f245a7",
   "metadata": {},
   "source": [
    "## Boilerplate (Jak to wygl\u0105da w kodzie?)\n",
    "\n",
    "W prawdziwym skrypcie nie robisz tego r\u0119cznie. U\u017cywasz wrappera `DistributedDataParallel`.\n",
    "\n",
    "Oto \"Szablon Startowy\", kt\u00f3ry ka\u017cdy in\u017cynier DDP ma pod r\u0119k\u0105.\n",
    "*(Ten kod nie zadzia\u0142a w notatniku, bo wymaga uruchomienia przez `torchrun`, ale jest referencj\u0105)*.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "def main():\n",
    "    # 1. Inicjalizacja grupy procesowej\n",
    "    dist.init_process_group(\"nccl\")\n",
    "    \n",
    "    # 2. Sprawdzenie, kim jestem (Rank)\n",
    "    rank = dist.get_rank()\n",
    "    world_size = dist.get_world_size()\n",
    "    device = torch.device(f\"cuda:{rank}\")\n",
    "    \n",
    "    # 3. Model na GPU\n",
    "    model = MyModel().to(device)\n",
    "    # Magia: DDP automatycznie rejestruje hooki na gradientach, \u017ceby robi\u0107 AllReduce\n",
    "    model = DDP(model, device_ids=[rank])\n",
    "    \n",
    "    # 4. Sampler (\u017beby ka\u017cdy GPU dosta\u0142 inne dane!)\n",
    "    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)\n",
    "    loader = DataLoader(dataset, sampler=sampler, batch_size=32)\n",
    "    \n",
    "    # 5. P\u0119tla\n",
    "    for epoch in range(10):\n",
    "        sampler.set_epoch(epoch) # Wa\u017cne dla tasowania!\n",
    "        for batch in loader:\n",
    "            ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356cf69d",
   "metadata": {},
   "source": [
    "## \ud83e\udd4b Black Belt Summary\n",
    "\n",
    "1.  **DistributedSampler:** Kluczowy element. Dzieli tort danych na kawa\u0142ki. Bez tego ka\u017cdy GPU uczy\u0142by si\u0119 na tym samym (strata zasob\u00f3w) lub losowo (ryzyko duplikat\u00f3w).\n",
    "2.  **SyncBatchNorm:** Zwyk\u0142y BatchNorm dzia\u0142a tylko lokalnie (na 1 GPU). Je\u015bli masz ma\u0142y batch per GPU (np. 2), BN zwariuje. Musisz u\u017cy\u0107 `nn.SyncBatchNorm.convert_sync_batchnorm(model)`, \u017ceby statystyki by\u0142y liczone globalnie (kosztuje troch\u0119 czasu na komunikacj\u0119).\n",
    "3.  **`torchrun`:** Nie uruchamiaj skrypt\u00f3w przez `python train.py`. U\u017cywaj `torchrun --nproc_per_node=4 train.py`. To automatycznie zarz\u0105dza rangami."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}