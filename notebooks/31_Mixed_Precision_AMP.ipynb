{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/takzen/pytorch-black-belt/blob/main/notebooks/31_Mixed_Precision_AMP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# \u2601\ufe0f COLAB SETUP (Automatyczna instalacja \u015brodowiska)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Sprawdzamy, czy jeste\u015bmy w Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('\u2601\ufe0f Wykryto \u015brodowisko Google Colab. Konfiguruj\u0119...')\n",
    "\n",
    "    # 1. Pobieramy plik requirements.txt bezpo\u015brednio z repozytorium\n",
    "    !wget -q https://raw.githubusercontent.com/takzen/ai-engineering-handbook/main/requirements.txt -O requirements.txt\n",
    "\n",
    "    # 2. Instalujemy biblioteki\n",
    "    print('\u23f3 Instaluj\u0119 zale\u017cno\u015bci (to mo\u017ce chwil\u0119 potrwa\u0107)...')\n",
    "    !pip install -q -r requirements.txt\n",
    "\n",
    "    print('\u2705 Gotowe! \u015arodowisko jest zgodne z repozytorium.')\n",
    "else:\n",
    "    print('\ud83d\udcbb Wykryto \u015brodowisko lokalne. Zak\u0142adam, \u017ce masz ju\u017c uv/venv.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd300fb",
   "metadata": {},
   "source": [
    "# \ud83e\udd4b Lekcja 31: Mixed Precision (AMP) & GradScaler\n",
    "\n",
    "Standardowo PyTorch u\u017cywa `float32` (4 bajty na liczb\u0119).\n",
    "Karty NVIDIA (Volta, Turing, Ampere) maj\u0105 **Tensor Cores**, kt\u00f3re licz\u0105 macierze w `float16` (2 bajty) niesamowicie szybko.\n",
    "\n",
    "**Problem z FP16:**\n",
    "Zakres liczb jest ma\u0142y.\n",
    "*   Najmniejsza liczba dodatnia w FP16 to ok. `6e-5`.\n",
    "*   Gradienty w sieciach cz\u0119sto s\u0105 rz\u0119du `1e-7`. W FP16 staj\u0105 si\u0119 zerem (**Underflow**). Sie\u0107 przestaje si\u0119 uczy\u0107.\n",
    "\n",
    "**Rozwi\u0105zanie (AMP Pipeline):**\n",
    "1.  **Autocast:** PyTorch automatycznie decyduje, kt\u00f3re operacje (Conv, MatMul) zrobi\u0107 w FP16 (szybkie), a kt\u00f3re (Softmax, Sum) zostawi\u0107 w FP32 (stabilne).\n",
    "2.  **GradScaler:** Mno\u017cy Loss przez du\u017c\u0105 liczb\u0119 (np. 65536), \u017ceby \"nadmucha\u0107\" ma\u0142e gradienty, by nie znikn\u0119\u0142y w FP16. Przed aktualizacj\u0105 wag dzieli je z powrotem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7caa2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 GPU: NVIDIA GeForce RTX 4060\n",
      "Liczba w FP32: 0.00001000\n",
      "Liczba w FP16: 0.00001001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# Sprawd\u017amy sprz\u0119t\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(f\"\u2705 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"\u26a0\ufe0f Brak GPU. AMP zadzia\u0142a (bfloat16 na CPU), ale zysk b\u0119dzie mniejszy.\")\n",
    "\n",
    "# Symulacja problemu Underflow\n",
    "small_grad = torch.tensor(1e-5, dtype=torch.float32)\n",
    "print(f\"Liczba w FP32: {small_grad.item():.8f}\")\n",
    "print(f\"Liczba w FP16: {small_grad.half().item():.8f}\") \n",
    "# 1e-5 w FP16 jest bezpieczne, ale 1e-8 sta\u0142oby si\u0119 zerem!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c7daa4",
   "metadata": {},
   "source": [
    "## Wzorzec Projektowy AMP\n",
    "\n",
    "Kod treningowy zmienia si\u0119 minimalnie.\n",
    "Zamiast:\n",
    "```python\n",
    "loss = criterion(model(x), y)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "```\n",
    "Robimy:\n",
    "```python\n",
    "with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "    loss = criterion(model(x), y)\n",
    "\n",
    "scaler.scale(loss).backward() # Skalowanie + Backward\n",
    "scaler.step(optimizer)        # Odskalowanie + Update\n",
    "scaler.update()               # Aktualizacja wsp\u00f3\u0142czynnika skali\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e859f033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup gotowy. Skaler zainicjowany (Nowe API bez ostrze\u017ce\u0144).\n"
     ]
    }
   ],
   "source": [
    "# Prosty model, ale z du\u017cymi macierzami, \u017ceby poczu\u0107 r\u00f3\u017cnic\u0119 w pami\u0119ci\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4096, 4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(4096, 4096)\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Inicjalizacja Skalera (Nowoczesne API PyTorch 2.x)\n",
    "# Zamiast torch.cuda.amp.GradScaler, u\u017cywamy torch.amp.GradScaler\n",
    "# Pierwszy argument to typ urz\u0105dzenia ('cuda').\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=(device == \"cuda\"))\n",
    "\n",
    "# Dane\n",
    "data = torch.randn(64, 4096, device=device)\n",
    "target = torch.randn(64, 4096, device=device)\n",
    "\n",
    "print(\"Setup gotowy. Skaler zainicjowany (Nowe API bez ostrze\u017ce\u0144).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21becd6e",
   "metadata": {},
   "source": [
    "## P\u0119tla Treningowa z AMP\n",
    "\n",
    "Zwr\u00f3\u0107 uwag\u0119 na `scaler.update()`. Skaler jest inteligentny:\n",
    "*   Je\u015bli wykryje `NaN` lub `Inf` (co oznacza, \u017ce skala by\u0142a za du\u017ca i nast\u0105pi\u0142 Overflow) -> **Pominie ten krok** (nie zaktualizuje wag) i zmniejszy skal\u0119.\n",
    "*   Je\u015bli przez X krok\u00f3w nie ma b\u0142\u0119d\u00f3w -> Zwi\u0119kszy skal\u0119, \u017ceby zyska\u0107 na precyzji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0c56fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startowa skala: 65536.0\n",
      "Krok 0: Loss=1.0529, Skala=65536.0\n",
      "Krok 2: Loss=1.0524, Skala=65536.0\n",
      "Krok 4: Loss=1.0518, Skala=65536.0\n",
      "Krok 6: Loss=1.0513, Skala=65536.0\n",
      "Krok 8: Loss=1.0507, Skala=65536.0\n",
      "Czas: 0.4104s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Startowa skala: {scaler.get_scale()}\")\n",
    "\n",
    "start = time.time()\n",
    "for step in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 1. Autocast (Tu dzieje si\u0119 magia mieszania typ\u00f3w)\n",
    "    # dtype=torch.float16 dla GPU NVIDIA\n",
    "    with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "        output = model(data)\n",
    "        loss = (output - target).pow(2).mean() # MSE\n",
    "    \n",
    "    # 2. Backward ze skalowaniem\n",
    "    # Zamiast loss.backward()\n",
    "    scaler.scale(loss).backward()\n",
    "    \n",
    "    # 3. Step ze skalowaniem\n",
    "    # Zamiast optimizer.step()\n",
    "    # To odskalowuje gradienty (dzieli przez scale factor) przed aktualizacj\u0105 wag\n",
    "    scaler.step(optimizer)\n",
    "    \n",
    "    # 4. Aktualizacja samej skali\n",
    "    scaler.update()\n",
    "    \n",
    "    if step % 2 == 0:\n",
    "        print(f\"Krok {step}: Loss={loss.item():.4f}, Skala={scaler.get_scale()}\")\n",
    "\n",
    "print(f\"Czas: {time.time() - start:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7690950c",
   "metadata": {},
   "source": [
    "## Pu\u0142apka: Gradient Clipping i Unscale\n",
    "\n",
    "Co je\u015bli u\u017cywasz `clip_grad_norm_` (Lekcja 32)?\n",
    "Nie mo\u017cesz przyci\u0105\u0107 gradient\u00f3w, kt\u00f3re s\u0105 przeskalowane (pomno\u017cone przez 65536), bo to bez sensu.\n",
    "Musisz je najpierw **r\u0119cznie odskalowa\u0107**.\n",
    "\n",
    "Kolejno\u015b\u0107 jest krytyczna:\n",
    "1.  `scaler.scale(loss).backward()`\n",
    "2.  `scaler.unscale_(optimizer)`  <-- WA\u017bNE\n",
    "3.  `clip_grad_norm_(...)`\n",
    "4.  `scaler.step(optimizer)`\n",
    "5.  `scaler.update()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02618363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krok z Clippingiem wykonany pomy\u015blnie.\n"
     ]
    }
   ],
   "source": [
    "# Demonstracja z Clippingiem\n",
    "optimizer.zero_grad()\n",
    "\n",
    "with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "    output = model(data)\n",
    "    loss = (output - target).pow(2).mean()\n",
    "\n",
    "# Backward\n",
    "scaler.scale(loss).backward()\n",
    "\n",
    "# --- MANEWR Z CLIPPINGIEM ---\n",
    "# Musimy najpierw odskalowa\u0107 gradienty w miejscu, \u017ceby policzy\u0107 ich prawdziw\u0105 norm\u0119\n",
    "scaler.unscale_(optimizer)\n",
    "\n",
    "# Teraz gradienty s\u0105 normalnymi liczbami FP32, mo\u017cemy je ci\u0105\u0107\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "# Step (skaler wie, \u017ce ju\u017c zrobili\u015bmy unscale, wi\u0119c nie zrobi tego drugi raz)\n",
    "scaler.step(optimizer)\n",
    "scaler.update()\n",
    "\n",
    "print(\"Krok z Clippingiem wykonany pomy\u015blnie.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2339c424",
   "metadata": {},
   "source": [
    "## \ud83e\udd4b Black Belt Summary\n",
    "\n",
    "1.  **Zawsze u\u017cywaj AMP na GPU.** To darmowa wydajno\u015b\u0107. Nie ma powodu, by trenowa\u0107 w czystym FP32 (chyba \u017ce masz bardzo specyficzne problemy numeryczne).\n",
    "2.  **`bfloat16` (Brain Float):** Na najnowszych kartach (Ampere A100, Hopper H100) zamiast `float16` mo\u017cna u\u017cywa\u0107 `bfloat16`. Ma on taki sam zakres jak `float32`, tylko mniejsz\u0105 precyzj\u0119. Dzi\u0119ki temu **nie potrzebuje GradScalera**! (Wystarczy samo `autocast`).\n",
    "3.  **Oszcz\u0119dno\u015b\u0107:** Dzi\u0119ki AMP, tensory aktywacji (zapisywane do backwardu) zajmuj\u0105 po\u0142ow\u0119 miejsca. Mo\u017cesz podwoi\u0107 Batch Size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}