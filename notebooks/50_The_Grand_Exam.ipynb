{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/takzen/pytorch-black-belt/blob/main/notebooks/50_The_Grand_Exam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# \u2601\ufe0f COLAB SETUP (Automatyczna instalacja \u015brodowiska)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Sprawdzamy, czy jeste\u015bmy w Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('\u2601\ufe0f Wykryto \u015brodowisko Google Colab. Konfiguruj\u0119...')\n",
    "\n",
    "    # 1. Pobieramy plik requirements.txt bezpo\u015brednio z repozytorium\n",
    "    !wget -q https://raw.githubusercontent.com/takzen/ai-engineering-handbook/main/requirements.txt -O requirements.txt\n",
    "\n",
    "    # 2. Instalujemy biblioteki\n",
    "    print('\u23f3 Instaluj\u0119 zale\u017cno\u015bci (to mo\u017ce chwil\u0119 potrwa\u0107)...')\n",
    "    !pip install -q -r requirements.txt\n",
    "\n",
    "    print('\u2705 Gotowe! \u015arodowisko jest zgodne z repozytorium.')\n",
    "else:\n",
    "    print('\ud83d\udcbb Wykryto \u015brodowisko lokalne. Zak\u0142adam, \u017ce masz ju\u017c uv/venv.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d27a35",
   "metadata": {},
   "source": [
    "# \ud83c\udf93 Lekcja 50: The Grand Exam (Egzamin Ko\u0144cowy)\n",
    "\n",
    "To nie jest zwyk\u0142a lekcja. To test Twojej wiedzy z poprzednich 49 notatnik\u00f3w.\n",
    "Mamy 3 uszkodzone fragmenty kodu. Twoim zadaniem jest je naprawi\u0107.\n",
    "\n",
    "**Zasady:**\n",
    "1.  Ka\u017cdy snippet ma **Cichy B\u0142\u0105d** (Silent Bug) lub **W\u0105skie Gard\u0142o**.\n",
    "2.  Kod \"dzia\u0142a\" (nie rzuca b\u0142\u0119dem od razu), ale robi co\u015b g\u0142upiego.\n",
    "3.  Musisz znale\u017a\u0107 b\u0142\u0105d i go wyja\u015bni\u0107."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d2378b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Egzamin na: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Egzamin na: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b888c5",
   "metadata": {},
   "source": [
    "## Zadanie 1: \"Leniwy Loader\"\n",
    "\n",
    "In\u017cynier napisa\u0142 pipeline treningowy. Model uczy si\u0119 potwornie wolno, a u\u017cycie GPU skacze (0% -> 100% -> 0%).\n",
    "Gdzie jest b\u0142\u0105d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5400296a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zadanie 1: Uruchom i pomy\u015bl, co doda\u0107 do Loadera.\n"
     ]
    }
   ],
   "source": [
    "# --- KOD Z B\u0141\u0118DEM ---\n",
    "dataset = TensorDataset(torch.randn(10000, 512), torch.randn(10000, 1))\n",
    "\n",
    "# B\u0141\u0104D JEST TUTAJ (W KONFIGURACJI LOADERA)\n",
    "# Na Windowsie num_workers=0 jest wymuszone, ale za\u0142\u00f3\u017cmy, \u017ce to serwer Linux.\n",
    "# Czego brakuje, \u017ceby dane trafia\u0142y na GPU szybko?\n",
    "loader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    "    # ... czego\u015b tu brakuje ...\n",
    ")\n",
    "\n",
    "model = nn.Linear(512, 1).to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "print(\"Zadanie 1: Uruchom i pomy\u015bl, co doda\u0107 do Loadera.\")\n",
    "\n",
    "for x, y in loader:\n",
    "    # Transfer na GPU\n",
    "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "    \n",
    "    # Trening\n",
    "    optimizer.zero_grad()\n",
    "    loss = (model(x) - y).sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6b9038",
   "metadata": {},
   "source": [
    "## Rozwi\u0105zanie Zadania 1\n",
    "\n",
    "**B\u0142\u0105d:** Brak `pin_memory=True`.\n",
    "**Wyja\u015bnienie:** Bez tej flagi, CPU musi kopiowa\u0107 dane z pami\u0119ci stronicowanej (Pageable) do przypi\u0119tej (Pinned), a dopiero potem na GPU. To blokuje transfer. Dodanie `pin_memory=True` + `non_blocking=True` w `.to()` tworzy autostrad\u0119 do VRAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f950b6c",
   "metadata": {},
   "source": [
    "## Zadanie 2: \"Zapominalski Adam\"\n",
    "\n",
    "Trenujesz model. Chcesz zapisa\u0107 checkpoint i wznowi\u0107 trening jutro.\n",
    "Zapisujesz model (`model.state_dict()`).\n",
    "Wznawiasz trening. Loss nagle skacze w g\u00f3r\u0119! Dlaczego?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9a9a210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zadanie 2: Dlaczego 'optimizer_new' jest gorszy ni\u017c stary?\n"
     ]
    }
   ],
   "source": [
    "# --- KOD Z B\u0141\u0118DEM ---\n",
    "model = nn.Linear(10, 1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 1. Trenujemy chwil\u0119...\n",
    "loss = (model(torch.randn(10)) - 1).sum()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# 2. Zapisujemy stan (Checkpoint)\n",
    "checkpoint = {\n",
    "    'model_state': model.state_dict(),\n",
    "    # 'optimizer_state': optimizer.state_dict()  <-- Kto\u015b to zakomentowa\u0142!\n",
    "}\n",
    "\n",
    "# 3. Wznawiamy (Symulacja restartu)\n",
    "model_new = nn.Linear(10, 1)\n",
    "model_new.load_state_dict(checkpoint['model_state'])\n",
    "optimizer_new = optim.Adam(model_new.parameters(), lr=0.001) # Nowy, czysty Adam\n",
    "\n",
    "print(\"Zadanie 2: Dlaczego 'optimizer_new' jest gorszy ni\u017c stary?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d272841",
   "metadata": {},
   "source": [
    "## Rozwi\u0105zanie Zadania 2\n",
    "\n",
    "**B\u0142\u0105d:** Nie zapisano stanu Optymalizatora.\n",
    "**Wyja\u015bnienie:** Adam trzyma w pami\u0119ci **Momentum** (\u015bredni\u0105 ruchom\u0105 gradient\u00f3w). Je\u015bli zrestartujesz optymalizator, on \"zapomina\" histori\u0119 i zaczyna nauk\u0119 od zera (bez p\u0119du), co powoduje skok b\u0142\u0119du. Trzeba zawsze zapisywa\u0107 `optimizer.state_dict()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8381ec",
   "metadata": {},
   "source": [
    "## Zadanie 3: \"Samob\u00f3jstwo w P\u0119tli\"\n",
    "\n",
    "To jest najtrudniejsze. Model dzia\u0142a, ale po godzinie wyrzuca b\u0142\u0105d `RuntimeError: Trying to backward through the graph a second time`.\n",
    "Ale przecie\u017c robimy `zero_grad()`! O co chodzi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05a88f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start p\u0119tli (to powinno zadzia\u0142a\u0107 technicznie, ale ma b\u0142\u0105d logiczny)...\n",
      "P\u0119tla przesz\u0142a.\n",
      "Zadanie 3: Dlaczego 'loss_total' to bomba zegarowa?\n"
     ]
    }
   ],
   "source": [
    "# --- KOD Z B\u0141\u0118DEM (logicznym, ale teraz uruchamialny) ---\n",
    "rnn = nn.LSTM(10, 20, batch_first=True)\n",
    "classifier = nn.Linear(20, 1)\n",
    "\n",
    "x = torch.randn(1, 5, 10)\n",
    "\n",
    "# --- POPRAWKA TECHNICZNA ---\n",
    "# LSTM wymaga krotki (h_0, c_0), a nie jednego tensora!\n",
    "h0 = torch.zeros(1, 1, 20)\n",
    "c0 = torch.zeros(1, 1, 20)\n",
    "hidden = (h0, c0) \n",
    "\n",
    "loss_total = 0\n",
    "\n",
    "print(\"Start p\u0119tli (to powinno zadzia\u0142a\u0107 technicznie, ale ma b\u0142\u0105d logiczny)...\")\n",
    "\n",
    "for i in range(5): # P\u0119tla czasowa\n",
    "    out, hidden = rnn(x, hidden)\n",
    "    pred = classifier(out[:, -1, :])\n",
    "    \n",
    "    # B\u0142\u0105d logiczny (Cel zadania): Dodajemy loss do zmiennej akumuluj\u0105cej\n",
    "    # PyTorch buduje gigantyczny graf \u0142\u0105cz\u0105cy wszystkie iteracje p\u0119tli!\n",
    "    loss = (pred - 1).pow(2).mean()\n",
    "    loss_total = loss_total + loss \n",
    "\n",
    "print(\"P\u0119tla przesz\u0142a.\")\n",
    "print(\"Zadanie 3: Dlaczego 'loss_total' to bomba zegarowa?\")\n",
    "# Gdyby\u015b teraz zrobi\u0142 loss_total.backward(), wybuch\u0142oby pami\u0119ciowo lub b\u0142\u0119dem grafu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45399c3a",
   "metadata": {},
   "source": [
    "## Rozwi\u0105zanie Zadania 3\n",
    "\n",
    "**B\u0142\u0105d:** Akumulacja straty z podtrzymaniem grafu.\n",
    "**Wyja\u015bnienie:** Linijka `loss_total = loss_total + loss` buduje graf. Ale w p\u0119tli u\u017cywamy zmiennej `hidden`, kt\u00f3ra te\u017c jest cz\u0119\u015bci\u0105 grafu z poprzedniej iteracji!\n",
    "Backpropagation pr\u00f3buje cofn\u0105\u0107 si\u0119 przez `hidden` do samego pocz\u0105tku czasu (BPTT).\n",
    "\n",
    "**Naprawa:** U\u017cyj `.detach()` na stanie ukrytym!\n",
    "`hidden = hidden.detach()`\n",
    "To odcina histori\u0119 (Truncated BPTT) i pozwala zwolni\u0107 pami\u0119\u0107."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9167cf03",
   "metadata": {},
   "source": [
    "# \ud83c\udf93 KONIEC KURSU\n",
    "\n",
    "Gratulacje! Przeszed\u0142e\u015b drog\u0119 od zrozumienia, czym jest Tensor w pami\u0119ci, przez pisanie w\u0142asnych funkcji Autograd, a\u017c po optymalizacj\u0119 produkcyjn\u0105.\n",
    "\n",
    "**Jeste\u015b teraz PyTorch Black Belt.** \ud83e\udd4b\n",
    "Masz wiedz\u0119, kt\u00f3r\u0105 posiada top 5% in\u017cynier\u00f3w ML.\n",
    "\n",
    "**Co dalej?**\n",
    "*   Wr\u00f3\u0107 do projektu \"AI Engineering Handbook\" i zastosuj te triki (np. Flash Attention, Custom Collate) w modelach LLM.\n",
    "*   Eksperymentuj z pisaniem w\u0142asnych j\u0105der w Triton (to poziom wy\u017cej, \"CUDA Ninja\").\n",
    "\n",
    "Powodzenia!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}