{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/takzen/pytorch-black-belt/blob/main/notebooks/16_Custom_Collate_Fn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# \u2601\ufe0f COLAB SETUP (Automatyczna instalacja \u015brodowiska)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Sprawdzamy, czy jeste\u015bmy w Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('\u2601\ufe0f Wykryto \u015brodowisko Google Colab. Konfiguruj\u0119...')\n",
    "\n",
    "    # 1. Pobieramy plik requirements.txt bezpo\u015brednio z repozytorium\n",
    "    !wget -q https://raw.githubusercontent.com/takzen/ai-engineering-handbook/main/requirements.txt -O requirements.txt\n",
    "\n",
    "    # 2. Instalujemy biblioteki\n",
    "    print('\u23f3 Instaluj\u0119 zale\u017cno\u015bci (to mo\u017ce chwil\u0119 potrwa\u0107)...')\n",
    "    !pip install -q -r requirements.txt\n",
    "\n",
    "    print('\u2705 Gotowe! \u015arodowisko jest zgodne z repozytorium.')\n",
    "else:\n",
    "    print('\ud83d\udcbb Wykryto \u015brodowisko lokalne. Zak\u0142adam, \u017ce masz ju\u017c uv/venv.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfec8521",
   "metadata": {},
   "source": [
    "# \ud83e\udd4b Lekcja 16: Custom Collate Fn (Obs\u0142uga danych o r\u00f3\u017cnej d\u0142ugo\u015bci)\n",
    "\n",
    "W In\u017cynierii Danych PyTorch `DataLoader` dzia\u0142a w dw\u00f3ch krokach:\n",
    "1.  **Sampler** wybiera indeksy (np. `[0, 5, 2]`).\n",
    "2.  **Dataset** zwraca surowe obiekty dla tych indeks\u00f3w.\n",
    "3.  **Collate Fn** (Sklejacz) bierze list\u0119 tych obiekt\u00f3w i zamienia je w jeden Tensor (Batch).\n",
    "\n",
    "Domy\u015blny `default_collate` robi po prostu `torch.stack()`.\n",
    "Dla tekst\u00f3w o r\u00f3\u017cnej d\u0142ugo\u015bci musimy napisa\u0107 w\u0142asny `collate_fn`, kt\u00f3ry u\u017cywa **Paddingu** (wype\u0142niania zerami)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b82ec676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- SUROWE DANE ---\n",
      "Pr\u00f3bka 0: tensor([1, 2, 3]) (D\u0142ugo\u015b\u0107: 3)\n",
      "Pr\u00f3bka 1: tensor([4, 5, 6, 7, 8]) (D\u0142ugo\u015b\u0107: 5)\n",
      "Pr\u00f3bka 2: tensor([9]) (D\u0142ugo\u015b\u0107: 1)\n",
      "Pr\u00f3bka 3: tensor([10, 11, 12, 13]) (D\u0142ugo\u015b\u0107: 4)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# 1. DANE (Symulacja zda\u0144 o r\u00f3\u017cnej d\u0142ugo\u015bci)\n",
    "# Wyobra\u017a sobie, \u017ce to s\u0105 ztokenizowane zdania (IDs s\u0142\u00f3w).\n",
    "raw_data = [\n",
    "    torch.tensor([1, 2, 3]),             # Zdanie A (d\u0142ugo\u015b\u0107 3)\n",
    "    torch.tensor([4, 5, 6, 7, 8]),       # Zdanie B (d\u0142ugo\u015b\u0107 5)\n",
    "    torch.tensor([9]),                   # Zdanie C (d\u0142ugo\u015b\u0107 1)\n",
    "    torch.tensor([10, 11, 12, 13])       # Zdanie D (d\u0142ugo\u015b\u0107 4)\n",
    "]\n",
    "\n",
    "print(\"--- SUROWE DANE ---\")\n",
    "for i, seq in enumerate(raw_data):\n",
    "    print(f\"Pr\u00f3bka {i}: {seq} (D\u0142ugo\u015b\u0107: {len(seq)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301e8567",
   "metadata": {},
   "source": [
    "## Problem: Domy\u015blny Collate\n",
    "\n",
    "Spr\u00f3bujmy wrzuci\u0107 to do Loadera bez \u017cadnej konfiguracji.\n",
    "Oczekujemy b\u0142\u0119du `RuntimeError`, poniewa\u017c PyTorch nie potrafi u\u0142o\u017cy\u0107 \"schodk\u00f3w\" w r\u00f3wn\u0105 macierz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d69e304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr\u00f3ba uruchomienia domy\u015blnego loadera...\n",
      "\n",
      "\ud83d\udeab B\u0141\u0104D (Zgodnie z planem):\n",
      "stack expects each tensor to be equal size, but got [3] at entry 0 and [5] at entry 1\n",
      "\n",
      "Wyja\u015bnienie: stack expects each tensor to be equal size.\n"
     ]
    }
   ],
   "source": [
    "# batch_size=2, \u017ceby pr\u00f3bowa\u0142 sklei\u0107 przynajmniej dwa elementy\n",
    "loader_broken = DataLoader(raw_data, batch_size=2, shuffle=False)\n",
    "\n",
    "print(\"Pr\u00f3ba uruchomienia domy\u015blnego loadera...\")\n",
    "\n",
    "try:\n",
    "    for batch in loader_broken:\n",
    "        print(batch)\n",
    "except RuntimeError as e:\n",
    "    print(\"\\n\ud83d\udeab B\u0141\u0104D (Zgodnie z planem):\")\n",
    "    print(e)\n",
    "    print(\"\\nWyja\u015bnienie: stack expects each tensor to be equal size.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7dd0d1",
   "metadata": {},
   "source": [
    "## Rozwi\u0105zanie: Padding Collate\n",
    "\n",
    "Napiszemy funkcj\u0119, kt\u00f3ra:\n",
    "1.  Przyjmuje list\u0119 tensor\u00f3w (`batch`).\n",
    "2.  Znajduje najd\u0142u\u017cszy tensor.\n",
    "3.  Wype\u0142nia kr\u00f3tsze tensory zerami (`padding_value=0`) do tej d\u0142ugo\u015bci.\n",
    "4.  Zwraca idealny prostok\u0105t.\n",
    "\n",
    "U\u017cyjemy do tego `pad_sequence` z biblioteki `torch.nn.utils.rnn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24fdcced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- WYNIK Z W\u0141ASNYM COLLATE ---\n",
      "\n",
      "Batch 0:\n",
      "Kszta\u0142t: torch.Size([2, 5])\n",
      "tensor([[1, 2, 3, 0, 0],\n",
      "        [4, 5, 6, 7, 8]])\n",
      "Prawdziwe d\u0142ugo\u015bci: [3, 5]\n",
      "\n",
      "Batch 1:\n",
      "Kszta\u0142t: torch.Size([2, 4])\n",
      "tensor([[ 9,  0,  0,  0],\n",
      "        [10, 11, 12, 13]])\n",
      "Prawdziwe d\u0142ugo\u015bci: [1, 4]\n",
      "\n",
      "Widzisz zera? To jest Padding. Macierz jest prostok\u0105tna!\n"
     ]
    }
   ],
   "source": [
    "def my_padding_collate(batch):\n",
    "    \"\"\"\n",
    "    batch: lista tensor\u00f3w [tensor([1,2,3]), tensor([4,5])]\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Padding\n",
    "    # batch_first=True -> Wymiary [Batch, Time]\n",
    "    # padding_value=0  -> Czym wype\u0142nia\u0107 braki? (Zazwyczaj 0 to ID dla <PAD>)\n",
    "    padded_batch = pad_sequence(batch, batch_first=True, padding_value=0)\n",
    "    \n",
    "    # 2. (Opcjonalnie) Zwracamy te\u017c oryginalne d\u0142ugo\u015bci\n",
    "    # To przydaje si\u0119 np. w sieciach rekurencyjnych (pack_padded_sequence),\n",
    "    # \u017ceby sie\u0107 wiedzia\u0142a, \u017ce te zera na ko\u0144cu to \u015bmieci.\n",
    "    lengths = torch.tensor([len(x) for x in batch])\n",
    "    \n",
    "    return padded_batch, lengths\n",
    "\n",
    "# Testujemy\n",
    "# num_workers=0 (Dla bezpiecze\u0144stwa na Windows)\n",
    "loader_fixed = DataLoader(raw_data, batch_size=2, collate_fn=my_padding_collate, shuffle=False)\n",
    "\n",
    "print(\"--- WYNIK Z W\u0141ASNYM COLLATE ---\")\n",
    "\n",
    "for i, (batch, lens) in enumerate(loader_fixed):\n",
    "    print(f\"\\nBatch {i}:\")\n",
    "    print(f\"Kszta\u0142t: {batch.shape}\")\n",
    "    print(batch)\n",
    "    print(f\"Prawdziwe d\u0142ugo\u015bci: {lens.tolist()}\")\n",
    "\n",
    "print(\"\\nWidzisz zera? To jest Padding. Macierz jest prostok\u0105tna!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b622bc96",
   "metadata": {},
   "source": [
    "## \ud83e\udd4b Black Belt Summary\n",
    "\n",
    "1.  **Kiedy u\u017cywa\u0107?** Zawsze, gdy Twoje dane wej\u015bciowe nie s\u0105 sztywn\u0105 macierz\u0105 (Tekst, Audio o r\u00f3\u017cnym czasie trwania, Grafy o r\u00f3\u017cnej liczbie w\u0119z\u0142\u00f3w, Detekcja obiekt\u00f3w z r\u00f3\u017cn\u0105 liczb\u0105 ramek).\n",
    "2.  **`pad_sequence`:** Najlepszy przyjaciel in\u017cyniera NLP. Pami\u0119taj o `batch_first=True`.\n",
    "3.  **Maskowanie:** W Transformerach b\u0119dziesz musia\u0142 u\u017cy\u0107 tych zer, \u017ceby stworzy\u0107 `Attention Mask` (\u017ceby model nie zwraca\u0142 uwagi na puste wype\u0142niacze).\n",
    "\n",
    "W nast\u0119pnej lekcji zajmiemy si\u0119 **Samplerami**. Co zrobi\u0107, gdy masz 99% zdrowych pacjent\u00f3w i 1% chorych? (Imbalanced Dataset)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}