{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/takzen/pytorch-black-belt/blob/main/notebooks/41_ONNX_Advanced_Export.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# \u2601\ufe0f COLAB SETUP (Automatyczna instalacja \u015brodowiska)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Sprawdzamy, czy jeste\u015bmy w Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('\u2601\ufe0f Wykryto \u015brodowisko Google Colab. Konfiguruj\u0119...')\n",
    "\n",
    "    # 1. Pobieramy plik requirements.txt bezpo\u015brednio z repozytorium\n",
    "    !wget -q https://raw.githubusercontent.com/takzen/ai-engineering-handbook/main/requirements.txt -O requirements.txt\n",
    "\n",
    "    # 2. Instalujemy biblioteki\n",
    "    print('\u23f3 Instaluj\u0119 zale\u017cno\u015bci (to mo\u017ce chwil\u0119 potrwa\u0107)...')\n",
    "    !pip install -q -r requirements.txt\n",
    "\n",
    "    print('\u2705 Gotowe! \u015arodowisko jest zgodne z repozytorium.')\n",
    "else:\n",
    "    print('\ud83d\udcbb Wykryto \u015brodowisko lokalne. Zak\u0142adam, \u017ce masz ju\u017c uv/venv.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a71b4cb",
   "metadata": {},
   "source": [
    "# \ud83e\udd4b Lekcja 41: Advanced ONNX Export (Dynamic Axes)\n",
    "\n",
    "Standardowy `torch.onnx.export` zapami\u0119tuje kszta\u0142t danych przyk\u0142adowych (`dummy_input`).\n",
    "Je\u015bli w produkcji spr\u00f3bujesz poda\u0107 inne wymiary (np. wi\u0119kszy batch, d\u0142u\u017csze zdanie, wi\u0119kszy obrazek), ONNX rzuci b\u0142\u0119dem.\n",
    "\n",
    "**Rozwi\u0105zanie: `dynamic_axes`**\n",
    "To s\u0142ownik, w kt\u00f3rym m\u00f3wimy eksporterowi:\n",
    "*\"Wymiar nr 0 to 'batch', on mo\u017ce si\u0119 zmienia\u0107. Wymiar nr 2 to 'height', te\u017c zmienny. Ale wymiar nr 1 (kana\u0142y) jest sztywny.\"*\n",
    "\n",
    "Przetestujemy to na modelu RNN (gdzie zmienia si\u0119 i Batch, i D\u0142ugo\u015b\u0107 Sekwencji)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e938654e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RNN gotowy.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Konfiguracja\n",
    "DEVICE = \"cpu\" # Do eksportu wystarczy CPU\n",
    "FILE_NAME = \"dynamic_rnn.onnx\"\n",
    "\n",
    "# Model: Prosty RNN\n",
    "class DynamicRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Seq_Len, Input_Size]\n",
    "        out, _ = self.rnn(x)\n",
    "        # Bierzemy ostatni krok czasu\n",
    "        last_step = out[:, -1, :]\n",
    "        return self.fc(last_step)\n",
    "\n",
    "model = DynamicRNN(input_size=10, hidden_size=20, output_size=5)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model RNN gotowy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9bcc56",
   "metadata": {},
   "source": [
    "## Eksport Sztywny (\u0179le) vs Dynamiczny (Dobrze)\n",
    "\n",
    "Najpierw przygotujmy `dummy_input`.\n",
    "Niech to b\u0119dzie `[Batch=1, Seq=5, Features=10]`.\n",
    "\n",
    "Je\u015bli nie u\u017cyjemy `dynamic_axes`, ONNX \"zabetonuje\" `Seq=5`.\n",
    "Je\u015bli u\u017cyjemy, b\u0119dziemy mogli wrzuci\u0107 sekwencj\u0119 o d\u0142ugo\u015bci 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9ac69b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eksportowanie z danymi: torch.Size([1, 5, 10])\n",
      "\u2705 Wyeksportowano model do dynamic_rnn.onnx\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "# Wyciszamy ostrze\u017cenia o przestarza\u0142ych funkcjach\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Dane przyk\u0142adowe (do \u015bledzenia)\n",
    "dummy_input = torch.randn(1, 5, 10)\n",
    "\n",
    "print(f\"Eksportowanie z danymi: {dummy_input.shape}\")\n",
    "\n",
    "# EKSPORT Z DYNAMICZNYMI OSIAMI\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    FILE_NAME,\n",
    "    input_names=[\"input_seq\"],\n",
    "    output_names=[\"output_prob\"],\n",
    "    \n",
    "    # --- TU DZIEJE SI\u0118 MAGIA ---\n",
    "    dynamic_axes={\n",
    "        \"input_seq\": {\n",
    "            0: \"batch_size\",  # O\u015b 0 (Batch) jest zmienna\n",
    "            1: \"seq_len\"      # O\u015b 1 (D\u0142ugo\u015b\u0107 czasu) jest zmienna\n",
    "        },\n",
    "        \"output_prob\": {\n",
    "            0: \"batch_size\"   # Wyj\u015bcie te\u017c musi mie\u0107 zmienny batch!\n",
    "        }\n",
    "    },\n",
    "    # ---------------------------\n",
    "    \n",
    "    opset_version=17,\n",
    "    \n",
    "    # --- POPRAWKA ---\n",
    "    # Wy\u0142\u0105czamy silnik Dynamo, kt\u00f3ry pr\u00f3buje \"zabetonowa\u0107\" wymiary.\n",
    "    # Wymuszamy u\u017cycie klasycznego TorchScript Tracing.\n",
    "    dynamo=False  \n",
    ")\n",
    "\n",
    "print(f\"\u2705 Wyeksportowano model do {FILE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64603379",
   "metadata": {},
   "source": [
    "## Test Elastyczno\u015bci (ONNX Runtime)\n",
    "\n",
    "Teraz najwa\u017cniejszy test.\n",
    "Uruchomimy model w \u015brodowisku `onnxruntime` na danych o **zupe\u0142nie innych wymiarach** ni\u017c przy eksportcie.\n",
    "\n",
    "1.  Zmienimy Batch z 1 na 3.\n",
    "2.  Zmienimy Seq Len z 5 na 15.\n",
    "\n",
    "Je\u015bli zadzia\u0142a -> Sukces.\n",
    "Je\u015bli wywali b\u0142\u0105d -> \u0179le skonfigurowane osie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7acfc495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test zgodny (1, 5): \u2705 OK. Wynik: (1, 5)\n",
      "Test dynamiczny (3, 15): \u2705 OK. Wynik: (3, 5)\n",
      "Model obs\u0142u\u017cy\u0142 zmienne wymiary!\n"
     ]
    }
   ],
   "source": [
    "# Tworzymy sesj\u0119\n",
    "sess = ort.InferenceSession(FILE_NAME)\n",
    "\n",
    "# 1. Test zgodny (1, 5, 10)\n",
    "input_match = np.random.randn(1, 5, 10).astype(np.float32)\n",
    "res_match = sess.run(None, {\"input_seq\": input_match})\n",
    "print(f\"Test zgodny (1, 5): \u2705 OK. Wynik: {res_match[0].shape}\")\n",
    "\n",
    "# 2. Test dynamiczny (3, 15, 10) - INNY BATCH, INNA D\u0141UGO\u015a\u0106\n",
    "input_dynamic = np.random.randn(3, 15, 10).astype(np.float32)\n",
    "\n",
    "try:\n",
    "    res_dynamic = sess.run(None, {\"input_seq\": input_dynamic})\n",
    "    print(f\"Test dynamiczny (3, 15): \u2705 OK. Wynik: {res_dynamic[0].shape}\")\n",
    "    print(\"Model obs\u0142u\u017cy\u0142 zmienne wymiary!\")\n",
    "except Exception as e:\n",
    "    print(f\"\u274c B\u0141\u0104D: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1d8cd3",
   "metadata": {},
   "source": [
    "## Inspekcja Wej\u015b\u0107\n",
    "\n",
    "Mo\u017cemy zapyta\u0107 sesj\u0119 ONNX, jakich kszta\u0142t\u00f3w si\u0119 spodziewa.\n",
    "Zamiast konkretnych liczb, powinni\u015bmy zobaczy\u0107 symbole (np. `batch_size`, `seq_len` lub `unk__`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20810420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CO WIDZI ONNX? ---\n",
      "Nazwa wej\u015bcia: input_seq\n",
      "Oczekiwany kszta\u0142t: ['batch_size', 'seq_len', 10]\n"
     ]
    }
   ],
   "source": [
    "inputs_info = sess.get_inputs()[0]\n",
    "\n",
    "print(\"--- CO WIDZI ONNX? ---\")\n",
    "print(f\"Nazwa wej\u015bcia: {inputs_info.name}\")\n",
    "print(f\"Oczekiwany kszta\u0142t: {inputs_info.shape}\")\n",
    "\n",
    "# Oczekujemy czego\u015b w stylu: ['batch_size', 'seq_len', 10]\n",
    "# Je\u015bli widzisz [1, 5, 10], to znaczy, \u017ce dynamic_axes nie zadzia\u0142a\u0142o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5076589",
   "metadata": {},
   "source": [
    "## \ud83e\udd4b Black Belt Summary\n",
    "\n",
    "1.  **Zawsze u\u017cywaj `dynamic_axes`** dla Batch Size (o\u015b 0). Nigdy nie wiesz, czy na produkcji b\u0119dziesz przetwarza\u0107 1 czy 64 zapytania naraz.\n",
    "2.  **Dla NLP/Audio:** Zawsze dynamizuj o\u015b czasu/sekwencji.\n",
    "3.  **Dla Obraz\u00f3w:** Tu ostro\u017cnie. CNN cz\u0119sto wymagaj\u0105 sztywnej wysoko\u015bci/szeroko\u015bci (chyba \u017ce u\u017cywasz Global Pooling na ko\u0144cu). Je\u015bli zmienisz rozmiar obrazka w locie, wagi mog\u0105 przesta\u0107 pasowa\u0107."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}