{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/takzen/pytorch-black-belt/blob/main/notebooks/15_Dataset_vs_IterableDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# \u2601\ufe0f COLAB SETUP (Automatyczna instalacja \u015brodowiska)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Sprawdzamy, czy jeste\u015bmy w Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('\u2601\ufe0f Wykryto \u015brodowisko Google Colab. Konfiguruj\u0119...')\n",
    "\n",
    "    # 1. Pobieramy plik requirements.txt bezpo\u015brednio z repozytorium\n",
    "    !wget -q https://raw.githubusercontent.com/takzen/ai-engineering-handbook/main/requirements.txt -O requirements.txt\n",
    "\n",
    "    # 2. Instalujemy biblioteki\n",
    "    print('\u23f3 Instaluj\u0119 zale\u017cno\u015bci (to mo\u017ce chwil\u0119 potrwa\u0107)...')\n",
    "    !pip install -q -r requirements.txt\n",
    "\n",
    "    print('\u2705 Gotowe! \u015arodowisko jest zgodne z repozytorium.')\n",
    "else:\n",
    "    print('\ud83d\udcbb Wykryto \u015brodowisko lokalne. Zak\u0142adam, \u017ce masz ju\u017c uv/venv.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458b09d3",
   "metadata": {},
   "source": [
    "# \ud83e\udd4b Lekcja 15: Dataset vs IterableDataset (Streaming danych)\n",
    "\n",
    "W PyTorch mamy dwa sposoby na karmienie modelu danymi:\n",
    "\n",
    "1.  **Map-style (`Dataset`):**\n",
    "    *   Musisz zna\u0107 d\u0142ugo\u015b\u0107 (`__len__`).\n",
    "    *   Musisz mie\u0107 dost\u0119p do ka\u017cdego elementu (`__getitem__(idx)`).\n",
    "    *   *Idealne do:* Zdj\u0119\u0107 na dysku, ma\u0142ych plik\u00f3w CSV.\n",
    "\n",
    "2.  **Iterable-style (`IterableDataset`):**\n",
    "    *   Dzia\u0142a jak strumie\u0144 (Generator).\n",
    "    *   Nie musi zna\u0107 ko\u0144ca danych.\n",
    "    *   *Idealne do:* Petabajt\u00f3w tekstu, streamingu z sieci, log\u00f3w serwera.\n",
    "\n",
    "W tej lekcji napiszemy **poprawn\u0105 klas\u0119 `IterableDataset`**, kt\u00f3ra potrafi bezpiecznie dzieli\u0107 prac\u0119, nawet je\u015bli uruchomimy j\u0105 na wielu workerach (na serwerze produkcyjnym)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac75decf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane \u017ar\u00f3d\u0142owe: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
    "import math\n",
    "\n",
    "# Symulacja danych (np. linie w ogromnym pliku tekstowym)\n",
    "data_source = list(range(20))\n",
    "\n",
    "print(f\"Dane \u017ar\u00f3d\u0142owe: {data_source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a3b4b",
   "metadata": {},
   "source": [
    "## Podej\u015bcie 1: Klasyczny Map-style (Standard)\n",
    "\n",
    "To znasz. Proste i skuteczne, ale wymaga za\u0142adowania indeks\u00f3w do pami\u0119ci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fad76f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Map Dataset (Dzia\u0142a losowo) ---\n",
      "[16, 13, 11, 7]\n",
      "[5, 0, 12, 3]\n",
      "[10, 14, 19, 4]\n",
      "[9, 17, 8, 6]\n",
      "[1, 18, 2, 15]\n"
     ]
    }
   ],
   "source": [
    "class MyMapDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Test\n",
    "map_ds = MyMapDataset(data_source)\n",
    "loader = DataLoader(map_ds, batch_size=4, shuffle=True)\n",
    "\n",
    "print(\"--- Map Dataset (Dzia\u0142a losowo) ---\")\n",
    "for batch in loader:\n",
    "    print(batch.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d53318",
   "metadata": {},
   "source": [
    "## Podej\u015bcie 2: IterableDataset (Streaming)\n",
    "\n",
    "Tutaj implementujemy metod\u0119 `__iter__`.\n",
    "\n",
    "**Kluczowy mechanizm (Workload Splitting):**\n",
    "Je\u015bli uruchomimy to na wielu procesorach (workerach), ka\u017cdy dostanie kopi\u0119 datasetu.\n",
    "Musimy r\u0119cznie sprawdzi\u0107 `get_worker_info()`, \u017ceby ka\u017cdy worker wzi\u0105\u0142 **inny kawa\u0142ek tortu**.\n",
    "Inaczej model uczy\u0142by si\u0119 na zduplikowanych danych.\n",
    "\n",
    "*Poni\u017cszy kod jest \"Production Ready\" - zadzia\u0142a poprawnie zar\u00f3wno na 1 procesie (Windows/Jupyter), jak i na 100 procesach (Klaster Linux).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1790202b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klasa zdefiniowana. Gotowa do u\u017cycia.\n"
     ]
    }
   ],
   "source": [
    "class SmartIterableDataset(IterableDataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        \n",
    "        if worker_info is None:\n",
    "            # SCENARIUSZ A: Jeden proces (np. Jupyter na Windowsie)\n",
    "            # Bierzemy ca\u0142e dane od pocz\u0105tku do ko\u0144ca.\n",
    "            iter_start = 0\n",
    "            iter_end = len(self.data)\n",
    "            iter_step = 1\n",
    "        else:\n",
    "            # SCENARIUSZ B: Wiele worker\u00f3w (np. Serwer treningowy)\n",
    "            # Dzielimy dane, \u017ceby workery nie dublowa\u0142y pracy.\n",
    "            worker_id = worker_info.id\n",
    "            num_workers = worker_info.num_workers\n",
    "            \n",
    "            # Ka\u017cdy worker bierze co n-ty element (np. co 4)\n",
    "            iter_start = worker_id\n",
    "            iter_end = len(self.data)\n",
    "            iter_step = num_workers\n",
    "            \n",
    "        # Generator (yield) - zwraca dane kawa\u0142ek po kawa\u0142ku\n",
    "        for i in range(iter_start, iter_end, iter_step):\n",
    "            yield self.data[i]\n",
    "\n",
    "print(\"Klasa zdefiniowana. Gotowa do u\u017cycia.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f728b46c",
   "metadata": {},
   "source": [
    "## Uruchomienie (Bezpieczne dla Windows)\n",
    "\n",
    "U\u017cyjemy `num_workers=0`.\n",
    "Dlaczego? Bo Jupyter na Windowsie nie obs\u0142uguje wieloprocesowo\u015bci dla klas zdefiniowanych wewn\u0105trz kom\u00f3rki.\n",
    "Ale dzi\u0119ki naszej logice `if worker_info is None`, kod zadzia\u0142a bezb\u0142\u0119dnie i przetworzy wszystkie dane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37ee797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iterable Dataset (Streaming) ---\n",
      "Batch: [0, 1, 2, 3]\n",
      "Batch: [4, 5, 6, 7]\n",
      "Batch: [8, 9, 10, 11]\n",
      "Batch: [12, 13, 14, 15]\n",
      "Batch: [16, 17, 18, 19]\n",
      "------------------------------\n",
      "Odebrano \u0142\u0105cznie: 20 element\u00f3w.\n",
      "\u2705 SUKCES: Wszystkie dane zosta\u0142y przetworzone poprawnie (bez duplikat\u00f3w).\n"
     ]
    }
   ],
   "source": [
    "# Inicjalizacja\n",
    "iter_ds = SmartIterableDataset(data_source)\n",
    "\n",
    "# Tworzymy Loader (num_workers=0 zapewnia stabilno\u015b\u0107 w notatniku)\n",
    "loader = DataLoader(iter_ds, batch_size=4, num_workers=0)\n",
    "\n",
    "print(\"--- Iterable Dataset (Streaming) ---\")\n",
    "all_data = []\n",
    "\n",
    "for batch in loader:\n",
    "    print(f\"Batch: {batch.tolist()}\")\n",
    "    all_data.extend(batch.tolist())\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Odebrano \u0142\u0105cznie: {len(all_data)} element\u00f3w.\")\n",
    "# Sprawdzenie poprawno\u015bci\n",
    "if sorted(all_data) == data_source:\n",
    "    print(\"\u2705 SUKCES: Wszystkie dane zosta\u0142y przetworzone poprawnie (bez duplikat\u00f3w).\")\n",
    "else:\n",
    "    print(\"\u274c B\u0141\u0104D: Co\u015b si\u0119 zgubi\u0142o lub zdublowa\u0142o.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a123d4",
   "metadata": {},
   "source": [
    "## \ud83e\udd4b Black Belt Summary\n",
    "\n",
    "1.  **IterableDataset** to konieczno\u015b\u0107 przy Big Data (gdy nie mo\u017cesz zrobi\u0107 `len(data)`).\n",
    "2.  **Pu\u0142apka Duplikat\u00f3w:** Domy\u015blnie PyTorch kopiuje dataset do ka\u017cdego workera. Musisz u\u017cy\u0107 `get_worker_info()` wewn\u0105trz `__iter__`, \u017ceby podzieli\u0107 prac\u0119.\n",
    "3.  **Shuffle:** W `IterableDataset` nie ma globalnego tasowania (`shuffle=True` nie zadzia\u0142a idealnie). Tasuje si\u0119 tylko lokalnie w buforze (o czym wi\u0119cej w module zaawansowanym)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}