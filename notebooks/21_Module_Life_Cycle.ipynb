{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/takzen/pytorch-black-belt/blob/main/notebooks/21_Module_Life_Cycle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# \u2601\ufe0f COLAB SETUP (Automatyczna instalacja \u015brodowiska)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Sprawdzamy, czy jeste\u015bmy w Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('\u2601\ufe0f Wykryto \u015brodowisko Google Colab. Konfiguruj\u0119...')\n",
    "\n",
    "    # 1. Pobieramy plik requirements.txt bezpo\u015brednio z repozytorium\n",
    "    !wget -q https://raw.githubusercontent.com/takzen/ai-engineering-handbook/main/requirements.txt -O requirements.txt\n",
    "\n",
    "    # 2. Instalujemy biblioteki\n",
    "    print('\u23f3 Instaluj\u0119 zale\u017cno\u015bci (to mo\u017ce chwil\u0119 potrwa\u0107)...')\n",
    "    !pip install -q -r requirements.txt\n",
    "\n",
    "    print('\u2705 Gotowe! \u015arodowisko jest zgodne z repozytorium.')\n",
    "else:\n",
    "    print('\ud83d\udcbb Wykryto \u015brodowisko lokalne. Zak\u0142adam, \u017ce masz ju\u017c uv/venv.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55fb5a2",
   "metadata": {},
   "source": [
    "# \ud83e\udd4b Lekcja 21: Cykl \u017cycia nn.Module (__call__ vs forward)\n",
    "\n",
    "Ka\u017cda sie\u0107 w PyTorch dziedziczy po `nn.Module`. To nie jest zwyk\u0142a klasa Pythona.\n",
    "To **kontener**, kt\u00f3ry u\u017cywa \"czarnej magii\" Pythona (`__setattr__`, `__call__`), \u017ceby \u015bledzi\u0107 Twoje wagi.\n",
    "\n",
    "**Kluczowa zasada:**\n",
    "NIGDY nie wywo\u0142uj `model.forward(x)` r\u0119cznie.\n",
    "ZAWSZE wywo\u0142uj `model(x)`.\n",
    "\n",
    "Dlaczego?\n",
    "`__call__` (kt\u00f3re jest wywo\u0142ywane przez `model()`) robi mn\u00f3stwo rzeczy w tle:\n",
    "1.  Uruchamia `_forward_pre_hooks`.\n",
    "2.  Uruchamia `forward()`.\n",
    "3.  Uruchamia `_forward_hooks`.\n",
    "\n",
    "Je\u015bli wywo\u0142asz `forward` bezpo\u015brednio, ominiesz system hook\u00f3w (co zepsuje np. Profiling, Quantization i biblioteki typu Captum)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c98c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gotowy.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. Definiujemy prosty modu\u0142\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"   -> Wewn\u0105trz forward()\")\n",
    "        return self.fc(x)\n",
    "\n",
    "model = MyModule()\n",
    "x = torch.randn(1, 10)\n",
    "\n",
    "print(\"Model gotowy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29df5c80",
   "metadata": {},
   "source": [
    "## Eksperyment: Call vs Forward\n",
    "\n",
    "Zarejestrujemy \"Hooka\" (funkcj\u0119, kt\u00f3ra odpala si\u0119 automatycznie przy ka\u017cdym przej\u015bciu danych).\n",
    "Zobaczymy, \u017ce `forward()` go ignoruje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f19212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. U\u017cycie poprawne: model(x) ---\n",
      "   -> Wewn\u0105trz forward()\n",
      "\ud83d\udd75\ufe0f HOOK: Kto\u015b u\u017cywa modelu!\n",
      "\n",
      "--- 2. U\u017cycie b\u0142\u0119dne: model.forward(x) ---\n",
      "   -> Wewn\u0105trz forward()\n",
      "\n",
      "Wniosek: Widzisz? W drugim przypadku szpieg (Hook) nie zadzia\u0142a\u0142!\n"
     ]
    }
   ],
   "source": [
    "# Funkcja-szpieg (Hook)\n",
    "def spy_hook(module, input, output):\n",
    "    print(\"\ud83d\udd75\ufe0f HOOK: Kto\u015b u\u017cywa modelu!\")\n",
    "\n",
    "# Rejestrujemy hooka\n",
    "handle = model.register_forward_hook(spy_hook)\n",
    "\n",
    "print(\"--- 1. U\u017cycie poprawne: model(x) ---\")\n",
    "# To wywo\u0142uje __call__\n",
    "out1 = model(x)\n",
    "\n",
    "print(\"\\n--- 2. U\u017cycie b\u0142\u0119dne: model.forward(x) ---\")\n",
    "# To omija __call__\n",
    "out2 = model.forward(x)\n",
    "\n",
    "print(\"\\nWniosek: Widzisz? W drugim przypadku szpieg (Hook) nie zadzia\u0142a\u0142!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6869c2",
   "metadata": {},
   "source": [
    "## Magia Rejestracji (`__setattr__`)\n",
    "\n",
    "W zwyk\u0142ym Pythonie: `self.a = 5` po prostu przypisuje liczb\u0119 do obiektu.\n",
    "W `nn.Module`: `self.layer = nn.Linear(...)` robi co\u015b wi\u0119cej.\n",
    "\n",
    "PyTorch przechwytuje ka\u017cde przypisanie (`__setattr__`).\n",
    "1.  Sprawdza: \"Czy to, co przypisujesz, to `Parameter` lub `Module`?\".\n",
    "2.  Je\u015bli tak: Dodaje to do specjalnej listy `_parameters` lub `_modules`.\n",
    "3.  Dzi\u0119ki temu `model.parameters()` lub `model.to('cuda')` wie, co ma przenie\u015b\u0107, bez Twojej ingerencji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94f852e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CO WIDZI PYTORCH? (model.state_dict()) ---\n",
      "odict_keys(['parametr', 'warstwa.weight', 'warstwa.bias'])\n",
      "\n",
      "--- ANALIZA ---\n",
      "Widzisz 'parametr'? TAK.\n",
      "Widzisz 'warstwa.weight'? TAK.\n",
      "Widzisz 'zwykly_tensor'? NIE! (Nie zostanie zapisany przy save_model!)\n"
     ]
    }
   ],
   "source": [
    "class MagicModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. Zwyk\u0142a zmienna Pythonowa (Ignorowana przez PyTorch)\n",
    "        self.zwykla_zmienna = [1, 2, 3]\n",
    "        \n",
    "        # 2. Tensor (Te\u017c ignorowany! To cz\u0119sty b\u0142\u0105d!)\n",
    "        self.zwykly_tensor = torch.randn(3, 3)\n",
    "        \n",
    "        # 3. nn.Parameter (To jest \u015bledzone!)\n",
    "        self.parametr = nn.Parameter(torch.randn(3, 3))\n",
    "        \n",
    "        # 4. Podmodu\u0142 (To te\u017c jest \u015bledzone!)\n",
    "        self.warstwa = nn.Linear(3, 3)\n",
    "\n",
    "model_magic = MagicModule()\n",
    "\n",
    "print(\"--- CO WIDZI PYTORCH? (model.state_dict()) ---\")\n",
    "# state_dict() zwraca tylko to, co PyTorch uzna\u0142 za \"swoje\"\n",
    "print(model_magic.state_dict().keys())\n",
    "\n",
    "print(\"\\n--- ANALIZA ---\")\n",
    "print(\"Widzisz 'parametr'? TAK.\")\n",
    "print(\"Widzisz 'warstwa.weight'? TAK.\")\n",
    "print(\"Widzisz 'zwykly_tensor'? NIE! (Nie zostanie zapisany przy save_model!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b7b39",
   "metadata": {},
   "source": [
    "## Pu\u0142apka Listy (`list` vs `nn.ModuleList`)\n",
    "\n",
    "To jest b\u0142\u0105d, kt\u00f3ry pope\u0142nia ka\u017cdy junior.\n",
    "Chcesz mie\u0107 list\u0119 10 warstw. Piszesz:\n",
    "`self.layers = [nn.Linear(...) for _ in range(10)]`\n",
    "\n",
    "To **nie zadzia\u0142a**. PyTorch nie zagl\u0105da do \u015brodka zwyk\u0142ych list Pythona.\n",
    "Te warstwy nie b\u0119d\u0105 trenowane, nie trafi\u0105 na GPU.\n",
    "\n",
    "Musisz u\u017cy\u0107 **`nn.ModuleList`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7502cf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba parametr\u00f3w w BrokenNet: 0\n",
      "Wynik: 0. PyTorch 'nie widzi' warstw w li\u015bcie.\n",
      "Liczba parametr\u00f3w w FixedNet:  6\n",
      "Wynik: 6 (3 wagi + 3 biasy). Dzia\u0142a.\n"
     ]
    }
   ],
   "source": [
    "class BrokenNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Z\u0141E: Zwyk\u0142a lista\n",
    "        self.layers = [nn.Linear(10, 10) for _ in range(3)]\n",
    "\n",
    "class FixedNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # DOBRE: ModuleList\n",
    "        self.layers = nn.ModuleList([nn.Linear(10, 10) for _ in range(3)])\n",
    "\n",
    "bad = BrokenNet()\n",
    "good = FixedNet()\n",
    "\n",
    "print(f\"Liczba parametr\u00f3w w BrokenNet: {len(list(bad.parameters()))}\")\n",
    "print(\"Wynik: 0. PyTorch 'nie widzi' warstw w li\u015bcie.\")\n",
    "\n",
    "print(f\"Liczba parametr\u00f3w w FixedNet:  {len(list(good.parameters()))}\")\n",
    "print(\"Wynik: 6 (3 wagi + 3 biasy). Dzia\u0142a.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b5014c",
   "metadata": {},
   "source": [
    "## \ud83e\udd4b Black Belt Summary\n",
    "\n",
    "1.  **Zasada nr 1:** Zawsze u\u017cywaj `model(x)`, nigdy `model.forward(x)`.\n",
    "2.  **Rejestracja:** \u017beby tensor by\u0142 \"widziany\" przez PyTorch (trening, save/load, GPU), musi by\u0107 typu `nn.Parameter` lub by\u0107 przypisany do `nn.Module`.\n",
    "3.  **Kontenery:** Zwyk\u0142a lista `[]` lub s\u0142ownik `{}` ukrywaj\u0105 warstwy przed PyTorchem. U\u017cywaj `nn.ModuleList` i `nn.ModuleDict`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}