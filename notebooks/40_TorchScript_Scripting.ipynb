{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/takzen/pytorch-black-belt/blob/main/notebooks/40_TorchScript_Scripting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# \u2601\ufe0f COLAB SETUP (Automatyczna instalacja \u015brodowiska)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Sprawdzamy, czy jeste\u015bmy w Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('\u2601\ufe0f Wykryto \u015brodowisko Google Colab. Konfiguruj\u0119...')\n",
    "\n",
    "    # 1. Pobieramy plik requirements.txt bezpo\u015brednio z repozytorium\n",
    "    !wget -q https://raw.githubusercontent.com/takzen/ai-engineering-handbook/main/requirements.txt -O requirements.txt\n",
    "\n",
    "    # 2. Instalujemy biblioteki\n",
    "    print('\u23f3 Instaluj\u0119 zale\u017cno\u015bci (to mo\u017ce chwil\u0119 potrwa\u0107)...')\n",
    "    !pip install -q -r requirements.txt\n",
    "\n",
    "    print('\u2705 Gotowe! \u015arodowisko jest zgodne z repozytorium.')\n",
    "else:\n",
    "    print('\ud83d\udcbb Wykryto \u015brodowisko lokalne. Zak\u0142adam, \u017ce masz ju\u017c uv/venv.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d9430a",
   "metadata": {},
   "source": [
    "# \ud83e\udd4b Lekcja 40: TorchScript Scripting (Kompilacja Kodu)\n",
    "\n",
    "W poprzedniej lekcji `trace` zepsu\u0142 nasz model z `if`-em.\n",
    "Rozwi\u0105zaniem jest **`torch.jit.script`**.\n",
    "\n",
    "**Scripting** nie uruchamia modelu na pr\u00f3b\u0119. On **analizuje kod \u017ar\u00f3d\u0142owy** (AST - Abstract Syntax Tree).\n",
    "Widzi `if x > 0:` i t\u0142umaczy to na j\u0119zyk TorchScript (IR), zachowuj\u0105c logik\u0119 warunkow\u0105.\n",
    "\n",
    "**Wymagania:**\n",
    "Aby kod da\u0142 si\u0119 skompilowa\u0107, musi by\u0107 napisany w \"podzbiorze Pythona\" (TorchScript Language).\n",
    "*   Wszystkie typy musz\u0105 by\u0107 jawne (Type Hinting).\n",
    "*   Nie mo\u017cna u\u017cywa\u0107 niekt\u00f3rych dynamicznych funkcji Pythona (np. `try-except`, dynamiczne listy r\u00f3\u017cnych typ\u00f3w)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ca4a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gotowy.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Ten sam model co wcze\u015bniej\n",
    "class DynamicNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(10, 10)\n",
    "\n",
    "    # WA\u017bNE: W Scriptingu warto u\u017cywa\u0107 Type Hinting!\n",
    "    # M\u00f3wimy wprost: x to Tensor, zwracamy Tensor.\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if x.sum() > 0:\n",
    "            return self.linear(x) * 2\n",
    "        else:\n",
    "            return self.linear(x) - 100\n",
    "\n",
    "model = DynamicNet()\n",
    "print(\"Model gotowy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aa7aa2",
   "metadata": {},
   "source": [
    "## Kompilacja (`torch.jit.script`)\n",
    "\n",
    "Tym razem nie podajemy danych przyk\u0142adowych!\n",
    "Podajemy sam model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6985877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Model skompilowany (Scripting).\n",
      "<class 'torch.jit._script.RecursiveScriptModule'>\n"
     ]
    }
   ],
   "source": [
    "# SCRIPTING (Kompilacja kodu)\n",
    "scripted_model = torch.jit.script(model)\n",
    "\n",
    "print(\"\u2705 Model skompilowany (Scripting).\")\n",
    "print(type(scripted_model)) # RecursiveScriptModule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db9e6f9",
   "metadata": {},
   "source": [
    "## Inspekcja Kodu (IR)\n",
    "\n",
    "Zobaczmy `scripted_model.code`.\n",
    "Tym razem powiniene\u015b zobaczy\u0107 instrukcj\u0119 `if` wewn\u0105trz skompilowanego kodu!\n",
    "(B\u0119dzie wygl\u0105da\u0107 troch\u0119 dziwnie, np. `prim::If`, ale tam b\u0119dzie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f25cb74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- KOD TORCHSCRIPT ---\n",
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  if bool(torch.gt(torch.sum(x), 0)):\n",
      "    linear = self.linear\n",
      "    _0 = torch.mul((linear).forward(x, ), 2)\n",
      "  else:\n",
      "    linear0 = self.linear\n",
      "    _1 = torch.sub((linear0).forward(x, ), 100)\n",
      "    _0 = _1\n",
      "  return _0\n",
      "\n",
      "\n",
      "Widzisz instrukcj\u0119 'if'? To znaczy, \u017ce logika zosta\u0142a zachowana!\n"
     ]
    }
   ],
   "source": [
    "print(\"--- KOD TORCHSCRIPT ---\")\n",
    "print(scripted_model.code)\n",
    "\n",
    "print(\"\\nWidzisz instrukcj\u0119 'if'? To znaczy, \u017ce logika zosta\u0142a zachowana!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa78f24b",
   "metadata": {},
   "source": [
    "## Dow\u00f3d Poprawno\u015bci\n",
    "\n",
    "Sprawd\u017amy, czy model dzia\u0142a poprawnie zar\u00f3wno dla danych dodatnich, jak i ujemnych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec8b9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Positive:\n",
      "\u2705 Zgadza si\u0119.\n",
      "\n",
      "Test Negative (To wcze\u015bniej nie dzia\u0142a\u0142o):\n",
      "\u2705 Zgadza si\u0119! If dzia\u0142a.\n"
     ]
    }
   ],
   "source": [
    "# Dane dodatnie (\u015bcie\u017cka A)\n",
    "pos = torch.ones(1, 10)\n",
    "out_pos_py = model(pos)\n",
    "out_pos_jit = scripted_model(pos)\n",
    "\n",
    "# Dane ujemne (\u015bcie\u017cka B - ta, kt\u00f3ra w Tracingu nie dzia\u0142a\u0142a)\n",
    "neg = -torch.ones(1, 10)\n",
    "out_neg_py = model(neg)\n",
    "out_neg_jit = scripted_model(neg)\n",
    "\n",
    "print(\"Test Positive:\")\n",
    "if torch.allclose(out_pos_py, out_pos_jit):\n",
    "    print(\"\u2705 Zgadza si\u0119.\")\n",
    "\n",
    "print(\"\\nTest Negative (To wcze\u015bniej nie dzia\u0142a\u0142o):\")\n",
    "if torch.allclose(out_neg_py, out_neg_jit):\n",
    "    print(\"\u2705 Zgadza si\u0119! If dzia\u0142a.\")\n",
    "else:\n",
    "    print(\"\u274c B\u0142\u0105d.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92ac1d2",
   "metadata": {},
   "source": [
    "## Type Hinting: Pu\u0142apka\n",
    "\n",
    "Scripting jest restrykcyjny.\n",
    "Je\u015bli masz funkcj\u0119, kt\u00f3ra czasem zwraca `Tensor`, a czasem `List[Tensor]`, kompilator rzuci b\u0142\u0119dem.\n",
    "Musisz u\u017cywa\u0107 `Union`, `List`, `Tuple`, `Dict` z modu\u0142u `typing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef78228e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Uda\u0142o si\u0119 skompilowa\u0107 model z typami.\n",
      "tensor([2., 2., 2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "class StrictNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    # Musimy powiedzie\u0107 kompilatorowi, co wchodzi i co wychodzi\n",
    "    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        result = x * 2\n",
    "        # Zwracamy s\u0142ownik\n",
    "        return {\"output\": result}\n",
    "\n",
    "try:\n",
    "    s_net = torch.jit.script(StrictNet())\n",
    "    print(\"\u2705 Uda\u0142o si\u0119 skompilowa\u0107 model z typami.\")\n",
    "    \n",
    "    # Test\n",
    "    out = s_net(torch.ones(5))\n",
    "    print(out[\"output\"])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"B\u0142\u0105d kompilacji: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e78a7a",
   "metadata": {},
   "source": [
    "## \ud83e\udd4b Black Belt Summary\n",
    "\n",
    "1.  **`trace` vs `script`:**\n",
    "    *   U\u017cywaj `trace` zawsze, gdy mo\u017cesz (jest prostszy, obs\u0142uguje wi\u0119cej bibliotek Pythonowych).\n",
    "    *   U\u017cywaj `script` tylko wtedy, gdy masz `control flow` (if, for) zale\u017cne od danych wej\u015bciowych.\n",
    "2.  **Mieszanie:** Mo\u017cesz miesza\u0107 obie metody!\n",
    "    ```python\n",
    "    @torch.jit.script\n",
    "    def complex_logic(x):\n",
    "        if x > 0: return x\n",
    "        else: return -x\n",
    "\n",
    "    class MyModel(nn.Module):\n",
    "        def forward(self, x):\n",
    "            x = complex_logic(x) # To jest skryptowane\n",
    "            return self.layer(x) # Reszt\u0119 mo\u017cna trace'owa\u0107\n",
    "    ```\n",
    "3.  **Deployment:** Skompilowany model (`.save()`) mo\u017cna za\u0142adowa\u0107 w C++ u\u017cywaj\u0105c `torch::jit::load()`. Tak dzia\u0142a AI w samochodach autonomicznych i robotach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}