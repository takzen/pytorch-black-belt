{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/takzen/pytorch-black-belt/blob/main/notebooks/26_Dynamic_Control_Flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# \u2601\ufe0f COLAB SETUP (Automatyczna instalacja \u015brodowiska)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Sprawdzamy, czy jeste\u015bmy w Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('\u2601\ufe0f Wykryto \u015brodowisko Google Colab. Konfiguruj\u0119...')\n",
    "\n",
    "    # 1. Pobieramy plik requirements.txt bezpo\u015brednio z repozytorium\n",
    "    !wget -q https://raw.githubusercontent.com/takzen/ai-engineering-handbook/main/requirements.txt -O requirements.txt\n",
    "\n",
    "    # 2. Instalujemy biblioteki\n",
    "    print('\u23f3 Instaluj\u0119 zale\u017cno\u015bci (to mo\u017ce chwil\u0119 potrwa\u0107)...')\n",
    "    !pip install -q -r requirements.txt\n",
    "\n",
    "    print('\u2705 Gotowe! \u015arodowisko jest zgodne z repozytorium.')\n",
    "else:\n",
    "    print('\ud83d\udcbb Wykryto \u015brodowisko lokalne. Zak\u0142adam, \u017ce masz ju\u017c uv/venv.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42fe69d",
   "metadata": {},
   "source": [
    "# \ud83e\udd4b Lekcja 26: Dynamic Control Flow (Python wewn\u0105trz sieci)\n",
    "\n",
    "W PyTorch metoda `forward()` to zwyk\u0142y kod Python.\n",
    "Mo\u017cesz u\u017cywa\u0107 `if`, `for`, `while`, a nawet `print()`.\n",
    "\n",
    "**Jak to dzia\u0142a?**\n",
    "Graf obliczeniowy nie jest budowany raz na zawsze na pocz\u0105tku.\n",
    "Jest budowany **od nowa przy ka\u017cdym przej\u015bciu `forward`**.\n",
    "\n",
    "*   Je\u015bli w Iteracji 1 wejdziesz do `if`: Graf zawiera ga\u0142\u0105\u017a A.\n",
    "*   Je\u015bli w Iteracji 2 wejdziesz do `else`: Graf zawiera ga\u0142\u0105\u017a B.\n",
    "\n",
    "To pozwala na budowanie **Dynamicznych Sieci Neuronowych**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3317419c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urz\u0105dzenie: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Konfiguracja\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Urz\u0105dzenie: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a253871",
   "metadata": {},
   "source": [
    "## Eksperyment 1: Warunek `if` (Data-Dependent Control Flow)\n",
    "\n",
    "Stworzymy sie\u0107 \"Dziwaczn\u0105\".\n",
    "*   Je\u015bli suma wej\u015bcia jest dodatnia -> U\u017cyj warstwy `fc_pos`.\n",
    "*   Je\u015bli suma wej\u015bcia jest ujemna -> U\u017cyj warstwy `fc_neg`.\n",
    "\n",
    "Silnik Autograd musi poradzi\u0107 sobie z tym, \u017ce w jednej iteracji u\u017cywamy jednych wag, a w drugiej innych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6c365d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> \u015acie\u017cka POZYTYWNA\n",
      "Gradient fc_pos: 1.0\n",
      "Gradient fc_neg: None\n",
      "--------------------\n",
      "   -> \u015acie\u017cka NEGATYWNA\n",
      "Gradient fc_pos: None\n",
      "Gradient fc_neg: -1.0\n"
     ]
    }
   ],
   "source": [
    "class WeirdNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc_pos = nn.Linear(10, 1) # Dla liczb dodatnich\n",
    "        self.fc_neg = nn.Linear(10, 1) # Dla liczb ujemnych\n",
    "        \n",
    "        # Inicjalizacja dla rozr\u00f3\u017cnienia\n",
    "        nn.init.constant_(self.fc_pos.weight, 1.0)\n",
    "        nn.init.constant_(self.fc_neg.weight, -1.0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # LOGIKA PYTHONOWA W \u015aRODKU SIECI\n",
    "        s = x.sum()\n",
    "        \n",
    "        if s > 0:\n",
    "            print(\"   -> \u015acie\u017cka POZYTYWNA\")\n",
    "            x = self.fc_pos(x)\n",
    "        else:\n",
    "            print(\"   -> \u015acie\u017cka NEGATYWNA\")\n",
    "            x = self.fc_neg(x)\n",
    "            \n",
    "        return x\n",
    "\n",
    "model = WeirdNet().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Test 1: Dane dodatnie\n",
    "input_pos = torch.ones(1, 10).to(DEVICE)\n",
    "out_pos = model(input_pos)\n",
    "out_pos.backward()\n",
    "\n",
    "print(f\"Gradient fc_pos: {model.fc_pos.weight.grad[0,0]}\") # Powinien by\u0107 (1.0)\n",
    "print(f\"Gradient fc_neg: {model.fc_neg.weight.grad}\")      # Powinien by\u0107 None (nieu\u017cywany)\n",
    "\n",
    "# Czy\u015bcimy\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Test 2: Dane ujemne\n",
    "print(\"-\" * 20)\n",
    "input_neg = -torch.ones(1, 10).to(DEVICE)\n",
    "out_neg = model(input_neg)\n",
    "out_neg.backward()\n",
    "\n",
    "print(f\"Gradient fc_pos: {model.fc_pos.weight.grad}\")      # Teraz to jest None/0\n",
    "print(f\"Gradient fc_neg: {model.fc_neg.weight.grad[0,0]}\") # Teraz to ma warto\u015b\u0107 (-1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55002626",
   "metadata": {},
   "source": [
    "## Eksperyment 2: P\u0119tla `for` (Weight Sharing w czasie)\n",
    "\n",
    "To jest fundament sieci RNN.\n",
    "U\u017cywamy **tej samej warstwy** wielokrotnie w p\u0119tli.\n",
    "\n",
    "PyTorch jest na tyle sprytny, \u017ce wie: *\"U\u017cy\u0142e\u015b tej warstwy 5 razy. Podczas `backward` musz\u0119 zsumowa\u0107 gradienty z tych 5 u\u017cy\u0107\"*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92ca9659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model z p\u0119tl\u0105 dzia\u0142a.\n",
      "Gradient wagi (istnieje?): True\n"
     ]
    }
   ],
   "source": [
    "class LoopNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(10, 10) # Jedna warstwa\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, steps: int) -> torch.Tensor:\n",
    "        # Dynamiczna p\u0119tla - liczba krok\u00f3w zale\u017cy od argumentu wywo\u0142ania!\n",
    "        for i in range(steps):\n",
    "            x = self.fc(x)\n",
    "            # Mo\u017cemy nawet zrobi\u0107 co\u015b szalonego:\n",
    "            if x.mean() > 100:\n",
    "                print(f\"   (Przerwanie p\u0119tli w kroku {i} - wybuch warto\u015bci)\")\n",
    "                break\n",
    "        return x\n",
    "\n",
    "loop_model = LoopNet().to(DEVICE)\n",
    "\n",
    "# Uruchamiamy na 3 kroki\n",
    "x = torch.randn(1, 10).to(DEVICE)\n",
    "out = loop_model(x, steps=3)\n",
    "out.sum().backward()\n",
    "\n",
    "print(\"Model z p\u0119tl\u0105 dzia\u0142a.\")\n",
    "print(f\"Gradient wagi (istnieje?): {loop_model.fc.weight.grad is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064969fc",
   "metadata": {},
   "source": [
    "## Pu\u0142apka: Wydajno\u015b\u0107 i Eksport\n",
    "\n",
    "Dynamiczne grafy s\u0105 super do debugowania i bada\u0144. Ale maj\u0105 wad\u0119 na produkcji.\n",
    "\n",
    "1.  **Brak optymalizacji:** Kompilator nie wie, co si\u0119 stanie (czy wejdziemy w `if`, ile razy obr\u00f3ci si\u0119 `for`). Trudno z\u0142\u0105czy\u0107 operacje (Operator Fusion).\n",
    "2.  **Eksport (ONNX):** ONNX woli statyczne grafy. Eksport modelu z `if x.sum() > 0` mo\u017ce by\u0107 trudny lub niemo\u017cliwy (trzeba u\u017cywa\u0107 `torch.jit.script` zamiast `trace`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec3a372a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Dow\u00f3d 1] Skompilowany kod (IR):\n",
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  s = torch.sum(x)\n",
      "  if bool(torch.gt(s, 0)):\n",
      "    print(CONSTANTS.c0)\n",
      "    fc_pos = self.fc_pos\n",
      "    x0 = (fc_pos).forward(x, )\n",
      "  else:\n",
      "    print(CONSTANTS.c1)\n",
      "    fc_neg = self.fc_neg\n",
      "    x0 = (fc_neg).forward(x, )\n",
      "  return x0\n",
      "\n",
      "[Dow\u00f3d 2] Uruchomienie na danych ujemnych...\n",
      "   -> \u015acie\u017cka NEGATYWNA\n",
      "\u015arednia warto\u015b\u0107 wyniku: 10.278833389282227\n",
      "\u2705 SUKCES: Wynik dodatni. Model poprawnie wybra\u0142 \u015bcie\u017ck\u0119 'else' (fc_neg).\n"
     ]
    }
   ],
   "source": [
    "# 1. Kompilacja (Scripting)\n",
    "# Analizuje AST (drzewo sk\u0142adniowe) Pythona i kompiluje logik\u0119.\n",
    "scripted_model = torch.jit.script(model)\n",
    "\n",
    "# 2. Dow\u00f3d 1: Inspekcja Kodu\n",
    "# Wy\u015bwietlamy to, jak TorchScript \"zrozumia\u0142\" nasz model.\n",
    "# Powiniene\u015b zobaczy\u0107 instrukcj\u0119: \"if bool(torch.gt(s, 0.)):\"\n",
    "print(\"\\n[Dow\u00f3d 1] Skompilowany kod (IR):\")\n",
    "print(scripted_model.code)\n",
    "\n",
    "# 3. Dow\u00f3d 2: Test Numeryczny\n",
    "print(\"[Dow\u00f3d 2] Uruchomienie na danych ujemnych...\")\n",
    "# Wej\u015bcie: same -1.\n",
    "# \u015acie\u017cka Positive (Waga 1.0): -1 * 1 = -1\n",
    "# \u015acie\u017cka Negative (Waga -1.0): -1 * -1 = 1 (Tego oczekujemy)\n",
    "\n",
    "out_jit = scripted_model(input_neg)\n",
    "mean_val = out_jit.mean().item()\n",
    "\n",
    "print(f\"\u015arednia warto\u015b\u0107 wyniku: {mean_val}\")\n",
    "\n",
    "if mean_val > 0:\n",
    "    print(\"\u2705 SUKCES: Wynik dodatni. Model poprawnie wybra\u0142 \u015bcie\u017ck\u0119 'else' (fc_neg).\")\n",
    "else:\n",
    "    print(\"\u274c B\u0141\u0104D: Wynik ujemny. Model b\u0142\u0119dnie poszed\u0142 \u015bcie\u017ck\u0105 'if' (fc_pos).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3e0065",
   "metadata": {},
   "source": [
    "## \ud83e\udd4b Black Belt Summary\n",
    "\n",
    "1.  **Define-by-Run:** PyTorch buduje graf w locie. To pozwala na u\u017cywanie natywnego Pythona (`if`, `for`, `print`).\n",
    "2.  **Gradienty:** Autograd automatycznie radzi sobie z warunkowo\u015bci\u0105. Nieu\u017cywane ga\u0142\u0119zie nie dostaj\u0105 gradient\u00f3w. Wielokrotnie u\u017cywane warstwy (p\u0119tle) akumuluj\u0105 gradienty.\n",
    "3.  **Cena:** Dynamiczne grafy s\u0105 trudniejsze do zoptymalizowania (`torch.compile`) i wyeksportowania (`ONNX`).\n",
    "    *   Je\u015bli musisz eksportowa\u0107 logik\u0119 `if`, u\u017cywaj **`torch.jit.script`**, a nie `trace`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}