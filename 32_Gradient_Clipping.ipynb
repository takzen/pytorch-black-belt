{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n<a href=\"https://colab.research.google.com/github/takzen/pytorch-black-belt/blob/main/32_Gradient_Clipping.ipynb\" target=\"_parent\">\n    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# \u2601\ufe0f COLAB SETUP (Automatyczna instalacja \u015brodowiska)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Sprawdzamy, czy jeste\u015bmy w Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('\u2601\ufe0f Wykryto \u015brodowisko Google Colab. Konfiguruj\u0119...')\n",
    "\n",
    "    # 1. Pobieramy plik requirements.txt bezpo\u015brednio z repozytorium\n",
    "    !wget -q https://raw.githubusercontent.com/takzen/ai-engineering-handbook/main/requirements.txt -O requirements.txt\n",
    "\n",
    "    # 2. Instalujemy biblioteki\n",
    "    print('\u23f3 Instaluj\u0119 zale\u017cno\u015bci (to mo\u017ce chwil\u0119 potrwa\u0107)...')\n",
    "    !pip install -q -r requirements.txt\n",
    "\n",
    "    print('\u2705 Gotowe! \u015arodowisko jest zgodne z repozytorium.')\n",
    "else:\n",
    "    print('\ud83d\udcbb Wykryto \u015brodowisko lokalne. Zak\u0142adam, \u017ce masz ju\u017c uv/venv.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71305d1e",
   "metadata": {},
   "source": [
    "# \ud83e\udd4b Lekcja 32: Gradient Clipping (Ratunek przed wybuchem)\n",
    "\n",
    "W g\u0142\u0119bokich sieciach (szczeg\u00f3lnie RNN i Transformerach) zdarza si\u0119 zjawisko **Exploding Gradients**.\n",
    "Pochodna w jednym kroku wynosi np. `1000`. Wagi zmieniaj\u0105 si\u0119 drastycznie. Sie\u0107 \"wylatuje z toru\" i zwraca `NaN`.\n",
    "\n",
    "**Rozwi\u0105zanie: Gradient Clipping.**\n",
    "Sprawdzamy **norm\u0119** (d\u0142ugo\u015b\u0107) wektora wszystkich gradient\u00f3w.\n",
    "Je\u015bli jest wi\u0119ksza ni\u017c pr\u00f3g (np. 1.0), skalujemy wszystkie gradienty w d\u00f3\u0142, zachowuj\u0105c ich kierunek.\n",
    "\n",
    "Wz\u00f3r:\n",
    "$$ g_{new} = g \\cdot \\frac{\\text{max\\_norm}}{\\max(\\text{max\\_norm}, ||g||)} $$\n",
    "\n",
    "PyTorch robi to jedn\u0105 funkcj\u0105: `torch.nn.utils.clip_grad_norm_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f0bcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient przed ci\u0119ciem: 4000.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. Symulacja problemu (Wybuchaj\u0105cy gradient)\n",
    "# Prosta waga, kt\u00f3ra ma du\u017cy gradient\n",
    "w = torch.tensor([10.0], requires_grad=True)\n",
    "\n",
    "# Symulujemy strat\u0119, kt\u00f3ra jest bardzo stroma\n",
    "# loss = w^4 -> grad = 4*w^3\n",
    "# dla w=10 -> grad = 4000\n",
    "loss = w**4\n",
    "loss.backward()\n",
    "\n",
    "print(f\"Gradient przed ci\u0119ciem: {w.grad.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f26baf",
   "metadata": {},
   "source": [
    "## Clipping w akcji\n",
    "\n",
    "U\u017cyjemy `clip_grad_norm_`.\n",
    "Ta funkcja dzia\u0142a **In-Place** na parametrach (modyfikuje `.grad` bezpo\u015brednio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a444fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient po ci\u0119ciu: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 2. Przycinanie\n",
    "# max_norm=1.0 -> Chcemy, \u017ceby d\u0142ugo\u015b\u0107 wektora gradient\u00f3w nie przekracza\u0142a 1.0\n",
    "torch.nn.utils.clip_grad_norm_([w], max_norm=1.0)\n",
    "\n",
    "print(f\"Gradient po ci\u0119ciu: {w.grad.item()}\")\n",
    "\n",
    "# Sprawd\u017amy, czy kierunek si\u0119 zachowa\u0142 (dla skalara to tylko znak)\n",
    "# By\u0142o 4000 (+), jest 1.0 (+). Jest ok."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8ced99",
   "metadata": {},
   "source": [
    "## Clipping w p\u0119tli treningowej (Wzorzec)\n",
    "\n",
    "Gdzie wstawi\u0107 clipping w kodzie?\n",
    "**Pomi\u0119dzy** `backward()` a `step()`.\n",
    "\n",
    "1.  `loss.backward()` (Policz gradienty).\n",
    "2.  `clip_grad_norm_()` (Przytnij je, je\u015bli s\u0105 za du\u017ce).\n",
    "3.  `optimizer.step()` (Zr\u00f3b krok z bezpiecznymi gradientami)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56f54814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- P\u0119tla z Clippingiem ---\n",
      "Krok 0: Norma gradientu = 0.7192\n",
      "Krok 1: Norma gradientu = 0.7104\n",
      "Krok 2: Norma gradientu = 0.6965\n",
      "Trening stabilny.\n"
     ]
    }
   ],
   "source": [
    "# Symulacja p\u0119tli z sieci\u0105 RNN (kt\u00f3re cz\u0119sto wybuchaj\u0105)\n",
    "model = nn.RNN(input_size=10, hidden_size=20, batch_first=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Losowe dane\n",
    "inputs = torch.randn(5, 10, 10) # [Batch, Seq, Feat]\n",
    "target = torch.randn(5, 20)     # [Batch, Hidden]\n",
    "\n",
    "print(\"--- P\u0119tla z Clippingiem ---\")\n",
    "\n",
    "for step in range(3):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output, _ = model(inputs)\n",
    "    # Bierzemy ostatni krok czasu\n",
    "    loss = (output[:, -1, :] - target).pow(2).mean()\n",
    "    \n",
    "    # 1. Liczymy gradienty\n",
    "    loss.backward()\n",
    "    \n",
    "    # Sprawd\u017amy norm\u0119 przed ci\u0119ciem (dla ciekawo\u015bci)\n",
    "    # Obliczamy norm\u0119 wszystkich parametr\u00f3w naraz\n",
    "    total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), 2) for p in model.parameters() if p.grad is not None]), 2)\n",
    "    print(f\"Krok {step}: Norma gradientu = {total_norm:.4f}\")\n",
    "    \n",
    "    # 2. PRZYCINAMY (Bezpiecznik)\n",
    "    # Zazwyczaj max_norm ustawia si\u0119 na 1.0 lub 5.0\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    \n",
    "    # 3. Aktualizacja\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Trening stabilny.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b33b6d",
   "metadata": {},
   "source": [
    "## Clipping by Value vs by Norm\n",
    "\n",
    "S\u0105 dwie metody:\n",
    "1.  **`clip_grad_norm_` (Zalecane):** Skaluje ca\u0142y wektor gradient\u00f3w. Zachowuje **kierunek** update'u.\n",
    "2.  **`clip_grad_value_`:** Ucina ka\u017cd\u0105 liczb\u0119 z osobna (np. min -1, max 1). Zmienia kierunek wektora!\n",
    "\n",
    "Zazwyczaj u\u017cywamy **Norm**, bo chcemy i\u015b\u0107 w dobr\u0105 stron\u0119, tylko wolniej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc6268d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orygina\u0142: [10.0, 1.0]\n",
      "Po Norm Clip:  [10.0, 1.0] (Proporcja zachowana - to jest bezpieczne)\n",
      "Po Value Clip: [5.0, 1.0]  (Kierunek ZMIENIONY! - 10 spad\u0142o do 5, a 1 zosta\u0142o 1)\n"
     ]
    }
   ],
   "source": [
    "# Demonstracja zmiany kierunku przy Value Clipping\n",
    "g = torch.tensor([10.0, 1.0]) # Wektor [10, 1]. Kierunek dominuje o\u015b X.\n",
    "\n",
    "# Kopia do test\u00f3w\n",
    "g_norm = g.clone()\n",
    "g_val = g.clone()\n",
    "\n",
    "# 1. Norm Clipping (max_norm=5)\n",
    "# Skalujemy ca\u0142y wektor, \u017ceby jego d\u0142ugo\u015b\u0107 (hipotenusa) wynosi\u0142a 5.\n",
    "# Proporcje 10:1 zostan\u0105 zachowane (kierunek ten sam).\n",
    "torch.nn.utils.clip_grad_norm_([g_norm], max_norm=5.0)\n",
    "\n",
    "# 2. Value Clipping (max_value=5)\n",
    "# Zamiast clip_grad_value_ (kt\u00f3re wymaga parametru z .grad), \n",
    "# u\u017cywamy .clamp_, co robi matematycznie to samo na surowym tensorze.\n",
    "# Ucinamy ka\u017cd\u0105 liczb\u0119, kt\u00f3ra jest wi\u0119ksza ni\u017c 5 lub mniejsza ni\u017c -5.\n",
    "g_val.clamp_(-5.0, 5.0) \n",
    "\n",
    "print(f\"Orygina\u0142: {g.tolist()}\")\n",
    "print(f\"Po Norm Clip:  {g_norm.tolist()} (Proporcja zachowana - to jest bezpieczne)\")\n",
    "print(f\"Po Value Clip: {g_val.tolist()}  (Kierunek ZMIENIONY! - 10 spad\u0142o do 5, a 1 zosta\u0142o 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8125ddbe",
   "metadata": {},
   "source": [
    "## \ud83e\udd4b Black Belt Summary\n",
    "\n",
    "1.  **Zawsze u\u017cywaj `clip_grad_norm_`** przy trenowaniu **RNN, LSTM, GRU i Transformer\u00f3w** (np. GPT). Te sieci s\u0105 g\u0142\u0119bokie w czasie i gradienty lubi\u0105 si\u0119 tam kumulowa\u0107.\n",
    "2.  **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}