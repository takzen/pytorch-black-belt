{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71305d1e",
   "metadata": {},
   "source": [
    "#  Lekcja 32: Gradient Clipping (Ratunek przed wybuchem)\n",
    "\n",
    "W gbokich sieciach (szczeg贸lnie RNN i Transformerach) zdarza si zjawisko **Exploding Gradients**.\n",
    "Pochodna w jednym kroku wynosi np. `1000`. Wagi zmieniaj si drastycznie. Sie \"wylatuje z toru\" i zwraca `NaN`.\n",
    "\n",
    "**Rozwizanie: Gradient Clipping.**\n",
    "Sprawdzamy **norm** (dugo) wektora wszystkich gradient贸w.\n",
    "Jeli jest wiksza ni偶 pr贸g (np. 1.0), skalujemy wszystkie gradienty w d贸, zachowujc ich kierunek.\n",
    "\n",
    "Wz贸r:\n",
    "$$ g_{new} = g \\cdot \\frac{\\text{max\\_norm}}{\\max(\\text{max\\_norm}, ||g||)} $$\n",
    "\n",
    "PyTorch robi to jedn funkcj: `torch.nn.utils.clip_grad_norm_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f0bcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient przed ciciem: 4000.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. Symulacja problemu (Wybuchajcy gradient)\n",
    "# Prosta waga, kt贸ra ma du偶y gradient\n",
    "w = torch.tensor([10.0], requires_grad=True)\n",
    "\n",
    "# Symulujemy strat, kt贸ra jest bardzo stroma\n",
    "# loss = w^4 -> grad = 4*w^3\n",
    "# dla w=10 -> grad = 4000\n",
    "loss = w**4\n",
    "loss.backward()\n",
    "\n",
    "print(f\"Gradient przed ciciem: {w.grad.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f26baf",
   "metadata": {},
   "source": [
    "## Clipping w akcji\n",
    "\n",
    "U偶yjemy `clip_grad_norm_`.\n",
    "Ta funkcja dziaa **In-Place** na parametrach (modyfikuje `.grad` bezporednio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a444fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient po ciciu: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 2. Przycinanie\n",
    "# max_norm=1.0 -> Chcemy, 偶eby dugo wektora gradient贸w nie przekraczaa 1.0\n",
    "torch.nn.utils.clip_grad_norm_([w], max_norm=1.0)\n",
    "\n",
    "print(f\"Gradient po ciciu: {w.grad.item()}\")\n",
    "\n",
    "# Sprawd藕my, czy kierunek si zachowa (dla skalara to tylko znak)\n",
    "# Byo 4000 (+), jest 1.0 (+). Jest ok."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8ced99",
   "metadata": {},
   "source": [
    "## Clipping w ptli treningowej (Wzorzec)\n",
    "\n",
    "Gdzie wstawi clipping w kodzie?\n",
    "**Pomidzy** `backward()` a `step()`.\n",
    "\n",
    "1.  `loss.backward()` (Policz gradienty).\n",
    "2.  `clip_grad_norm_()` (Przytnij je, jeli s za du偶e).\n",
    "3.  `optimizer.step()` (Zr贸b krok z bezpiecznymi gradientami)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56f54814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ptla z Clippingiem ---\n",
      "Krok 0: Norma gradientu = 0.7192\n",
      "Krok 1: Norma gradientu = 0.7104\n",
      "Krok 2: Norma gradientu = 0.6965\n",
      "Trening stabilny.\n"
     ]
    }
   ],
   "source": [
    "# Symulacja ptli z sieci RNN (kt贸re czsto wybuchaj)\n",
    "model = nn.RNN(input_size=10, hidden_size=20, batch_first=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Losowe dane\n",
    "inputs = torch.randn(5, 10, 10) # [Batch, Seq, Feat]\n",
    "target = torch.randn(5, 20)     # [Batch, Hidden]\n",
    "\n",
    "print(\"--- Ptla z Clippingiem ---\")\n",
    "\n",
    "for step in range(3):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output, _ = model(inputs)\n",
    "    # Bierzemy ostatni krok czasu\n",
    "    loss = (output[:, -1, :] - target).pow(2).mean()\n",
    "    \n",
    "    # 1. Liczymy gradienty\n",
    "    loss.backward()\n",
    "    \n",
    "    # Sprawd藕my norm przed ciciem (dla ciekawoci)\n",
    "    # Obliczamy norm wszystkich parametr贸w naraz\n",
    "    total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), 2) for p in model.parameters() if p.grad is not None]), 2)\n",
    "    print(f\"Krok {step}: Norma gradientu = {total_norm:.4f}\")\n",
    "    \n",
    "    # 2. PRZYCINAMY (Bezpiecznik)\n",
    "    # Zazwyczaj max_norm ustawia si na 1.0 lub 5.0\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    \n",
    "    # 3. Aktualizacja\n",
    "    optimizer.step()\n",
    "\n",
    "print(\"Trening stabilny.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b33b6d",
   "metadata": {},
   "source": [
    "## Clipping by Value vs by Norm\n",
    "\n",
    "S dwie metody:\n",
    "1.  **`clip_grad_norm_` (Zalecane):** Skaluje cay wektor gradient贸w. Zachowuje **kierunek** update'u.\n",
    "2.  **`clip_grad_value_`:** Ucina ka偶d liczb z osobna (np. min -1, max 1). Zmienia kierunek wektora!\n",
    "\n",
    "Zazwyczaj u偶ywamy **Norm**, bo chcemy i w dobr stron, tylko wolniej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc6268d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orygina: [10.0, 1.0]\n",
      "Po Norm Clip:  [10.0, 1.0] (Proporcja zachowana - to jest bezpieczne)\n",
      "Po Value Clip: [5.0, 1.0]  (Kierunek ZMIENIONY! - 10 spado do 5, a 1 zostao 1)\n"
     ]
    }
   ],
   "source": [
    "# Demonstracja zmiany kierunku przy Value Clipping\n",
    "g = torch.tensor([10.0, 1.0]) # Wektor [10, 1]. Kierunek dominuje o X.\n",
    "\n",
    "# Kopia do test贸w\n",
    "g_norm = g.clone()\n",
    "g_val = g.clone()\n",
    "\n",
    "# 1. Norm Clipping (max_norm=5)\n",
    "# Skalujemy cay wektor, 偶eby jego dugo (hipotenusa) wynosia 5.\n",
    "# Proporcje 10:1 zostan zachowane (kierunek ten sam).\n",
    "torch.nn.utils.clip_grad_norm_([g_norm], max_norm=5.0)\n",
    "\n",
    "# 2. Value Clipping (max_value=5)\n",
    "# Zamiast clip_grad_value_ (kt贸re wymaga parametru z .grad), \n",
    "# u偶ywamy .clamp_, co robi matematycznie to samo na surowym tensorze.\n",
    "# Ucinamy ka偶d liczb, kt贸ra jest wiksza ni偶 5 lub mniejsza ni偶 -5.\n",
    "g_val.clamp_(-5.0, 5.0) \n",
    "\n",
    "print(f\"Orygina: {g.tolist()}\")\n",
    "print(f\"Po Norm Clip:  {g_norm.tolist()} (Proporcja zachowana - to jest bezpieczne)\")\n",
    "print(f\"Po Value Clip: {g_val.tolist()}  (Kierunek ZMIENIONY! - 10 spado do 5, a 1 zostao 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8125ddbe",
   "metadata": {},
   "source": [
    "##  Black Belt Summary\n",
    "\n",
    "1.  **Zawsze u偶ywaj `clip_grad_norm_`** przy trenowaniu **RNN, LSTM, GRU i Transformer贸w** (np. GPT). Te sieci s gbokie w czasie i gradienty lubi si tam kumulowa.\n",
    "2.  **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
