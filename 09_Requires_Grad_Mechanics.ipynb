{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec9a512",
   "metadata": {},
   "source": [
    "#  Lekcja 9: Requires Grad & Inference Mode (Zarzdzanie Pamici)\n",
    "\n",
    "Ka偶dy tensor w PyTorch ma flag `requires_grad`.\n",
    "*   `True`: PyTorch alokuje dodatkow pami na graf obliczeniowy.\n",
    "*   `False`: Tensor zachowuje si jak zwyka macierz NumPy (lekki).\n",
    "\n",
    "Podczas **treningu** chcemy `True` (dla wag).\n",
    "Podczas **u偶ywania (Inference)** chcemy `False` (偶eby nie zapcha pamici).\n",
    "\n",
    "Mamy trzy sposoby na kontrolowanie tego:\n",
    "1.  **.detach():** Fizyczne oderwanie tensora od grafu.\n",
    "2.  **with torch.no_grad():** Klasyczny spos贸b na wyczenie silnika Autograd.\n",
    "3.  **with torch.inference_mode():** Nowoczesny, ekstremalnie zoptymalizowany tryb dla produkcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54dccf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wagi (w) requires_grad: True\n",
      "Dane (x) requires_grad: False\n",
      "Wynik (y) requires_grad: True\n",
      "Funkcja y: <MmBackward0 object at 0x0000014F58561780>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. Tensor, kt贸ry chce si uczy (Wagi)\n",
    "w = torch.randn(5, 5, requires_grad=True)\n",
    "\n",
    "# 2. Tensor, kt贸ry jest danymi (Input)\n",
    "x = torch.randn(5, 5) # Domylnie requires_grad=False\n",
    "\n",
    "print(f\"Wagi (w) requires_grad: {w.requires_grad}\")\n",
    "print(f\"Dane (x) requires_grad: {x.requires_grad}\")\n",
    "\n",
    "# Operacja\n",
    "y = w @ x\n",
    "\n",
    "# Wynik \"dziedziczy\" ch uczenia si po rodzicach!\n",
    "# Skoro 'w' wymagao gradientu, to 'y' te偶 go wymaga (偶eby policzy pochodn dla 'w').\n",
    "print(f\"Wynik (y) requires_grad: {y.requires_grad}\")\n",
    "print(f\"Funkcja y: {y.grad_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf1519d",
   "metadata": {},
   "source": [
    "## 1. Metoda `.detach()` (Chirurgiczne cicie)\n",
    "\n",
    "U偶ywamy tego, gdy chcemy przerwa przepyw gradient贸w w poowie sieci.\n",
    "Czsty przypadek: **GAN-y** lub **Transfer Learning** (zamra偶anie czci sieci).\n",
    "\n",
    "`.detach()` zwraca nowy tensor, kt贸ry dzieli t sam pami, ale **nie ma historii**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c275a081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orygina y: <MmBackward0 object at 0x0000014F58562E90> (Ma histori)\n",
      "Odcity z:  None (Brak historii)\n",
      "Czy z wymaga gradientu? False\n",
      "\n",
      "--- TEST PAMICI ---\n",
      "Zmienilimy z[0,0]. Sprawd藕my y[0,0]: 999.0\n",
      "Uwaga: .detach() nie kopiuje danych! Zmiana w 'z' zmienia 'y'.\n"
     ]
    }
   ],
   "source": [
    "# Mamy y, kt贸re jest czci grafu\n",
    "print(f\"Orygina y: {y.grad_fn} (Ma histori)\")\n",
    "\n",
    "# Odcinamy\n",
    "z = y.detach()\n",
    "\n",
    "print(f\"Odcity z:  {z.grad_fn} (Brak historii)\")\n",
    "print(f\"Czy z wymaga gradientu? {z.requires_grad}\")\n",
    "\n",
    "# Dow贸d na wsp贸dzielenie pamici (Uwa偶aj na in-place!)\n",
    "print(\"\\n--- TEST PAMICI ---\")\n",
    "z[0, 0] = 999\n",
    "print(f\"Zmienilimy z[0,0]. Sprawd藕my y[0,0]: {y[0,0]}\")\n",
    "print(\"Uwaga: .detach() nie kopiuje danych! Zmiana w 'z' zmienia 'y'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfe4ef2",
   "metadata": {},
   "source": [
    "## 2. `no_grad()` vs `inference_mode()`\n",
    "\n",
    "To s mened偶ery kontekstu (`with ...`).\n",
    "\n",
    "*   **`torch.no_grad()`**: Tylko ustawia `requires_grad=False` dla nowych tensor贸w. Ale nadal pozwala na pewne operacje, kt贸re mog by potrzebne do `backward` w przyszoci.\n",
    "*   **`torch.inference_mode()` (ZALECANE)**: Wycza wszystko. Nie mo偶na u偶y wyniku z tego bloku do 偶adnego treningu. Dziki temu PyTorch mo偶e pomin np. ledzenie wersji (Version Counter), co przyspiesza kod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d339b96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- NO GRAD ---\n",
      "Czy wymaga gradientu? False\n",
      "\n",
      "--- INFERENCE MODE (Black Belt Choice) ---\n",
      "Czy wymaga gradientu? False\n",
      "Bd no_grad: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "\n",
      " Backward na inference_mode: ZABLOKOWANE.\n",
      "Bd: element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    }
   ],
   "source": [
    "print(\"--- NO GRAD ---\")\n",
    "with torch.no_grad():\n",
    "    y_no_grad = w @ x\n",
    "    print(f\"Czy wymaga gradientu? {y_no_grad.requires_grad}\")\n",
    "    # W no_grad() wci偶 mo偶emy robi in-place operations, kt贸re s ledzone przez Version Counter\n",
    "    \n",
    "print(\"\\n--- INFERENCE MODE (Black Belt Choice) ---\")\n",
    "with torch.inference_mode():\n",
    "    y_inf = w @ x\n",
    "    print(f\"Czy wymaga gradientu? {y_inf.requires_grad}\")\n",
    "    \n",
    "    # R贸偶nica jest subtelna, ale kluczowa.\n",
    "    # Spr贸bujmy u偶y tych wynik贸w do dalszego treningu poza blokiem.\n",
    "    \n",
    "try:\n",
    "    # To zadziaa (cho nie policzy gradientu dla w, bo y_no_grad nie ma historii)\n",
    "    loss = y_no_grad.sum()\n",
    "    loss.backward() \n",
    "    print(\"Backward na no_grad: Przeszo (ale gradient贸w brak).\")\n",
    "except Exception as e:\n",
    "    print(f\"Bd no_grad: {e}\")\n",
    "\n",
    "try:\n",
    "    # To wyrzuci bd! Inference Mode zabrania tworzenia grafu nawet p贸藕niej.\n",
    "    loss = y_inf.sum()\n",
    "    loss.backward()\n",
    "except RuntimeError as e:\n",
    "    print(f\"\\n Backward na inference_mode: ZABLOKOWANE.\")\n",
    "    print(f\"Bd: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe1518b",
   "metadata": {},
   "source": [
    "## Dlaczego `inference_mode` jest szybsze?\n",
    "\n",
    "W `inference_mode` PyTorch pomija tworzenie struktur `ViewTracking` i `VersionCounter`.\n",
    "Przy maych modelach (MLP) r贸偶nica jest znikoma.\n",
    "Przy gigantycznych modelach (LLM, ViT) i bardzo maych batchach (np. obsuga zapyta HTTP w czasie rzeczywistym), narzut Pythona na obsug grafu mo偶e by zauwa偶alny.\n",
    "\n",
    "**Zasada in偶ynierska:**\n",
    "*   Trenujesz? -> Nic nie r贸b.\n",
    "*   Walidujesz/Testujesz/Wdra偶asz? -> **`@torch.inference_mode()`** (jako dekorator funkcji)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d53d882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wynik predykcji: torch.Size([5, 5])\n",
      "Czy ma histori? None\n"
     ]
    }
   ],
   "source": [
    "# Wzorzec projektowy: Dekorator\n",
    "@torch.inference_mode()\n",
    "def predict(model_weights, inputs):\n",
    "    # Caa ta funkcja jest chroniona i zoptymalizowana\n",
    "    return model_weights @ inputs\n",
    "\n",
    "# Symulacja \"Modelu\" na produkcji\n",
    "result = predict(w, x)\n",
    "\n",
    "print(\"Wynik predykcji:\", result.shape)\n",
    "print(\"Czy ma histori?\", result.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859054c6",
   "metadata": {},
   "source": [
    "##  Black Belt Summary\n",
    "\n",
    "1.  **`x.requires_grad`**: Wasno wirusowa. Jeli jeden skadnik r贸wnania tego wymaga, wynik te偶 bdzie tego wymaga.\n",
    "2.  **`.detach()`**: U偶ywaj, gdy chcesz \"urwa\" histori (np. przekazujc stan ukryty w LSTM do nowej sekwencji albo wizualizujc tensor w matplotlib).\n",
    "3.  **`torch.no_grad()`**: Stare, dobre, ale wolniejsze. U偶ywaj tylko, jeli musisz manipulowa tensorami w specyficzny spos贸b.\n",
    "4.  **`torch.inference_mode()`**: **Nowy standard.** U偶ywaj zawsze na produkcji i podczas walidacji. Jest szybsze i bezpieczniejsze (gwarantuje, 偶e nie zrobisz bdu w logice gradient贸w)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
