{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n<a href=\"https://colab.research.google.com/github/takzen/pytorch-black-belt/blob/main/02_Broadcasting_Magic.ipynb\" target=\"_parent\">\n    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbb4dab",
   "metadata": {},
   "source": [
    "# \ud83e\udd4b Lekcja 2: Broadcasting Magic (Matematyka bez p\u0119tli)\n",
    "\n",
    "Jak doda\u0107 wektor `[1, 2, 3]` do ka\u017cdego wiersza macierzy `[[0, 0, 0], [10, 10, 10]]`?\n",
    "W C++ pisa\u0142by\u015b p\u0119tl\u0119. W PyTorch dzieje si\u0119 to \"samo\".\n",
    "\n",
    "**Zasady Broadcastingu:**\n",
    "PyTorch por\u00f3wnuje wymiary dw\u00f3ch tensor\u00f3w **od prawej do lewej**:\n",
    "1.  Je\u015bli wymiary s\u0105 r\u00f3wne -> OK.\n",
    "2.  Je\u015bli jeden z wymiar\u00f3w ma rozmiar **1** -> Rozci\u0105gnij go (wirtualnie) do rozmiaru drugiego.\n",
    "3.  Je\u015bli jednego wymiaru brakuje -> Dopisz **1** z lewej strony.\n",
    "\n",
    "Je\u015bli \u017cadna zasada nie pasuje -> B\u0142\u0105d.\n",
    "\n",
    "**Cel lekcji:**\n",
    "Zrozumie\u0107, jak PyTorch \"oszukuje\" pami\u0119\u0107, udaj\u0105c, \u017ce ma\u0142e tensory s\u0105 du\u017ce, \u017ceby wykona\u0107 obliczenia b\u0142yskawicznie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e277b2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kszta\u0142t A: torch.Size([2, 3])\n",
      "Kszta\u0142t B: torch.Size([3])\n",
      "\n",
      "--- WYNIK A + B ---\n",
      "tensor([[ 1,  2,  3],\n",
      "        [11, 12, 13]])\n",
      "Co si\u0119 sta\u0142o? Wektor B zosta\u0142 'dodany' do ka\u017cdego wiersza A osobno.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. PRZYK\u0141AD PODSTAWOWY\n",
    "# Macierz (2 wiersze, 3 kolumny)\n",
    "A = torch.tensor([[0, 0, 0], \n",
    "                  [10, 10, 10]])\n",
    "\n",
    "# Wektor (3 elementy)\n",
    "B = torch.tensor([1, 2, 3])\n",
    "\n",
    "print(f\"Kszta\u0142t A: {A.shape}\")\n",
    "print(f\"Kszta\u0142t B: {B.shape}\")\n",
    "\n",
    "# Dodawanie\n",
    "C = A + B\n",
    "\n",
    "print(\"\\n--- WYNIK A + B ---\")\n",
    "print(C)\n",
    "print(\"Co si\u0119 sta\u0142o? Wektor B zosta\u0142 'dodany' do ka\u017cdego wiersza A osobno.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf182037",
   "metadata": {},
   "source": [
    "## Co si\u0119 sta\u0142o pod mask\u0105? (Wizualizacja Zasad)\n",
    "\n",
    "Analiza kszta\u0142t\u00f3w od prawej:\n",
    "*   A: `(2, 3)`\n",
    "*   B: `(   3)`\n",
    "\n",
    "1.  Wyr\u00f3wnanie do prawej: Ostatni wymiar to `3` vs `3`. Pasuje.\n",
    "2.  Brakuj\u0105cy wymiar: B nie ma pierwszego wymiaru. PyTorch traktuje go jako `(1, 3)`.\n",
    "3.  Rozci\u0105ganie jedynek: Wymiar `1` w B jest rozci\u0105gany do `2` (\u017ceby pasowa\u0142 do A).\n",
    "\n",
    "Efektywnie B staje si\u0119:\n",
    "`[[1, 2, 3], [1, 2, 3]]` (ale tylko wirtualnie, w pami\u0119ci to nadal 3 liczby!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe21b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col: torch.Size([3, 1])\n",
      "Row: torch.Size([4])\n",
      "\n",
      "--- WYNIK (Siatka) ---\n",
      "tensor([[11, 21, 31, 41],\n",
      "        [12, 22, 32, 42],\n",
      "        [13, 23, 33, 43]])\n",
      "Nowy kszta\u0142t: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 2. PRZYK\u0141AD TRUDNY (Kolumna + Wiersz)\n",
    "# Wektor kolumnowy (3, 1)\n",
    "col = torch.tensor([[1], \n",
    "                    [2], \n",
    "                    [3]])\n",
    "\n",
    "# Wektor wierszowy (1, 4) (lub po prostu 4)\n",
    "row = torch.tensor([10, 20, 30, 40])\n",
    "\n",
    "print(f\"Col: {col.shape}\")\n",
    "print(f\"Row: {row.shape}\")\n",
    "\n",
    "# Wynik? Macierz 3x4!\n",
    "# Col rozci\u0105ga si\u0119 w prawo. Row rozci\u0105ga si\u0119 w d\u00f3\u0142.\n",
    "grid = col + row\n",
    "\n",
    "print(\"\\n--- WYNIK (Siatka) ---\")\n",
    "print(grid)\n",
    "print(f\"Nowy kszta\u0142t: {grid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f689d7",
   "metadata": {},
   "source": [
    "## .expand() vs .repeat() (Pami\u0119\u0107)\n",
    "\n",
    "To jest test na Seniora.\n",
    "Chcesz powieli\u0107 tensor. Czego u\u017cyjesz?\n",
    "\n",
    "*   **`.repeat(2, 2)`**: Fizycznie kopiuje dane. Zajmuje now\u0105 pami\u0119\u0107.\n",
    "*   **`.expand(2, 2)`**: Tworzy **Widok (View)**. Ustawia `stride=0` na rozci\u0105ganym wymiarze. **Zu\u017cycie pami\u0119ci = 0.**\n",
    "\n",
    "Zawsze u\u017cywaj `expand()`, je\u015bli tylko potrzebujesz odczyta\u0107 dane (do matematyki)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d3918fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ORYGINA\u0141 ---\n",
      "Shape: torch.Size([3, 1]), Stride: (1, 1)\n",
      "Adres pami\u0119ci: 6545664508352\n",
      "\n",
      "--- EXPAND (Wirtualna kopia) ---\n",
      "Shape: torch.Size([3, 4])\n",
      "Stride: (1, 0)\n",
      "Adres pami\u0119ci: 6545664508352\n",
      "\u2705 To ten sam obszar pami\u0119ci! Zero koszt\u00f3w.\n",
      "\n",
      "--- REPEAT (Fizyczna kopia) ---\n",
      "Adres pami\u0119ci: 6545664508416\n",
      "\u274c Adres jest inny. Zaalokowano now\u0105 pami\u0119\u0107.\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([[1], [2], [3]]) # (3, 1)\n",
    "\n",
    "print(\"--- ORYGINA\u0141 ---\")\n",
    "print(f\"Shape: {t.shape}, Stride: {t.stride()}\")\n",
    "print(f\"Adres pami\u0119ci: {t.untyped_storage().data_ptr()}\")\n",
    "\n",
    "# U\u017cywamy EXPAND (powi\u0119kszamy do 3x4)\n",
    "t_expanded = t.expand(3, 4)\n",
    "\n",
    "print(\"\\n--- EXPAND (Wirtualna kopia) ---\")\n",
    "print(f\"Shape: {t_expanded.shape}\")\n",
    "print(f\"Stride: {t_expanded.stride()}\") \n",
    "# Zauwa\u017c stride=(1, 0). 0 oznacza: \"\u017ceby przej\u015b\u0107 do nast\u0119pnej kolumny, przesu\u0144 si\u0119 o 0 bajt\u00f3w\".\n",
    "# Czyli czytamy ci\u0105gle t\u0119 sam\u0105 liczb\u0119!\n",
    "\n",
    "print(f\"Adres pami\u0119ci: {t_expanded.untyped_storage().data_ptr()}\")\n",
    "if t.untyped_storage().data_ptr() == t_expanded.untyped_storage().data_ptr():\n",
    "    print(\"\u2705 To ten sam obszar pami\u0119ci! Zero koszt\u00f3w.\")\n",
    "\n",
    "# U\u017cywamy REPEAT\n",
    "t_repeated = t.repeat(1, 4)\n",
    "print(\"\\n--- REPEAT (Fizyczna kopia) ---\")\n",
    "print(f\"Adres pami\u0119ci: {t_repeated.untyped_storage().data_ptr()}\")\n",
    "print(\"\u274c Adres jest inny. Zaalokowano now\u0105 pami\u0119\u0107.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19fdff3",
   "metadata": {},
   "source": [
    "## Praktyczne Zastosowanie: Macierz Odleg\u0142o\u015bci (Pairwise Distance)\n",
    "\n",
    "Masz 3 punkty A i 2 punkty B. Chcesz policzy\u0107 odleg\u0142o\u015b\u0107 ka\u017cdego A do ka\u017cdego B.\n",
    "Bez p\u0119tli `for`.\n",
    "\n",
    "*   A: `(3, 2)` -> Zmieniamy na `(3, 1, 2)`\n",
    "*   B: `(2, 2)` -> Zmieniamy na `(1, 2, 2)`\n",
    "*   R\u00f3\u017cnica: `(3, 2, 2)` -> Ka\u017cdy z ka\u017cdym!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09daf554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kszta\u0142t r\u00f3\u017cnicy: torch.Size([3, 2, 2])\n",
      "\n",
      "--- MACIERZ ODLEG\u0141O\u015aCI ---\n",
      "tensor([[ 1.0000, 14.1421],\n",
      "        [ 1.0000, 12.7279],\n",
      "        [ 2.2361, 11.3137]])\n"
     ]
    }
   ],
   "source": [
    "# Punkty A (np. Klienci)\n",
    "A = torch.tensor([[0., 0.], \n",
    "                  [1., 1.], \n",
    "                  [2., 2.]]) # (3, 2)\n",
    "\n",
    "# Punkty B (np. Sklepy)\n",
    "B = torch.tensor([[0., 1.], \n",
    "                  [10., 10.]]) # (2, 2)\n",
    "\n",
    "# Chcemy wynik (3, 2) - odleg\u0142o\u015bci\n",
    "\n",
    "# 1. Unsqueeze (Dodajemy wymiary \"dummy\" dla broadcastingu)\n",
    "# A: (3, 1, 2)\n",
    "# B: (1, 2, 2)\n",
    "diff = A.unsqueeze(1) - B.unsqueeze(0)\n",
    "\n",
    "print(f\"Kszta\u0142t r\u00f3\u017cnicy: {diff.shape}\")\n",
    "# (3, 2, 2) -> (3 klient\u00f3w, 2 sklepy, 2 wsp\u00f3\u0142rz\u0119dne x/y)\n",
    "\n",
    "# 2. Kwadrat i Suma (Norma L2)\n",
    "dist_sq = diff ** 2\n",
    "dist_sum = dist_sq.sum(dim=2) # Sumujemy po wsp\u00f3\u0142rz\u0119dnych (x+y)\n",
    "dist = torch.sqrt(dist_sum)\n",
    "\n",
    "print(\"\\n--- MACIERZ ODLEG\u0141O\u015aCI ---\")\n",
    "print(dist)\n",
    "# Wiersz 0: Odleg\u0142o\u015b\u0107 Klienta 0 do Sklepu 0 i Sklepu 1\n",
    "# Wiersz 1: Odleg\u0142o\u015b\u0107 Klienta 1 ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5a20e2",
   "metadata": {},
   "source": [
    "## \ud83e\udd4b Black Belt Summary\n",
    "\n",
    "1.  **Zasada prawej r\u0119ki:** Wymiary s\u0105 dopasowywane od prawej strony.\n",
    "2.  **Jedyneczka to joker:** Wymiar o rozmiarze `1` dopasowuje si\u0119 do wszystkiego.\n",
    "3.  **Expand > Repeat:** `expand` manipuluje tylko *stride* (krokiem), `repeat` kopiuje dane.\n",
    "4.  **Unsqueeze jest przyjacielem:** Cz\u0119sto dodajemy `None` lub `.unsqueeze()`, \u017ceby \"przygotowa\u0107\" tensor pod broadcasting (np. zmieniaj\u0105c `(N)` na `(N, 1)`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}