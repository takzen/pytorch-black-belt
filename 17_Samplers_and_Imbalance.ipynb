{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109578ff",
   "metadata": {},
   "source": [
    "#  Lekcja 17: Samplers & Imbalance (Walka z Nier贸wnowag)\n",
    "\n",
    "W domylnym `DataLoader(shuffle=True)` ka偶da pr贸bka ma takie samo prawdopodobiestwo wyboru.\n",
    "Przy niezbalansowanych danych (Imbalanced Data) to katastrofa.\n",
    "\n",
    "**WeightedRandomSampler** dziaa jak ruletka, gdzie pola maj r贸偶ne rozmiary.\n",
    "1.  Liczymy wagi dla ka偶dej klasy (odwrotnie proporcjonalne do liczebnoci).\n",
    "2.  Przypisujemy wag do ka偶dej pr贸bki w zbiorze.\n",
    "3.  Sampler losuje indeksy na podstawie tych wag.\n",
    "\n",
    "Efekt? Mimo 偶e w danych masz 90% klasy A i 10% klasy B, w Batchu zobaczysz 50% A i 50% B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d81e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba pr贸bek: 100\n",
      "Liczba zer: 90\n",
      "Liczba jedynek: 10\n",
      "Proporcja: 9:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "\n",
    "# 1. GENERUJEMY NIEZBALANSOWANE DANE\n",
    "# 90 zer (Klasa wikszociowa)\n",
    "# 10 jedynek (Klasa mniejszociowa - Rzadka)\n",
    "labels = torch.cat([torch.zeros(90), torch.ones(10)]).long()\n",
    "data = torch.randn(100, 5) # Jakie losowe cechy\n",
    "\n",
    "dataset = TensorDataset(data, labels)\n",
    "\n",
    "print(f\"Liczba pr贸bek: {len(labels)}\")\n",
    "print(f\"Liczba zer: {(labels == 0).sum()}\")\n",
    "print(f\"Liczba jedynek: {(labels == 1).sum()}\")\n",
    "print(\"Proporcja: 9:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61755df7",
   "metadata": {},
   "source": [
    "## Problem: Standardowy Loader\n",
    "\n",
    "Zobaczmy, co si stanie, gdy u偶yjemy zwykego Loadera.\n",
    "W batchu o rozmiarze 10 spodziewamy si rednio jednej jedynki (albo zera). Model prawie nigdy nie zobaczy klasy mniejszociowej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55706739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ZWYKY LOADER ---\n",
      "Batch 0: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Batch 1: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Batch 2: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Wniosek: Widzisz prawie same zera. Model uzna, 偶e jedynki to bd statystyczny.\n"
     ]
    }
   ],
   "source": [
    "# Zwyky loader\n",
    "loader_imbalanced = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "print(\"--- ZWYKY LOADER ---\")\n",
    "for i, (x, y) in enumerate(loader_imbalanced):\n",
    "    print(f\"Batch {i}: {y.tolist()}\")\n",
    "    if i >= 2: break # Poka偶 tylko 3 pierwsze\n",
    "\n",
    "print(\"\\nWniosek: Widzisz prawie same zera. Model uzna, 偶e jedynki to bd statystyczny.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8753f9c8",
   "metadata": {},
   "source": [
    "## Rozwizanie: Obliczanie Wag\n",
    "\n",
    "Musimy nada wag ka偶dej pr贸bce.\n",
    "Zasada: **Im rzadsza klasa, tym wiksza waga.**\n",
    "\n",
    "Wz贸r: $W_{class} = \\frac{1}{\\text{Liczba pr贸bek w tej klasie}}$\n",
    "\n",
    "*   Waga dla 0: $1/90 \\approx 0.011$\n",
    "*   Waga dla 1: $1/10 = 0.1$ (ok. 9x wiksza!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f005b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waga dla klasy 0: 0.0111\n",
      "Waga dla klasy 1: 0.1000\n",
      "Przykadowe wagi pr贸bek: tensor([0.0111, 0.0111, 0.0111, 0.0111, 0.0111], dtype=torch.float64) ... tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 1. Liczymy wystpienia klas\n",
    "class_counts = [90, 10] # [Zera, Jedynki]\n",
    "num_samples = sum(class_counts)\n",
    "\n",
    "# 2. Liczymy wagi dla klas (1 / count)\n",
    "class_weights = [1.0 / c for c in class_counts]\n",
    "\n",
    "# 3. Przypisujemy wag do KA呕DEJ PRBKI w zbiorze\n",
    "# Tworzymy list 100 wag. Jeli pr贸bka to 0 -> waga maa. Jeli 1 -> waga du偶a.\n",
    "sample_weights = [class_weights[label] for label in labels]\n",
    "\n",
    "# Zamieniamy na tensor\n",
    "sample_weights = torch.DoubleTensor(sample_weights)\n",
    "\n",
    "print(f\"Waga dla klasy 0: {class_weights[0]:.4f}\")\n",
    "print(f\"Waga dla klasy 1: {class_weights[1]:.4f}\")\n",
    "print(f\"Przykadowe wagi pr贸bek: {sample_weights[:5]} ... {sample_weights[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281770d9",
   "metadata": {},
   "source": [
    "## U偶ycie WeightedRandomSampler\n",
    "\n",
    "Tworzymy sampler i przekazujemy go do `DataLoader`.\n",
    "\n",
    "**Wa偶ne:**\n",
    "1.  `replacement=True`: Pozwala wylosowa t sam pr贸bk (t rzadk jedynk) wiele razy w jednej epoce. To klucz do oversamplingu.\n",
    "2.  `shuffle=False`: W Loaderze musimy wyczy shuffle, bo Sampler i tak losuje (te dwie opcje si wykluczaj)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6fd9d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ZBALANSOWANY LOADER ---\n",
      "Batch 0: [1, 1, 1, 0, 0, 0, 1, 0, 1, 0]\n",
      "Batch 1: [0, 0, 1, 0, 1, 1, 0, 0, 0, 1]\n",
      "Batch 2: [0, 1, 1, 0, 1, 0, 1, 1, 0, 0]\n",
      "Batch 3: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "Batch 4: [1, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "Batch 5: [0, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
      "Batch 6: [1, 1, 0, 0, 1, 1, 1, 0, 1, 1]\n",
      "Batch 7: [0, 1, 1, 0, 1, 1, 1, 1, 1, 0]\n",
      "Batch 8: [1, 0, 1, 1, 0, 0, 1, 0, 1, 0]\n",
      "Batch 9: [0, 1, 1, 1, 1, 1, 0, 0, 1, 0]\n",
      "------------------------------\n",
      "Suma Zer: 54\n",
      "Suma Jedynek: 46\n",
      "Widzisz? Mimo 偶e mamy tylko 10 jedynek w bazie, loader poda ich okoo 50!\n"
     ]
    }
   ],
   "source": [
    "# Tworzymy Sampler\n",
    "# num_samples=len(sample_weights) oznacza, 偶e w epoce chcemy zobaczy 100 pr贸bek (tyle co orygina),\n",
    "# ale bd one sztucznie zbalansowane.\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Tworzymy Loader z Samplerem (shuffle musi by False!)\n",
    "loader_balanced = DataLoader(dataset, batch_size=10, sampler=sampler)\n",
    "\n",
    "print(\"--- ZBALANSOWANY LOADER ---\")\n",
    "total_zeros = 0\n",
    "total_ones = 0\n",
    "\n",
    "for i, (x, y) in enumerate(loader_balanced):\n",
    "    print(f\"Batch {i}: {y.tolist()}\")\n",
    "    total_zeros += (y == 0).sum().item()\n",
    "    total_ones += (y == 1).sum().item()\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Suma Zer: {total_zeros}\")\n",
    "print(f\"Suma Jedynek: {total_ones}\")\n",
    "print(\"Widzisz? Mimo 偶e mamy tylko 10 jedynek w bazie, loader poda ich okoo 50!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db08a51",
   "metadata": {},
   "source": [
    "##  Black Belt Summary\n",
    "\n",
    "1.  **Nie modyfikuj danych na dysku.** To strata miejsca. U偶ywaj Samplera.\n",
    "2.  **`replacement=True`**: To jest magia. Dziki temu Sampler \"klonuje\" rzadkie przypadki w locie.\n",
    "3.  **Wz贸r na wagi:** Zawsze `1 / count`.\n",
    "4.  **Puapka:** Nie u偶ywaj `shuffle=True` razem z `sampler`. PyTorch rzuci bdem.\n",
    "\n",
    "W nastpnej lekcji zejdziemy najni偶ej jak si da w in偶ynierii danych: **Multiprocessing i Pin Memory**. Zrozumiemy, dlaczego Tw贸j procesor (CPU) dawi kart graficzn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
