{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n<a href=\"https://colab.research.google.com/github/takzen/pytorch-black-belt/blob/main/17_Samplers_and_Imbalance.ipynb\" target=\"_parent\">\n    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# \u2601\ufe0f COLAB SETUP (Automatyczna instalacja \u015brodowiska)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Sprawdzamy, czy jeste\u015bmy w Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('\u2601\ufe0f Wykryto \u015brodowisko Google Colab. Konfiguruj\u0119...')\n",
    "\n",
    "    # 1. Pobieramy plik requirements.txt bezpo\u015brednio z repozytorium\n",
    "    !wget -q https://raw.githubusercontent.com/takzen/ai-engineering-handbook/main/requirements.txt -O requirements.txt\n",
    "\n",
    "    # 2. Instalujemy biblioteki\n",
    "    print('\u23f3 Instaluj\u0119 zale\u017cno\u015bci (to mo\u017ce chwil\u0119 potrwa\u0107)...')\n",
    "    !pip install -q -r requirements.txt\n",
    "\n",
    "    print('\u2705 Gotowe! \u015arodowisko jest zgodne z repozytorium.')\n",
    "else:\n",
    "    print('\ud83d\udcbb Wykryto \u015brodowisko lokalne. Zak\u0142adam, \u017ce masz ju\u017c uv/venv.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109578ff",
   "metadata": {},
   "source": [
    "# \ud83e\udd4b Lekcja 17: Samplers & Imbalance (Walka z Nier\u00f3wnowag\u0105)\n",
    "\n",
    "W domy\u015blnym `DataLoader(shuffle=True)` ka\u017cda pr\u00f3bka ma takie samo prawdopodobie\u0144stwo wyboru.\n",
    "Przy niezbalansowanych danych (Imbalanced Data) to katastrofa.\n",
    "\n",
    "**WeightedRandomSampler** dzia\u0142a jak ruletka, gdzie pola maj\u0105 r\u00f3\u017cne rozmiary.\n",
    "1.  Liczymy wagi dla ka\u017cdej klasy (odwrotnie proporcjonalne do liczebno\u015bci).\n",
    "2.  Przypisujemy wag\u0119 do ka\u017cdej pr\u00f3bki w zbiorze.\n",
    "3.  Sampler losuje indeksy na podstawie tych wag.\n",
    "\n",
    "Efekt? Mimo \u017ce w danych masz 90% klasy A i 10% klasy B, w Batchu zobaczysz 50% A i 50% B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d81e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba pr\u00f3bek: 100\n",
      "Liczba zer: 90\n",
      "Liczba jedynek: 10\n",
      "Proporcja: 9:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "\n",
    "# 1. GENERUJEMY NIEZBALANSOWANE DANE\n",
    "# 90 zer (Klasa wi\u0119kszo\u015bciowa)\n",
    "# 10 jedynek (Klasa mniejszo\u015bciowa - Rzadka)\n",
    "labels = torch.cat([torch.zeros(90), torch.ones(10)]).long()\n",
    "data = torch.randn(100, 5) # Jakie\u015b losowe cechy\n",
    "\n",
    "dataset = TensorDataset(data, labels)\n",
    "\n",
    "print(f\"Liczba pr\u00f3bek: {len(labels)}\")\n",
    "print(f\"Liczba zer: {(labels == 0).sum()}\")\n",
    "print(f\"Liczba jedynek: {(labels == 1).sum()}\")\n",
    "print(\"Proporcja: 9:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61755df7",
   "metadata": {},
   "source": [
    "## Problem: Standardowy Loader\n",
    "\n",
    "Zobaczmy, co si\u0119 stanie, gdy u\u017cyjemy zwyk\u0142ego Loadera.\n",
    "W batchu o rozmiarze 10 spodziewamy si\u0119 \u015brednio jednej jedynki (albo zera). Model prawie nigdy nie zobaczy klasy mniejszo\u015bciowej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55706739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ZWYK\u0141Y LOADER ---\n",
      "Batch 0: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Batch 1: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Batch 2: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Wniosek: Widzisz prawie same zera. Model uzna, \u017ce jedynki to b\u0142\u0105d statystyczny.\n"
     ]
    }
   ],
   "source": [
    "# Zwyk\u0142y loader\n",
    "loader_imbalanced = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "print(\"--- ZWYK\u0141Y LOADER ---\")\n",
    "for i, (x, y) in enumerate(loader_imbalanced):\n",
    "    print(f\"Batch {i}: {y.tolist()}\")\n",
    "    if i >= 2: break # Poka\u017c tylko 3 pierwsze\n",
    "\n",
    "print(\"\\nWniosek: Widzisz prawie same zera. Model uzna, \u017ce jedynki to b\u0142\u0105d statystyczny.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8753f9c8",
   "metadata": {},
   "source": [
    "## Rozwi\u0105zanie: Obliczanie Wag\n",
    "\n",
    "Musimy nada\u0107 wag\u0119 ka\u017cdej pr\u00f3bce.\n",
    "Zasada: **Im rzadsza klasa, tym wi\u0119ksza waga.**\n",
    "\n",
    "Wz\u00f3r: $W_{class} = \\frac{1}{\\text{Liczba pr\u00f3bek w tej klasie}}$\n",
    "\n",
    "*   Waga dla 0: $1/90 \\approx 0.011$\n",
    "*   Waga dla 1: $1/10 = 0.1$ (ok. 9x wi\u0119ksza!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f005b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waga dla klasy 0: 0.0111\n",
      "Waga dla klasy 1: 0.1000\n",
      "Przyk\u0142adowe wagi pr\u00f3bek: tensor([0.0111, 0.0111, 0.0111, 0.0111, 0.0111], dtype=torch.float64) ... tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# 1. Liczymy wyst\u0105pienia klas\n",
    "class_counts = [90, 10] # [Zera, Jedynki]\n",
    "num_samples = sum(class_counts)\n",
    "\n",
    "# 2. Liczymy wagi dla klas (1 / count)\n",
    "class_weights = [1.0 / c for c in class_counts]\n",
    "\n",
    "# 3. Przypisujemy wag\u0119 do KA\u017bDEJ PR\u00d3BKI w zbiorze\n",
    "# Tworzymy list\u0119 100 wag. Je\u015bli pr\u00f3bka to 0 -> waga ma\u0142a. Je\u015bli 1 -> waga du\u017ca.\n",
    "sample_weights = [class_weights[label] for label in labels]\n",
    "\n",
    "# Zamieniamy na tensor\n",
    "sample_weights = torch.DoubleTensor(sample_weights)\n",
    "\n",
    "print(f\"Waga dla klasy 0: {class_weights[0]:.4f}\")\n",
    "print(f\"Waga dla klasy 1: {class_weights[1]:.4f}\")\n",
    "print(f\"Przyk\u0142adowe wagi pr\u00f3bek: {sample_weights[:5]} ... {sample_weights[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281770d9",
   "metadata": {},
   "source": [
    "## U\u017cycie WeightedRandomSampler\n",
    "\n",
    "Tworzymy sampler i przekazujemy go do `DataLoader`.\n",
    "\n",
    "**Wa\u017cne:**\n",
    "1.  `replacement=True`: Pozwala wylosowa\u0107 t\u0119 sam\u0105 pr\u00f3bk\u0119 (t\u0119 rzadk\u0105 jedynk\u0119) wiele razy w jednej epoce. To klucz do oversamplingu.\n",
    "2.  `shuffle=False`: W Loaderze musimy wy\u0142\u0105czy\u0107 shuffle, bo Sampler i tak losuje (te dwie opcje si\u0119 wykluczaj\u0105)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6fd9d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ZBALANSOWANY LOADER ---\n",
      "Batch 0: [1, 1, 1, 0, 0, 0, 1, 0, 1, 0]\n",
      "Batch 1: [0, 0, 1, 0, 1, 1, 0, 0, 0, 1]\n",
      "Batch 2: [0, 1, 1, 0, 1, 0, 1, 1, 0, 0]\n",
      "Batch 3: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "Batch 4: [1, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "Batch 5: [0, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
      "Batch 6: [1, 1, 0, 0, 1, 1, 1, 0, 1, 1]\n",
      "Batch 7: [0, 1, 1, 0, 1, 1, 1, 1, 1, 0]\n",
      "Batch 8: [1, 0, 1, 1, 0, 0, 1, 0, 1, 0]\n",
      "Batch 9: [0, 1, 1, 1, 1, 1, 0, 0, 1, 0]\n",
      "------------------------------\n",
      "Suma Zer: 54\n",
      "Suma Jedynek: 46\n",
      "Widzisz? Mimo \u017ce mamy tylko 10 jedynek w bazie, loader poda\u0142 ich oko\u0142o 50!\n"
     ]
    }
   ],
   "source": [
    "# Tworzymy Sampler\n",
    "# num_samples=len(sample_weights) oznacza, \u017ce w epoce chcemy zobaczy\u0107 100 pr\u00f3bek (tyle co orygina\u0142),\n",
    "# ale b\u0119d\u0105 one sztucznie zbalansowane.\n",
    "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Tworzymy Loader z Samplerem (shuffle musi by\u0107 False!)\n",
    "loader_balanced = DataLoader(dataset, batch_size=10, sampler=sampler)\n",
    "\n",
    "print(\"--- ZBALANSOWANY LOADER ---\")\n",
    "total_zeros = 0\n",
    "total_ones = 0\n",
    "\n",
    "for i, (x, y) in enumerate(loader_balanced):\n",
    "    print(f\"Batch {i}: {y.tolist()}\")\n",
    "    total_zeros += (y == 0).sum().item()\n",
    "    total_ones += (y == 1).sum().item()\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Suma Zer: {total_zeros}\")\n",
    "print(f\"Suma Jedynek: {total_ones}\")\n",
    "print(\"Widzisz? Mimo \u017ce mamy tylko 10 jedynek w bazie, loader poda\u0142 ich oko\u0142o 50!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db08a51",
   "metadata": {},
   "source": [
    "## \ud83e\udd4b Black Belt Summary\n",
    "\n",
    "1.  **Nie modyfikuj danych na dysku.** To strata miejsca. U\u017cywaj Samplera.\n",
    "2.  **`replacement=True`**: To jest magia. Dzi\u0119ki temu Sampler \"klonuje\" rzadkie przypadki w locie.\n",
    "3.  **Wz\u00f3r na wagi:** Zawsze `1 / count`.\n",
    "4.  **Pu\u0142apka:** Nie u\u017cywaj `shuffle=True` razem z `sampler`. PyTorch rzuci b\u0142\u0119dem.\n",
    "\n",
    "W nast\u0119pnej lekcji zejdziemy najni\u017cej jak si\u0119 da w in\u017cynierii danych: **Multiprocessing i Pin Memory**. Zrozumiemy, dlaczego Tw\u00f3j procesor (CPU) d\u0142awi kart\u0119 graficzn\u0105."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}