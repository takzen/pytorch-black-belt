{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "956d764e",
   "metadata": {},
   "source": [
    "# ü•ã Lekcja 43: DDP (Distributed Data Parallel) - Anatomia Synchronizacji\n",
    "\n",
    "Dlaczego `nn.DataParallel` (DP) jest z≈Çe?\n",
    "Bo kopiuje model do VRAM przy ka≈ºdym kroku (Forward), a potem go kasuje. Narzut komunikacyjny jest gigantyczny.\n",
    "\n",
    "**DDP (Distributed Data Parallel)** jest inne:\n",
    "1.  Model jest kopiowany raz (na starcie).\n",
    "2.  Procesy ≈ºyjƒÖ niezale≈ºnie (nie blokujƒÖ siƒô przez GIL).\n",
    "3.  Jedyny moment komunikacji to **U≈õrednianie Gradient√≥w (AllReduce)**.\n",
    "\n",
    "**Matematyka DDP:**\n",
    "*   GPU 0: Obliczy≈Ç gradient $g_0 = 10$.\n",
    "*   GPU 1: Obliczy≈Ç gradient $g_1 = 12$.\n",
    "*   **AllReduce:** Oba GPU ustalajƒÖ: \"Nasz wsp√≥lny gradient to $(10+12)/2 = 11$\".\n",
    "*   Update: Oba GPU odejmujƒÖ $11$ od wag. PozostajƒÖ identyczne.\n",
    "\n",
    "Zasymulujemy to rƒôcznie na dw√≥ch \"wirtualnych\" GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d569ca5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symulacja: Dwa procesy wystartowa≈Çy z identycznym modelem.\n",
      "Waga GPU0 (pierwsza): 1.0\n",
      "Waga GPU1 (pierwsza): 1.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "\n",
    "# Konfiguracja\n",
    "# Udajemy, ≈ºe mamy 2 urzƒÖdzenia (nawet je≈õli to CPU)\n",
    "RANK_0_DEVICE = \"cpu\"\n",
    "RANK_1_DEVICE = \"cpu\"\n",
    "\n",
    "# 1. TWORZYMY MODEL (Baza)\n",
    "# nn.Linear(10, 1) tworzy wagi o kszta≈Çcie [1, 10]\n",
    "base_model = nn.Linear(10, 1, bias=False)\n",
    "\n",
    "# Ustawiamy wagi na sztywno, ≈ºeby start by≈Ç identyczny\n",
    "with torch.no_grad():\n",
    "    base_model.weight.fill_(1.0)\n",
    "\n",
    "# 2. Rozsy≈Çamy model na \"GPU\" (Repliki)\n",
    "model_gpu0 = copy.deepcopy(base_model).to(RANK_0_DEVICE)\n",
    "model_gpu1 = copy.deepcopy(base_model).to(RANK_1_DEVICE)\n",
    "\n",
    "# Ka≈ºdy ma sw√≥j optymalizator\n",
    "opt_gpu0 = optim.SGD(model_gpu0.parameters(), lr=0.1)\n",
    "opt_gpu1 = optim.SGD(model_gpu1.parameters(), lr=0.1)\n",
    "\n",
    "print(\"Symulacja: Dwa procesy wystartowa≈Çy z identycznym modelem.\")\n",
    "\n",
    "# --- POPRAWKA ---\n",
    "# Zamiast .item() na ca≈Çym tensorze, bierzemy pierwszy element [0, 0]\n",
    "print(f\"Waga GPU0 (pierwsza): {model_gpu0.weight[0, 0].item()}\")\n",
    "print(f\"Waga GPU1 (pierwsza): {model_gpu1.weight[0, 0].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2340e3",
   "metadata": {},
   "source": [
    "## Krok 1: Forward/Backward (Desynchronizacja)\n",
    "\n",
    "Ka≈ºdy proces dostaje **inne dane** (dziƒôki `DistributedSampler`).\n",
    "Dlatego ka≈ºdy wyliczy **inny gradient**.\n",
    "Je≈õli zrobimy `step()` teraz, modele siƒô \"rozjadƒÖ\" i trening p√≥jdzie do kosza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "081b2e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GRADIENTY LOKALNE ---\n",
      "Grad GPU0: -180.00\n",
      "Grad GPU1: -720.00\n",
      "Modele chcƒÖ i≈õƒá w r√≥≈ºnych kierunkach!\n"
     ]
    }
   ],
   "source": [
    "# Dane dla GPU 0 (np. pierwsza po≈Çowa batcha)\n",
    "data_0 = torch.tensor([[1.0] * 10]).to(RANK_0_DEVICE) # Same jedynki\n",
    "target_0 = torch.tensor([[100.0]]).to(RANK_0_DEVICE)\n",
    "\n",
    "# Dane dla GPU 1 (np. druga po≈Çowa batcha)\n",
    "data_1 = torch.tensor([[2.0] * 10]).to(RANK_1_DEVICE) # Same dw√≥jki\n",
    "target_1 = torch.tensor([[200.0]]).to(RANK_1_DEVICE)\n",
    "\n",
    "# --- PROCES GPU 0 ---\n",
    "opt_gpu0.zero_grad()\n",
    "pred_0 = model_gpu0(data_0)\n",
    "loss_0 = (pred_0 - target_0)**2\n",
    "loss_0.backward()\n",
    "\n",
    "# --- PROCES GPU 1 ---\n",
    "opt_gpu1.zero_grad()\n",
    "pred_1 = model_gpu1(data_1)\n",
    "loss_1 = (pred_1 - target_1)**2\n",
    "loss_1.backward()\n",
    "\n",
    "print(\"--- GRADIENTY LOKALNE ---\")\n",
    "# Gradienty sƒÖ r√≥≈ºne, bo dane by≈Çy r√≥≈ºne!\n",
    "grad_0 = model_gpu0.weight.grad\n",
    "grad_1 = model_gpu1.weight.grad\n",
    "\n",
    "print(f\"Grad GPU0: {grad_0[0,0].item():.2f}\")\n",
    "print(f\"Grad GPU1: {grad_1[0,0].item():.2f}\")\n",
    "print(\"Modele chcƒÖ i≈õƒá w r√≥≈ºnych kierunkach!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd25152",
   "metadata": {},
   "source": [
    "## Krok 2: AllReduce (Synchronizacja)\n",
    "\n",
    "To jest ten moment, kt√≥ry DDP robi automatycznie (poprzez backend `nccl` na NVIDIA lub `gloo` na CPU).\n",
    "Musimy u≈õredniƒá gradienty ze wszystkich GPU.\n",
    "\n",
    "$$ G_{global} = \\frac{G_0 + G_1 + ... + G_k}{K} $$\n",
    "\n",
    "Nastƒôpnie nadpisujemy lokalne gradienty tym globalnym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afc1d771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PO ALL-REDUCE ---\n",
      "Grad GPU0: -450.00\n",
      "Grad GPU1: -450.00\n",
      "Gradienty sƒÖ teraz identyczne. Jeste≈õmy zsynchronizowani.\n"
     ]
    }
   ],
   "source": [
    "# Symulacja operacji DIST.ALL_REDUCE\n",
    "with torch.no_grad():\n",
    "    # 1. Sumujemy (Reduce)\n",
    "    global_grad = grad_0 + grad_1\n",
    "    \n",
    "    # 2. Dzielimy przez liczbƒô GPU (Average)\n",
    "    global_grad = global_grad / 2.0\n",
    "    \n",
    "    # 3. Rozsy≈Çamy z powrotem do modeli (Broadcast)\n",
    "    # Nadpisujemy lokalny .grad\n",
    "    model_gpu0.weight.grad.copy_(global_grad)\n",
    "    model_gpu1.weight.grad.copy_(global_grad)\n",
    "\n",
    "print(\"--- PO ALL-REDUCE ---\")\n",
    "print(f\"Grad GPU0: {model_gpu0.weight.grad[0,0].item():.2f}\")\n",
    "print(f\"Grad GPU1: {model_gpu1.weight.grad[0,0].item():.2f}\")\n",
    "print(\"Gradienty sƒÖ teraz identyczne. Jeste≈õmy zsynchronizowani.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c894099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- WAGI PO KROKU ---\n",
      "Waga GPU0: 46.0000\n",
      "Waga GPU1: 46.0000\n",
      "‚úÖ SUKCES! Modele pozosta≈Çy bli≈∫niakami.\n"
     ]
    }
   ],
   "source": [
    "# Krok 3: Optimizer Step\n",
    "opt_gpu0.step()\n",
    "opt_gpu1.step()\n",
    "\n",
    "print(\"\\n--- WAGI PO KROKU ---\")\n",
    "# POPRAWKA: Indeksowanie [0, 0]\n",
    "w0 = model_gpu0.weight[0, 0].item()\n",
    "w1 = model_gpu1.weight[0, 0].item()\n",
    "\n",
    "print(f\"Waga GPU0: {w0:.4f}\")\n",
    "print(f\"Waga GPU1: {w1:.4f}\")\n",
    "\n",
    "if w0 == w1:\n",
    "    print(\"‚úÖ SUKCES! Modele pozosta≈Çy bli≈∫niakami.\")\n",
    "else:\n",
    "    print(\"‚ùå B≈ÅƒÑD! Modele siƒô rozjecha≈Çy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f245a7",
   "metadata": {},
   "source": [
    "## Boilerplate (Jak to wyglƒÖda w kodzie?)\n",
    "\n",
    "W prawdziwym skrypcie nie robisz tego rƒôcznie. U≈ºywasz wrappera `DistributedDataParallel`.\n",
    "\n",
    "Oto \"Szablon Startowy\", kt√≥ry ka≈ºdy in≈ºynier DDP ma pod rƒôkƒÖ.\n",
    "*(Ten kod nie zadzia≈Ça w notatniku, bo wymaga uruchomienia przez `torchrun`, ale jest referencjƒÖ)*.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "def main():\n",
    "    # 1. Inicjalizacja grupy procesowej\n",
    "    dist.init_process_group(\"nccl\")\n",
    "    \n",
    "    # 2. Sprawdzenie, kim jestem (Rank)\n",
    "    rank = dist.get_rank()\n",
    "    world_size = dist.get_world_size()\n",
    "    device = torch.device(f\"cuda:{rank}\")\n",
    "    \n",
    "    # 3. Model na GPU\n",
    "    model = MyModel().to(device)\n",
    "    # Magia: DDP automatycznie rejestruje hooki na gradientach, ≈ºeby robiƒá AllReduce\n",
    "    model = DDP(model, device_ids=[rank])\n",
    "    \n",
    "    # 4. Sampler (≈ªeby ka≈ºdy GPU dosta≈Ç inne dane!)\n",
    "    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)\n",
    "    loader = DataLoader(dataset, sampler=sampler, batch_size=32)\n",
    "    \n",
    "    # 5. Pƒôtla\n",
    "    for epoch in range(10):\n",
    "        sampler.set_epoch(epoch) # Wa≈ºne dla tasowania!\n",
    "        for batch in loader:\n",
    "            ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356cf69d",
   "metadata": {},
   "source": [
    "## ü•ã Black Belt Summary\n",
    "\n",
    "1.  **DistributedSampler:** Kluczowy element. Dzieli tort danych na kawa≈Çki. Bez tego ka≈ºdy GPU uczy≈Çby siƒô na tym samym (strata zasob√≥w) lub losowo (ryzyko duplikat√≥w).\n",
    "2.  **SyncBatchNorm:** Zwyk≈Çy BatchNorm dzia≈Ça tylko lokalnie (na 1 GPU). Je≈õli masz ma≈Çy batch per GPU (np. 2), BN zwariuje. Musisz u≈ºyƒá `nn.SyncBatchNorm.convert_sync_batchnorm(model)`, ≈ºeby statystyki by≈Çy liczone globalnie (kosztuje trochƒô czasu na komunikacjƒô).\n",
    "3.  **`torchrun`:** Nie uruchamiaj skrypt√≥w przez `python train.py`. U≈ºywaj `torchrun --nproc_per_node=4 train.py`. To automatycznie zarzƒÖdza rangami."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
