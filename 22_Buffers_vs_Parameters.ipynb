{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6397ff6d",
   "metadata": {},
   "source": [
    "# ü•ã Lekcja 22: Buffers vs Parameters (Stan nietrenowalny)\n",
    "\n",
    "W PyTorch `nn.Module` ma dwa g≈Ç√≥wne magazyny:\n",
    "1.  **Parameters:** Tensory, kt√≥re majƒÖ gradient i sƒÖ aktualizowane przez optymalizator (Wagi, Biasy).\n",
    "2.  **Buffers:** Tensory, kt√≥re sƒÖ czƒô≈õciƒÖ stanu modelu (zapisujƒÖ siƒô w `state_dict`, przenoszƒÖ siƒô na GPU), ale **nie sƒÖ trenowane** przez gradient.\n",
    "\n",
    "**Typowy b≈ÇƒÖd:**\n",
    "Przypisanie tensora jako zwyk≈Çego atrybutu (`self.t = torch.randn(5)`).\n",
    "*   Skutek 1: Nie przeniesie siƒô na GPU przy `model.cuda()`.\n",
    "*   Skutek 2: Nie zapisze siƒô przy `torch.save()`.\n",
    "\n",
    "W tej lekcji naprawimy ten b≈ÇƒÖd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7367026e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model zainicjowany.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Definiujemy modu≈Ç z 3 rodzajami zmiennych\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. Parameter (Standard)\n",
    "        # To bƒôdzie trenowane.\n",
    "        self.weight = nn.Parameter(torch.randn(3, 3))\n",
    "        \n",
    "        # 2. Zwyk≈Çy atrybut (B≈ÅƒÑD!)\n",
    "        # To jest \"niewidzialne\" dla silnika PyTorch.\n",
    "        self.mistake_tensor = torch.randn(3, 3)\n",
    "        \n",
    "        # 3. Buffer (POPRAWNIE)\n",
    "        # To jest stan nietrenowalny (np. ≈õrednia w BatchNorm).\n",
    "        # Musimy u≈ºyƒá register_buffer(nazwa, tensor)\n",
    "        self.register_buffer('running_mean', torch.randn(3, 3))\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "print(\"Model zainicjowany.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492b6f34",
   "metadata": {},
   "source": [
    "## Test 1: Przenoszenie na GPU (`.to(device)`)\n",
    "\n",
    "To jest najczƒôstsza przyczyna b≈Çƒôdu `RuntimeError: Expected all tensors to be on the same device`.\n",
    "U≈ºytkownik pisze `model.to('cuda')`, ale jego pomocniczy tensor zostaje na CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b6e2ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przenoszƒô model na: cuda\n",
      "\n",
      "--- GDZIE SƒÑ DANE? ---\n",
      "Weight (Param):       cuda:0\n",
      "Running Mean (Buffer): cuda:0\n",
      "Mistake (Zwyk≈Çy):      cpu\n",
      "\n",
      "‚ùå B≈ÅƒÑD! 'mistake_tensor' zosta≈Ç na CPU, mimo ≈ºe model jest na GPU.\n",
      "W obliczeniach to spowoduje awariƒô.\n"
     ]
    }
   ],
   "source": [
    "# Sprawd≈∫my, czy masz GPU (je≈õli nie, test poka≈ºemy na idei)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Przenoszƒô model na: {device}\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print(\"\\n--- GDZIE SƒÑ DANE? ---\")\n",
    "print(f\"Weight (Param):       {model.weight.device}\")\n",
    "print(f\"Running Mean (Buffer): {model.running_mean.device}\")\n",
    "print(f\"Mistake (Zwyk≈Çy):      {model.mistake_tensor.device}\")\n",
    "\n",
    "if str(device) != 'cpu' and str(model.mistake_tensor.device) == 'cpu':\n",
    "    print(\"\\n‚ùå B≈ÅƒÑD! 'mistake_tensor' zosta≈Ç na CPU, mimo ≈ºe model jest na GPU.\")\n",
    "    print(\"W obliczeniach to spowoduje awariƒô.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40979199",
   "metadata": {},
   "source": [
    "## Test 2: Zapisywanie modelu (`state_dict`)\n",
    "\n",
    "Czy nasze dane przetrwajƒÖ zapis do pliku?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e3cd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CO JEST W PLIKU ZAPISU? ---\n",
      "odict_keys(['weight', 'running_mean'])\n",
      "‚úÖ Buffer: JEST ZAPISANY.\n",
      "‚ùå Mistake: BRAK (Zgubili≈õmy dane!).\n"
     ]
    }
   ],
   "source": [
    "state = model.state_dict()\n",
    "\n",
    "print(\"--- CO JEST W PLIKU ZAPISU? ---\")\n",
    "print(state.keys())\n",
    "\n",
    "# Weryfikacja\n",
    "if 'running_mean' in state:\n",
    "    print(\"‚úÖ Buffer: JEST ZAPISANY.\")\n",
    "else:\n",
    "    print(\"‚ùå Buffer: BRAK.\")\n",
    "\n",
    "if 'mistake_tensor' in state:\n",
    "    print(\"‚úÖ Mistake: JEST ZAPISANY.\")\n",
    "else:\n",
    "    print(\"‚ùå Mistake: BRAK (Zgubili≈õmy dane!).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577b7ee6",
   "metadata": {},
   "source": [
    "## Test 3: Optymalizator\n",
    "\n",
    "Czy optymalizator (np. Adam) spr√≥buje zmieniƒá nasze warto≈õci?\n",
    "Bufor√≥w nie powinien dotykaƒá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b7fe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CO WIDZI OPTYMALIZATOR? ---\n",
      "Trenowane parametry: ['weight']\n",
      "‚úÖ Buffer jest bezpieczny (nie bƒôdzie modyfikowany przez SGD).\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "print(\"--- CO WIDZI OPTYMALIZATOR? ---\")\n",
    "# Optymalizator iteruje po parametrach\n",
    "param_names = [n for n, p in model.named_parameters()]\n",
    "\n",
    "print(f\"Trenowane parametry: {param_names}\")\n",
    "\n",
    "if 'running_mean' not in param_names:\n",
    "    print(\"‚úÖ Buffer jest bezpieczny (nie bƒôdzie modyfikowany przez SGD).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6e6430",
   "metadata": {},
   "source": [
    "## ü•ã Black Belt Summary\n",
    "\n",
    "**Kiedy u≈ºywaƒá `register_buffer`?**\n",
    "\n",
    "1.  **BatchNorm / LayerNorm:** Przechowywanie ≈õredniej i wariancji, kt√≥re sƒÖ aktualizowane matematycznie, a nie gradientem.\n",
    "2.  **Positional Encodings (Transformer):** Macierz sinus√≥w jest sta≈Ça. Musi byƒá na GPU, musi byƒá zapisana z modelem, ale nie mo≈ºe siƒô zmieniaƒá.\n",
    "3.  **Maski:** Maski przyczynowe (Causal Mask) w GPT.\n",
    "4.  **Liczniki:** Np. `self.register_buffer('steps', torch.tensor(0))`, je≈õli chcesz, ≈ºeby model wiedzia≈Ç, ile krok√≥w ju≈º trenowa≈Ç (i ≈ºeby to siƒô zapisa≈Ço w checkpoincie).\n",
    "\n",
    "Je≈õli napiszesz `self.cos_table = ...` w Transformerze ‚Äì pope≈Çniasz b≈ÇƒÖd. U≈ºyj `register_buffer`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
