{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "458b09d3",
   "metadata": {},
   "source": [
    "# ü•ã Lekcja 15: Dataset vs IterableDataset (Streaming danych)\n",
    "\n",
    "W PyTorch mamy dwa sposoby na karmienie modelu danymi:\n",
    "\n",
    "1.  **Map-style (`Dataset`):**\n",
    "    *   Musisz znaƒá d≈Çugo≈õƒá (`__len__`).\n",
    "    *   Musisz mieƒá dostƒôp do ka≈ºdego elementu (`__getitem__(idx)`).\n",
    "    *   *Idealne do:* Zdjƒôƒá na dysku, ma≈Çych plik√≥w CSV.\n",
    "\n",
    "2.  **Iterable-style (`IterableDataset`):**\n",
    "    *   Dzia≈Ça jak strumie≈Ñ (Generator).\n",
    "    *   Nie musi znaƒá ko≈Ñca danych.\n",
    "    *   *Idealne do:* Petabajt√≥w tekstu, streamingu z sieci, log√≥w serwera.\n",
    "\n",
    "W tej lekcji napiszemy **poprawnƒÖ klasƒô `IterableDataset`**, kt√≥ra potrafi bezpiecznie dzieliƒá pracƒô, nawet je≈õli uruchomimy jƒÖ na wielu workerach (na serwerze produkcyjnym)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac75decf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dane ≈∫r√≥d≈Çowe: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, IterableDataset, DataLoader\n",
    "import math\n",
    "\n",
    "# Symulacja danych (np. linie w ogromnym pliku tekstowym)\n",
    "data_source = list(range(20))\n",
    "\n",
    "print(f\"Dane ≈∫r√≥d≈Çowe: {data_source}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a3b4b",
   "metadata": {},
   "source": [
    "## Podej≈õcie 1: Klasyczny Map-style (Standard)\n",
    "\n",
    "To znasz. Proste i skuteczne, ale wymaga za≈Çadowania indeks√≥w do pamiƒôci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fad76f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Map Dataset (Dzia≈Ça losowo) ---\n",
      "[16, 13, 11, 7]\n",
      "[5, 0, 12, 3]\n",
      "[10, 14, 19, 4]\n",
      "[9, 17, 8, 6]\n",
      "[1, 18, 2, 15]\n"
     ]
    }
   ],
   "source": [
    "class MyMapDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Test\n",
    "map_ds = MyMapDataset(data_source)\n",
    "loader = DataLoader(map_ds, batch_size=4, shuffle=True)\n",
    "\n",
    "print(\"--- Map Dataset (Dzia≈Ça losowo) ---\")\n",
    "for batch in loader:\n",
    "    print(batch.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d53318",
   "metadata": {},
   "source": [
    "## Podej≈õcie 2: IterableDataset (Streaming)\n",
    "\n",
    "Tutaj implementujemy metodƒô `__iter__`.\n",
    "\n",
    "**Kluczowy mechanizm (Workload Splitting):**\n",
    "Je≈õli uruchomimy to na wielu procesorach (workerach), ka≈ºdy dostanie kopiƒô datasetu.\n",
    "Musimy rƒôcznie sprawdziƒá `get_worker_info()`, ≈ºeby ka≈ºdy worker wziƒÖ≈Ç **inny kawa≈Çek tortu**.\n",
    "Inaczej model uczy≈Çby siƒô na zduplikowanych danych.\n",
    "\n",
    "*Poni≈ºszy kod jest \"Production Ready\" - zadzia≈Ça poprawnie zar√≥wno na 1 procesie (Windows/Jupyter), jak i na 100 procesach (Klaster Linux).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1790202b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klasa zdefiniowana. Gotowa do u≈ºycia.\n"
     ]
    }
   ],
   "source": [
    "class SmartIterableDataset(IterableDataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __iter__(self):\n",
    "        worker_info = torch.utils.data.get_worker_info()\n",
    "        \n",
    "        if worker_info is None:\n",
    "            # SCENARIUSZ A: Jeden proces (np. Jupyter na Windowsie)\n",
    "            # Bierzemy ca≈Çe dane od poczƒÖtku do ko≈Ñca.\n",
    "            iter_start = 0\n",
    "            iter_end = len(self.data)\n",
    "            iter_step = 1\n",
    "        else:\n",
    "            # SCENARIUSZ B: Wiele worker√≥w (np. Serwer treningowy)\n",
    "            # Dzielimy dane, ≈ºeby workery nie dublowa≈Çy pracy.\n",
    "            worker_id = worker_info.id\n",
    "            num_workers = worker_info.num_workers\n",
    "            \n",
    "            # Ka≈ºdy worker bierze co n-ty element (np. co 4)\n",
    "            iter_start = worker_id\n",
    "            iter_end = len(self.data)\n",
    "            iter_step = num_workers\n",
    "            \n",
    "        # Generator (yield) - zwraca dane kawa≈Çek po kawa≈Çku\n",
    "        for i in range(iter_start, iter_end, iter_step):\n",
    "            yield self.data[i]\n",
    "\n",
    "print(\"Klasa zdefiniowana. Gotowa do u≈ºycia.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f728b46c",
   "metadata": {},
   "source": [
    "## Uruchomienie (Bezpieczne dla Windows)\n",
    "\n",
    "U≈ºyjemy `num_workers=0`.\n",
    "Dlaczego? Bo Jupyter na Windowsie nie obs≈Çuguje wieloprocesowo≈õci dla klas zdefiniowanych wewnƒÖtrz kom√≥rki.\n",
    "Ale dziƒôki naszej logice `if worker_info is None`, kod zadzia≈Ça bezb≈Çƒôdnie i przetworzy wszystkie dane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37ee797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iterable Dataset (Streaming) ---\n",
      "Batch: [0, 1, 2, 3]\n",
      "Batch: [4, 5, 6, 7]\n",
      "Batch: [8, 9, 10, 11]\n",
      "Batch: [12, 13, 14, 15]\n",
      "Batch: [16, 17, 18, 19]\n",
      "------------------------------\n",
      "Odebrano ≈ÇƒÖcznie: 20 element√≥w.\n",
      "‚úÖ SUKCES: Wszystkie dane zosta≈Çy przetworzone poprawnie (bez duplikat√≥w).\n"
     ]
    }
   ],
   "source": [
    "# Inicjalizacja\n",
    "iter_ds = SmartIterableDataset(data_source)\n",
    "\n",
    "# Tworzymy Loader (num_workers=0 zapewnia stabilno≈õƒá w notatniku)\n",
    "loader = DataLoader(iter_ds, batch_size=4, num_workers=0)\n",
    "\n",
    "print(\"--- Iterable Dataset (Streaming) ---\")\n",
    "all_data = []\n",
    "\n",
    "for batch in loader:\n",
    "    print(f\"Batch: {batch.tolist()}\")\n",
    "    all_data.extend(batch.tolist())\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Odebrano ≈ÇƒÖcznie: {len(all_data)} element√≥w.\")\n",
    "# Sprawdzenie poprawno≈õci\n",
    "if sorted(all_data) == data_source:\n",
    "    print(\"‚úÖ SUKCES: Wszystkie dane zosta≈Çy przetworzone poprawnie (bez duplikat√≥w).\")\n",
    "else:\n",
    "    print(\"‚ùå B≈ÅƒÑD: Co≈õ siƒô zgubi≈Ço lub zdublowa≈Ço.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a123d4",
   "metadata": {},
   "source": [
    "## ü•ã Black Belt Summary\n",
    "\n",
    "1.  **IterableDataset** to konieczno≈õƒá przy Big Data (gdy nie mo≈ºesz zrobiƒá `len(data)`).\n",
    "2.  **Pu≈Çapka Duplikat√≥w:** Domy≈õlnie PyTorch kopiuje dataset do ka≈ºdego workera. Musisz u≈ºyƒá `get_worker_info()` wewnƒÖtrz `__iter__`, ≈ºeby podzieliƒá pracƒô.\n",
    "3.  **Shuffle:** W `IterableDataset` nie ma globalnego tasowania (`shuffle=True` nie zadzia≈Ça idealnie). Tasuje siƒô tylko lokalnie w buforze (o czym wiƒôcej w module zaawansowanym)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
