{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4341c56",
   "metadata": {},
   "source": [
    "# ðŸ¥‹ Lekcja 13: Gradient Accumulation (DuÅ¼y Batch na MaÅ‚ym GPU)\n",
    "\n",
    "W PyTorch `loss.backward()` nie nadpisuje gradientÃ³w, ale je **akumuluje** (dodaje do istniejÄ…cych: `w.grad += new_grad`).\n",
    "Zazwyczaj walczymy z tym, wpisujÄ…c `optimizer.zero_grad()` w kaÅ¼dej pÄ™tli.\n",
    "\n",
    "Ale w **Gradient Accumulation** wykorzystujemy to jako zaletÄ™!\n",
    "\n",
    "**Algorytm:**\n",
    "1.  Podziel wirtualny \"DuÅ¼y Batch\" (np. 128) na maÅ‚e \"Mikro Batche\" (np. 32).\n",
    "2.  ZrÃ³b Forward i Backward dla Mikro Batcha.\n",
    "3.  **WaÅ¼ne:** Podziel Loss przez liczbÄ™ krokÃ³w akumulacji (Å¼eby Å›rednia siÄ™ zgadzaÅ‚a).\n",
    "4.  PowtÃ³rz N razy.\n",
    "5.  Dopiero wtedy zrÃ³b `step()` i `zero_grad()`.\n",
    "\n",
    "DziÄ™ki temu trenujesz model tak, jakbyÅ› miaÅ‚ superkomputer, uÅ¼ywajÄ…c laptopa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8a688dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Batch: 32\n",
      "Real Batch:   8\n",
      "Kroki akumulacji: 4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Konfiguracja\n",
    "LARGE_BATCH_SIZE = 32   # Taki chcemy symulowaÄ‡\n",
    "MICRO_BATCH_SIZE = 8    # Taki mieÅ›ci siÄ™ w pamiÄ™ci\n",
    "ACCUMULATION_STEPS = LARGE_BATCH_SIZE // MICRO_BATCH_SIZE\n",
    "\n",
    "print(f\"Target Batch: {LARGE_BATCH_SIZE}\")\n",
    "print(f\"Real Batch:   {MICRO_BATCH_SIZE}\")\n",
    "print(f\"Kroki akumulacji: {ACCUMULATION_STEPS}\")\n",
    "\n",
    "# Dane i Model\n",
    "data = torch.randn(LARGE_BATCH_SIZE, 10)\n",
    "target = torch.randn(LARGE_BATCH_SIZE, 1)\n",
    "\n",
    "model = nn.Linear(10, 1)\n",
    "# Kopiujemy model, Å¼eby porÃ³wnaÄ‡ dwie metody (czy dajÄ… ten sam wynik)\n",
    "model_copy = nn.Linear(10, 1)\n",
    "model_copy.load_state_dict(model.state_dict())\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer_copy = optim.SGD(model_copy.parameters(), lr=0.01)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8a749a",
   "metadata": {},
   "source": [
    "## Metoda 1: Standardowa (DuÅ¼y Batch)\n",
    "\n",
    "To jest nasz punkt odniesienia (Baseline).\n",
    "Wrzucamy 32 prÃ³bki naraz. ZakÅ‚adamy, Å¼e mamy nieskoÅ„czonoÅ›Ä‡ RAM-u."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4017295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wagi po standardowym kroku (pierwsze 5):\n",
      "tensor([-0.2719, -0.0496, -0.2903,  0.0671,  0.2706])\n"
     ]
    }
   ],
   "source": [
    "# 1. Standardowy krok (Wszystko naraz)\n",
    "optimizer_copy.zero_grad()\n",
    "\n",
    "pred_full = model_copy(data)\n",
    "loss_full = criterion(pred_full, target)\n",
    "\n",
    "loss_full.backward()\n",
    "optimizer_copy.step()\n",
    "\n",
    "print(\"Wagi po standardowym kroku (pierwsze 5):\")\n",
    "print(model_copy.weight.data[0, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd6f4b",
   "metadata": {},
   "source": [
    "## Metoda 2: Gradient Accumulation\n",
    "\n",
    "Teraz zrobimy to samo, ale \"na raty\", po 8 prÃ³bek.\n",
    "Kluczowe zmiany:\n",
    "1.  Dzielimy `loss` przez `ACCUMULATION_STEPS`. Dlaczego?\n",
    "    *   `MSELoss` liczy Å›redniÄ… z batcha.\n",
    "    *   Åšrednia z 32 elementÃ³w to `sum(errors) / 32`.\n",
    "    *   Åšrednia z 8 elementÃ³w to `sum(errors) / 8`.\n",
    "    *   JeÅ›li po prostu dodamy gradienty z 4 maÅ‚ych batchy, suma bÄ™dzie 4x za duÅ¼a! Musimy to skorygowaÄ‡ rÄ™cznie.\n",
    "2.  `optimizer.step()` wykonujemy tylko co N krokÃ³w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da1e86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krok 1/4: Gradient policzony (ale wagi stojÄ…).\n",
      "Krok 2/4: Gradient policzony (ale wagi stojÄ…).\n",
      "Krok 3/4: Gradient policzony (ale wagi stojÄ…).\n",
      "Krok 4/4: Gradient policzony (ale wagi stojÄ…).\n",
      "\n",
      "Wagi po akumulacji (pierwsze 5):\n",
      "tensor([-0.2719, -0.0496, -0.2903,  0.0671,  0.2706])\n"
     ]
    }
   ],
   "source": [
    "# 2. Akumulacja\n",
    "optimizer.zero_grad() # Zerujemy raz na poczÄ…tku\n",
    "\n",
    "# PÄ™tla po mikro-batchach\n",
    "for i in range(ACCUMULATION_STEPS):\n",
    "    # Wycinamy kawaÅ‚ek danych (Slicing)\n",
    "    start = i * MICRO_BATCH_SIZE\n",
    "    end = start + MICRO_BATCH_SIZE\n",
    "    \n",
    "    micro_data = data[start:end]\n",
    "    micro_target = target[start:end]\n",
    "    \n",
    "    # Forward\n",
    "    pred = model(micro_data)\n",
    "    loss = criterion(pred, micro_target)\n",
    "    \n",
    "    # --- MAGIA AKUMULACJI ---\n",
    "    # Normalizujemy stratÄ™!\n",
    "    loss = loss / ACCUMULATION_STEPS\n",
    "    \n",
    "    # Backward (Gradienty siÄ™ dodajÄ… do .grad)\n",
    "    loss.backward()\n",
    "    \n",
    "    print(f\"Krok {i+1}/{ACCUMULATION_STEPS}: Gradient policzony (ale wagi stojÄ…).\")\n",
    "\n",
    "# Dopiero teraz aktualizacja wag\n",
    "optimizer.step()\n",
    "\n",
    "print(\"\\nWagi po akumulacji (pierwsze 5):\")\n",
    "print(model.weight.data[0, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8091e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Maksymalna rÃ³Å¼nica miÄ™dzy metodami: 0.0000000000\n",
      "âœ… SUKCES! Akumulacja dziaÅ‚a matematycznie identycznie jak duÅ¼y batch.\n"
     ]
    }
   ],
   "source": [
    "# WERYFIKACJA\n",
    "# Czy wyniki sÄ… identyczne?\n",
    "diff = torch.abs(model.weight.data - model_copy.weight.data).max()\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Maksymalna rÃ³Å¼nica miÄ™dzy metodami: {diff:.10f}\")\n",
    "\n",
    "if diff < 1e-6:\n",
    "    print(\"âœ… SUKCES! Akumulacja dziaÅ‚a matematycznie identycznie jak duÅ¼y batch.\")\n",
    "else:\n",
    "    print(\"âŒ COÅš NIE TAK. RÃ³Å¼nica jest zbyt duÅ¼a.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20aaefa",
   "metadata": {},
   "source": [
    "## ðŸ¥‹ Black Belt Summary\n",
    "\n",
    "Gradient Accumulation to potÄ™Å¼ne narzÄ™dzie, ale ma **jeden haczyk**:\n",
    "\n",
    "**Batch Normalization.**\n",
    "Warstwy `BatchNorm` liczÄ… Å›redniÄ… i wariancjÄ™ z **bieÅ¼Ä…cego batcha**.\n",
    "*   W duÅ¼ym batchu (32): Statystyki sÄ… liczone z 32 prÃ³bek.\n",
    "*   W akumulacji (8): Statystyki sÄ… liczone z 8 prÃ³bek (sÄ… bardziej zaszumione!).\n",
    "\n",
    "Akumulacja symuluje duÅ¼y batch dla WAG, ale **NIE dla Batchorma**.\n",
    "JeÅ›li musisz uÅ¼ywaÄ‡ akumulacji przy bardzo maÅ‚ych batchach (np. 1 lub 2), lepiej zamieÅ„ `BatchNorm` na `LayerNorm` lub `GroupNorm`, ktÃ³re nie zaleÅ¼Ä… od wielkoÅ›ci batcha."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
