{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n<a href=\"https://colab.research.google.com/github/takzen/pytorch-black-belt/blob/main/35_Weight_Decay_vs_L2.ipynb\" target=\"_parent\">\n    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd0b135",
   "metadata": {},
   "source": [
    "# \ud83e\udd4b Lekcja 35: Weight Decay vs L2 Regularization (Adam vs AdamW)\n",
    "\n",
    "Chcemy zapobiec overfittingowi, karaj\u0105c model za du\u017ce wagi.\n",
    "Mamy dwa sposoby matematyczne:\n",
    "\n",
    "1.  **L2 Regularization:** Dodajemy kar\u0119 do funkcji kosztu:\n",
    "    $$ Loss = MSE + \\frac{\\lambda}{2} ||w||^2 $$\n",
    "    Gradient: $\\nabla Loss = \\nabla MSE + \\lambda w$\n",
    "\n",
    "2.  **Weight Decay:** Modyfikujemy regu\u0142\u0119 aktualizacji wagi (bez ruszania Loss):\n",
    "    $$ w_{new} = w_{old} - lr \\cdot \\nabla MSE - lr \\cdot \\lambda \\cdot w_{old} $$\n",
    "\n",
    "**Wielki Sekret:**\n",
    "*   Dla **SGD**, te dwie metody s\u0105 matematycznie r\u00f3wnowa\u017cne.\n",
    "*   Dla **Adam**, NIE S\u0104. Adam dzieli gradient przez \"wariancj\u0119\". Je\u015bli dodasz L2 do gradientu, Adam to \"znormalizuje\" i kara przestanie dzia\u0142a\u0107 tak jak chcemy.\n",
    "*   Dlatego powsta\u0142 **AdamW** (Adam with decoupled Weight Decay), kt\u00f3ry stosuje metod\u0119 nr 2.\n",
    "\n",
    "Sprawdzimy to eksperymentalnie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0618a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from typing import Type\n",
    "\n",
    "# Sta\u0142a inicjalizacyjna\n",
    "W_INIT_VALUE = 10.0\n",
    "\n",
    "def run_experiment(optimizer_cls: Type[torch.optim.Optimizer], steps: int = 100, **optimizer_kwargs) -> float:\n",
    "    \"\"\"\n",
    "    Symuluje p\u0119tl\u0119 treningow\u0105 w izolacji, aby zbada\u0107 wp\u0142yw mechanizm\u00f3w \n",
    "    wewn\u0119trznych optymalizatora (np. Weight Decay) przy braku gradientu z danych.\n",
    "    \n",
    "    Args:\n",
    "        optimizer_cls: Klasa optymalizatora (np. optim.SGD, optim.AdamW)\n",
    "        steps: Liczba krok\u00f3w symulacji\n",
    "        **optimizer_kwargs: Parametry przekazywane do konstruktora (np. lr, weight_decay)\n",
    "        \n",
    "    Returns:\n",
    "        float: Ko\u0144cowa warto\u015b\u0107 wagi po optymalizacji.\n",
    "    \"\"\"\n",
    "    # Inicjalizacja wagi (Leaf Tensor)\n",
    "    w = torch.tensor([W_INIT_VALUE], requires_grad=True)\n",
    "    \n",
    "    # Inicjalizacja optymalizatora\n",
    "    optimizer = optimizer_cls([w], **optimizer_kwargs)\n",
    "    \n",
    "    for _ in range(steps):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # --- MECHANIZM SZTUCZNEGO GRAFU ---\n",
    "        # Tworzymy strat\u0119 zale\u017cn\u0105 od 'w', ale mno\u017cymy j\u0105 przez 0.\n",
    "        # Efekt matematyczny: Loss = 0, Gradient z danych (dLoss/dw) = 0.\n",
    "        # Cel: Zmuszenie PyTorcha do zbudowania grafu i uruchomienia .backward(),\n",
    "        # co pozwoli optymalizatorowi zaaplikowa\u0107 Weight Decay.\n",
    "        loss = w.sum() * 0.0\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return w.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7763423d",
   "metadata": {},
   "source": [
    "## Eksperyment 1: SGD\n",
    "\n",
    "Dla SGD, parametr `weight_decay` w PyTorch implementuje matematyk\u0119 L2.\n",
    "Waga powinna male\u0107 wyk\u0142adniczo (Decay)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce2e0b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (Bez WD): 10.0000\n",
      "SGD (Z WD):   3.6603\n",
      "\u2705 SGD poprawnie zmniejszy\u0142o wag\u0119.\n"
     ]
    }
   ],
   "source": [
    "# SGD bez weight decay (powinno zosta\u0107 10.0)\n",
    "res_sgd_none = run_experiment(optim.SGD, lr=0.1, weight_decay=0.0)\n",
    "\n",
    "# SGD z weight decay\n",
    "res_sgd_wd = run_experiment(optim.SGD, lr=0.1, weight_decay=0.1)\n",
    "\n",
    "print(f\"SGD (Bez WD): {res_sgd_none:.4f}\")\n",
    "print(f\"SGD (Z WD):   {res_sgd_wd:.4f}\")\n",
    "\n",
    "if res_sgd_wd < res_sgd_none:\n",
    "    print(\"\u2705 SGD poprawnie zmniejszy\u0142o wag\u0119.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846efbeb",
   "metadata": {},
   "source": [
    "## Eksperyment 2: Adam vs AdamW\n",
    "\n",
    "Tutaj le\u017cy pies pogrzebany.\n",
    "*   **`optim.Adam`**: Traktuje `weight_decay` jako L2 Regularization (dodaje do gradientu). Poniewa\u017c Adam dzieli przez histori\u0119 gradient\u00f3w, ta kara L2 jest \"wyg\u0142adzana\" i traci swoj\u0105 si\u0142\u0119 przy rzadkich cechach.\n",
    "*   **`optim.AdamW`**: Odejmuje decay bezpo\u015brednio od wagi, omijaj\u0105c mechanizm adaptacyjny Adama.\n",
    "\n",
    "Przyjrzyjmy si\u0119 wynikom. AdamW powinien zmniejszy\u0107 wag\u0119 **mocniej/bardziej przewidywalnie** ni\u017c Adam przy tych samych ustawieniach, w sytuacji gdy gradient z danych jest zerowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bcd823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam  (L2 style):    2.2445\n",
      "AdamW (Decoupled):   3.6603\n",
      "\n",
      "R\u00f3\u017cnica w wyniku: 1.4159\n"
     ]
    }
   ],
   "source": [
    "# Adam z 'weight_decay' (To jest implementacja L2!)\n",
    "res_adam = run_experiment(optim.Adam, lr=0.1, weight_decay=0.1)\n",
    "\n",
    "# AdamW z 'weight_decay' (To jest prawdziwe Decoupled Weight Decay)\n",
    "res_adamw = run_experiment(optim.AdamW, lr=0.1, weight_decay=0.1)\n",
    "\n",
    "print(f\"Adam  (L2 style):    {res_adam:.4f}\")\n",
    "print(f\"AdamW (Decoupled):   {res_adamw:.4f}\")\n",
    "\n",
    "# Analiza r\u00f3\u017cnicy\n",
    "diff = abs(res_adam - res_adamw)\n",
    "print(f\"\\nR\u00f3\u017cnica w wyniku: {diff:.4f}\")\n",
    "\n",
    "if res_adamw < res_adam:\n",
    "    print(\"\ud83d\udc49 AdamW zredukowa\u0142 wag\u0119 mocniej.\")\n",
    "    print(\"Dlaczego? W zwyk\u0142ym Adamie, gdy gradient=0, mechanizm adaptacyjny 'dzielenia przez zero' (epsilon) zaburza kar\u0119 L2.\")\n",
    "    print(\"AdamW aplikuje kar\u0119 czysto matematycznie: w = w - lr * lambda * w.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e313f7",
   "metadata": {},
   "source": [
    "## \ud83e\udd4b Black Belt Summary\n",
    "\n",
    "To jest najcz\u0119stszy b\u0142\u0105d w implementacji Transformer\u00f3w.\n",
    "Wielu in\u017cynier\u00f3w u\u017cywa `optim.Adam(model.parameters(), weight_decay=0.01)`.\n",
    "To jest **B\u0141\u0104D**. To nie dzia\u0142a tak, jak my\u015blisz.\n",
    "\n",
    "**Z\u0142ota Zasada:**\n",
    "1.  U\u017cywasz SGD? -> `optim.SGD` (weight_decay dzia\u0142a ok).\n",
    "2.  U\u017cywasz Adama? -> **ZAWSZE u\u017cywaj `optim.AdamW`**.\n",
    "3.  Zwyk\u0142y `optim.Adam` u\u017cywaj tylko wtedy, gdy `weight_decay=0` (bez regularyzacji)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}