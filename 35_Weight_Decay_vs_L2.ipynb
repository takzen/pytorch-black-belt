{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbd0b135",
   "metadata": {},
   "source": [
    "# ðŸ¥‹ Lekcja 35: Weight Decay vs L2 Regularization (Adam vs AdamW)\n",
    "\n",
    "Chcemy zapobiec overfittingowi, karajÄ…c model za duÅ¼e wagi.\n",
    "Mamy dwa sposoby matematyczne:\n",
    "\n",
    "1.  **L2 Regularization:** Dodajemy karÄ™ do funkcji kosztu:\n",
    "    $$ Loss = MSE + \\frac{\\lambda}{2} ||w||^2 $$\n",
    "    Gradient: $\\nabla Loss = \\nabla MSE + \\lambda w$\n",
    "\n",
    "2.  **Weight Decay:** Modyfikujemy reguÅ‚Ä™ aktualizacji wagi (bez ruszania Loss):\n",
    "    $$ w_{new} = w_{old} - lr \\cdot \\nabla MSE - lr \\cdot \\lambda \\cdot w_{old} $$\n",
    "\n",
    "**Wielki Sekret:**\n",
    "*   Dla **SGD**, te dwie metody sÄ… matematycznie rÃ³wnowaÅ¼ne.\n",
    "*   Dla **Adam**, NIE SÄ„. Adam dzieli gradient przez \"wariancjÄ™\". JeÅ›li dodasz L2 do gradientu, Adam to \"znormalizuje\" i kara przestanie dziaÅ‚aÄ‡ tak jak chcemy.\n",
    "*   Dlatego powstaÅ‚ **AdamW** (Adam with decoupled Weight Decay), ktÃ³ry stosuje metodÄ™ nr 2.\n",
    "\n",
    "Sprawdzimy to eksperymentalnie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0618a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from typing import Type\n",
    "\n",
    "# StaÅ‚a inicjalizacyjna\n",
    "W_INIT_VALUE = 10.0\n",
    "\n",
    "def run_experiment(optimizer_cls: Type[torch.optim.Optimizer], steps: int = 100, **optimizer_kwargs) -> float:\n",
    "    \"\"\"\n",
    "    Symuluje pÄ™tlÄ™ treningowÄ… w izolacji, aby zbadaÄ‡ wpÅ‚yw mechanizmÃ³w \n",
    "    wewnÄ™trznych optymalizatora (np. Weight Decay) przy braku gradientu z danych.\n",
    "    \n",
    "    Args:\n",
    "        optimizer_cls: Klasa optymalizatora (np. optim.SGD, optim.AdamW)\n",
    "        steps: Liczba krokÃ³w symulacji\n",
    "        **optimizer_kwargs: Parametry przekazywane do konstruktora (np. lr, weight_decay)\n",
    "        \n",
    "    Returns:\n",
    "        float: KoÅ„cowa wartoÅ›Ä‡ wagi po optymalizacji.\n",
    "    \"\"\"\n",
    "    # Inicjalizacja wagi (Leaf Tensor)\n",
    "    w = torch.tensor([W_INIT_VALUE], requires_grad=True)\n",
    "    \n",
    "    # Inicjalizacja optymalizatora\n",
    "    optimizer = optimizer_cls([w], **optimizer_kwargs)\n",
    "    \n",
    "    for _ in range(steps):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # --- MECHANIZM SZTUCZNEGO GRAFU ---\n",
    "        # Tworzymy stratÄ™ zaleÅ¼nÄ… od 'w', ale mnoÅ¼ymy jÄ… przez 0.\n",
    "        # Efekt matematyczny: Loss = 0, Gradient z danych (dLoss/dw) = 0.\n",
    "        # Cel: Zmuszenie PyTorcha do zbudowania grafu i uruchomienia .backward(),\n",
    "        # co pozwoli optymalizatorowi zaaplikowaÄ‡ Weight Decay.\n",
    "        loss = w.sum() * 0.0\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return w.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7763423d",
   "metadata": {},
   "source": [
    "## Eksperyment 1: SGD\n",
    "\n",
    "Dla SGD, parametr `weight_decay` w PyTorch implementuje matematykÄ™ L2.\n",
    "Waga powinna maleÄ‡ wykÅ‚adniczo (Decay)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce2e0b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (Bez WD): 10.0000\n",
      "SGD (Z WD):   3.6603\n",
      "âœ… SGD poprawnie zmniejszyÅ‚o wagÄ™.\n"
     ]
    }
   ],
   "source": [
    "# SGD bez weight decay (powinno zostaÄ‡ 10.0)\n",
    "res_sgd_none = run_experiment(optim.SGD, lr=0.1, weight_decay=0.0)\n",
    "\n",
    "# SGD z weight decay\n",
    "res_sgd_wd = run_experiment(optim.SGD, lr=0.1, weight_decay=0.1)\n",
    "\n",
    "print(f\"SGD (Bez WD): {res_sgd_none:.4f}\")\n",
    "print(f\"SGD (Z WD):   {res_sgd_wd:.4f}\")\n",
    "\n",
    "if res_sgd_wd < res_sgd_none:\n",
    "    print(\"âœ… SGD poprawnie zmniejszyÅ‚o wagÄ™.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846efbeb",
   "metadata": {},
   "source": [
    "## Eksperyment 2: Adam vs AdamW\n",
    "\n",
    "Tutaj leÅ¼y pies pogrzebany.\n",
    "*   **`optim.Adam`**: Traktuje `weight_decay` jako L2 Regularization (dodaje do gradientu). PoniewaÅ¼ Adam dzieli przez historiÄ™ gradientÃ³w, ta kara L2 jest \"wygÅ‚adzana\" i traci swojÄ… siÅ‚Ä™ przy rzadkich cechach.\n",
    "*   **`optim.AdamW`**: Odejmuje decay bezpoÅ›rednio od wagi, omijajÄ…c mechanizm adaptacyjny Adama.\n",
    "\n",
    "Przyjrzyjmy siÄ™ wynikom. AdamW powinien zmniejszyÄ‡ wagÄ™ **mocniej/bardziej przewidywalnie** niÅ¼ Adam przy tych samych ustawieniach, w sytuacji gdy gradient z danych jest zerowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bcd823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam  (L2 style):    2.2445\n",
      "AdamW (Decoupled):   3.6603\n",
      "\n",
      "RÃ³Å¼nica w wyniku: 1.4159\n"
     ]
    }
   ],
   "source": [
    "# Adam z 'weight_decay' (To jest implementacja L2!)\n",
    "res_adam = run_experiment(optim.Adam, lr=0.1, weight_decay=0.1)\n",
    "\n",
    "# AdamW z 'weight_decay' (To jest prawdziwe Decoupled Weight Decay)\n",
    "res_adamw = run_experiment(optim.AdamW, lr=0.1, weight_decay=0.1)\n",
    "\n",
    "print(f\"Adam  (L2 style):    {res_adam:.4f}\")\n",
    "print(f\"AdamW (Decoupled):   {res_adamw:.4f}\")\n",
    "\n",
    "# Analiza rÃ³Å¼nicy\n",
    "diff = abs(res_adam - res_adamw)\n",
    "print(f\"\\nRÃ³Å¼nica w wyniku: {diff:.4f}\")\n",
    "\n",
    "if res_adamw < res_adam:\n",
    "    print(\"ðŸ‘‰ AdamW zredukowaÅ‚ wagÄ™ mocniej.\")\n",
    "    print(\"Dlaczego? W zwykÅ‚ym Adamie, gdy gradient=0, mechanizm adaptacyjny 'dzielenia przez zero' (epsilon) zaburza karÄ™ L2.\")\n",
    "    print(\"AdamW aplikuje karÄ™ czysto matematycznie: w = w - lr * lambda * w.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e313f7",
   "metadata": {},
   "source": [
    "## ðŸ¥‹ Black Belt Summary\n",
    "\n",
    "To jest najczÄ™stszy bÅ‚Ä…d w implementacji TransformerÃ³w.\n",
    "Wielu inÅ¼ynierÃ³w uÅ¼ywa `optim.Adam(model.parameters(), weight_decay=0.01)`.\n",
    "To jest **BÅÄ„D**. To nie dziaÅ‚a tak, jak myÅ›lisz.\n",
    "\n",
    "**ZÅ‚ota Zasada:**\n",
    "1.  UÅ¼ywasz SGD? -> `optim.SGD` (weight_decay dziaÅ‚a ok).\n",
    "2.  UÅ¼ywasz Adama? -> **ZAWSZE uÅ¼ywaj `optim.AdamW`**.\n",
    "3.  ZwykÅ‚y `optim.Adam` uÅ¼ywaj tylko wtedy, gdy `weight_decay=0` (bez regularyzacji)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
