{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e42fe69d",
   "metadata": {},
   "source": [
    "# ğŸ¥‹ Lekcja 26: Dynamic Control Flow (Python wewnÄ…trz sieci)\n",
    "\n",
    "W PyTorch metoda `forward()` to zwykÅ‚y kod Python.\n",
    "MoÅ¼esz uÅ¼ywaÄ‡ `if`, `for`, `while`, a nawet `print()`.\n",
    "\n",
    "**Jak to dziaÅ‚a?**\n",
    "Graf obliczeniowy nie jest budowany raz na zawsze na poczÄ…tku.\n",
    "Jest budowany **od nowa przy kaÅ¼dym przejÅ›ciu `forward`**.\n",
    "\n",
    "*   JeÅ›li w Iteracji 1 wejdziesz do `if`: Graf zawiera gaÅ‚Ä…Åº A.\n",
    "*   JeÅ›li w Iteracji 2 wejdziesz do `else`: Graf zawiera gaÅ‚Ä…Åº B.\n",
    "\n",
    "To pozwala na budowanie **Dynamicznych Sieci Neuronowych**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3317419c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UrzÄ…dzenie: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Konfiguracja\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"UrzÄ…dzenie: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a253871",
   "metadata": {},
   "source": [
    "## Eksperyment 1: Warunek `if` (Data-Dependent Control Flow)\n",
    "\n",
    "Stworzymy sieÄ‡ \"DziwacznÄ…\".\n",
    "*   JeÅ›li suma wejÅ›cia jest dodatnia -> UÅ¼yj warstwy `fc_pos`.\n",
    "*   JeÅ›li suma wejÅ›cia jest ujemna -> UÅ¼yj warstwy `fc_neg`.\n",
    "\n",
    "Silnik Autograd musi poradziÄ‡ sobie z tym, Å¼e w jednej iteracji uÅ¼ywamy jednych wag, a w drugiej innych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6c365d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> ÅšcieÅ¼ka POZYTYWNA\n",
      "Gradient fc_pos: 1.0\n",
      "Gradient fc_neg: None\n",
      "--------------------\n",
      "   -> ÅšcieÅ¼ka NEGATYWNA\n",
      "Gradient fc_pos: None\n",
      "Gradient fc_neg: -1.0\n"
     ]
    }
   ],
   "source": [
    "class WeirdNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc_pos = nn.Linear(10, 1) # Dla liczb dodatnich\n",
    "        self.fc_neg = nn.Linear(10, 1) # Dla liczb ujemnych\n",
    "        \n",
    "        # Inicjalizacja dla rozrÃ³Å¼nienia\n",
    "        nn.init.constant_(self.fc_pos.weight, 1.0)\n",
    "        nn.init.constant_(self.fc_neg.weight, -1.0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # LOGIKA PYTHONOWA W ÅšRODKU SIECI\n",
    "        s = x.sum()\n",
    "        \n",
    "        if s > 0:\n",
    "            print(\"   -> ÅšcieÅ¼ka POZYTYWNA\")\n",
    "            x = self.fc_pos(x)\n",
    "        else:\n",
    "            print(\"   -> ÅšcieÅ¼ka NEGATYWNA\")\n",
    "            x = self.fc_neg(x)\n",
    "            \n",
    "        return x\n",
    "\n",
    "model = WeirdNet().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Test 1: Dane dodatnie\n",
    "input_pos = torch.ones(1, 10).to(DEVICE)\n",
    "out_pos = model(input_pos)\n",
    "out_pos.backward()\n",
    "\n",
    "print(f\"Gradient fc_pos: {model.fc_pos.weight.grad[0,0]}\") # Powinien byÄ‡ (1.0)\n",
    "print(f\"Gradient fc_neg: {model.fc_neg.weight.grad}\")      # Powinien byÄ‡ None (nieuÅ¼ywany)\n",
    "\n",
    "# CzyÅ›cimy\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# Test 2: Dane ujemne\n",
    "print(\"-\" * 20)\n",
    "input_neg = -torch.ones(1, 10).to(DEVICE)\n",
    "out_neg = model(input_neg)\n",
    "out_neg.backward()\n",
    "\n",
    "print(f\"Gradient fc_pos: {model.fc_pos.weight.grad}\")      # Teraz to jest None/0\n",
    "print(f\"Gradient fc_neg: {model.fc_neg.weight.grad[0,0]}\") # Teraz to ma wartoÅ›Ä‡ (-1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55002626",
   "metadata": {},
   "source": [
    "## Eksperyment 2: PÄ™tla `for` (Weight Sharing w czasie)\n",
    "\n",
    "To jest fundament sieci RNN.\n",
    "UÅ¼ywamy **tej samej warstwy** wielokrotnie w pÄ™tli.\n",
    "\n",
    "PyTorch jest na tyle sprytny, Å¼e wie: *\"UÅ¼yÅ‚eÅ› tej warstwy 5 razy. Podczas `backward` muszÄ™ zsumowaÄ‡ gradienty z tych 5 uÅ¼yÄ‡\"*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92ca9659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model z pÄ™tlÄ… dziaÅ‚a.\n",
      "Gradient wagi (istnieje?): True\n"
     ]
    }
   ],
   "source": [
    "class LoopNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(10, 10) # Jedna warstwa\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, steps: int) -> torch.Tensor:\n",
    "        # Dynamiczna pÄ™tla - liczba krokÃ³w zaleÅ¼y od argumentu wywoÅ‚ania!\n",
    "        for i in range(steps):\n",
    "            x = self.fc(x)\n",
    "            # MoÅ¼emy nawet zrobiÄ‡ coÅ› szalonego:\n",
    "            if x.mean() > 100:\n",
    "                print(f\"   (Przerwanie pÄ™tli w kroku {i} - wybuch wartoÅ›ci)\")\n",
    "                break\n",
    "        return x\n",
    "\n",
    "loop_model = LoopNet().to(DEVICE)\n",
    "\n",
    "# Uruchamiamy na 3 kroki\n",
    "x = torch.randn(1, 10).to(DEVICE)\n",
    "out = loop_model(x, steps=3)\n",
    "out.sum().backward()\n",
    "\n",
    "print(\"Model z pÄ™tlÄ… dziaÅ‚a.\")\n",
    "print(f\"Gradient wagi (istnieje?): {loop_model.fc.weight.grad is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064969fc",
   "metadata": {},
   "source": [
    "## PuÅ‚apka: WydajnoÅ›Ä‡ i Eksport\n",
    "\n",
    "Dynamiczne grafy sÄ… super do debugowania i badaÅ„. Ale majÄ… wadÄ™ na produkcji.\n",
    "\n",
    "1.  **Brak optymalizacji:** Kompilator nie wie, co siÄ™ stanie (czy wejdziemy w `if`, ile razy obrÃ³ci siÄ™ `for`). Trudno zÅ‚Ä…czyÄ‡ operacje (Operator Fusion).\n",
    "2.  **Eksport (ONNX):** ONNX woli statyczne grafy. Eksport modelu z `if x.sum() > 0` moÅ¼e byÄ‡ trudny lub niemoÅ¼liwy (trzeba uÅ¼ywaÄ‡ `torch.jit.script` zamiast `trace`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec3a372a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DowÃ³d 1] Skompilowany kod (IR):\n",
      "def forward(self,\n",
      "    x: Tensor) -> Tensor:\n",
      "  s = torch.sum(x)\n",
      "  if bool(torch.gt(s, 0)):\n",
      "    print(CONSTANTS.c0)\n",
      "    fc_pos = self.fc_pos\n",
      "    x0 = (fc_pos).forward(x, )\n",
      "  else:\n",
      "    print(CONSTANTS.c1)\n",
      "    fc_neg = self.fc_neg\n",
      "    x0 = (fc_neg).forward(x, )\n",
      "  return x0\n",
      "\n",
      "[DowÃ³d 2] Uruchomienie na danych ujemnych...\n",
      "   -> ÅšcieÅ¼ka NEGATYWNA\n",
      "Åšrednia wartoÅ›Ä‡ wyniku: 10.278833389282227\n",
      "âœ… SUKCES: Wynik dodatni. Model poprawnie wybraÅ‚ Å›cieÅ¼kÄ™ 'else' (fc_neg).\n"
     ]
    }
   ],
   "source": [
    "# 1. Kompilacja (Scripting)\n",
    "# Analizuje AST (drzewo skÅ‚adniowe) Pythona i kompiluje logikÄ™.\n",
    "scripted_model = torch.jit.script(model)\n",
    "\n",
    "# 2. DowÃ³d 1: Inspekcja Kodu\n",
    "# WyÅ›wietlamy to, jak TorchScript \"zrozumiaÅ‚\" nasz model.\n",
    "# PowinieneÅ› zobaczyÄ‡ instrukcjÄ™: \"if bool(torch.gt(s, 0.)):\"\n",
    "print(\"\\n[DowÃ³d 1] Skompilowany kod (IR):\")\n",
    "print(scripted_model.code)\n",
    "\n",
    "# 3. DowÃ³d 2: Test Numeryczny\n",
    "print(\"[DowÃ³d 2] Uruchomienie na danych ujemnych...\")\n",
    "# WejÅ›cie: same -1.\n",
    "# ÅšcieÅ¼ka Positive (Waga 1.0): -1 * 1 = -1\n",
    "# ÅšcieÅ¼ka Negative (Waga -1.0): -1 * -1 = 1 (Tego oczekujemy)\n",
    "\n",
    "out_jit = scripted_model(input_neg)\n",
    "mean_val = out_jit.mean().item()\n",
    "\n",
    "print(f\"Åšrednia wartoÅ›Ä‡ wyniku: {mean_val}\")\n",
    "\n",
    "if mean_val > 0:\n",
    "    print(\"âœ… SUKCES: Wynik dodatni. Model poprawnie wybraÅ‚ Å›cieÅ¼kÄ™ 'else' (fc_neg).\")\n",
    "else:\n",
    "    print(\"âŒ BÅÄ„D: Wynik ujemny. Model bÅ‚Ä™dnie poszedÅ‚ Å›cieÅ¼kÄ… 'if' (fc_pos).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3e0065",
   "metadata": {},
   "source": [
    "## ğŸ¥‹ Black Belt Summary\n",
    "\n",
    "1.  **Define-by-Run:** PyTorch buduje graf w locie. To pozwala na uÅ¼ywanie natywnego Pythona (`if`, `for`, `print`).\n",
    "2.  **Gradienty:** Autograd automatycznie radzi sobie z warunkowoÅ›ciÄ…. NieuÅ¼ywane gaÅ‚Ä™zie nie dostajÄ… gradientÃ³w. Wielokrotnie uÅ¼ywane warstwy (pÄ™tle) akumulujÄ… gradienty.\n",
    "3.  **Cena:** Dynamiczne grafy sÄ… trudniejsze do zoptymalizowania (`torch.compile`) i wyeksportowania (`ONNX`).\n",
    "    *   JeÅ›li musisz eksportowaÄ‡ logikÄ™ `if`, uÅ¼ywaj **`torch.jit.script`**, a nie `trace`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
