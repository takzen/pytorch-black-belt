{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2428a065",
   "metadata": {},
   "source": [
    "\n",
    "<a href=\"https://colab.research.google.com/github/takzen/pytorch-black-belt/blob/main/38_TensorBoard_Logging.ipynb\" target=\"_parent\">\n",
    "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "setup"
    ]
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# \u2601\ufe0f COLAB SETUP (Automatyczna instalacja \u015brodowiska)\n",
    "# --------------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Sprawdzamy, czy jeste\u015bmy w Google Colab\n",
    "if 'google.colab' in sys.modules:\n",
    "    print('\u2601\ufe0f Wykryto \u015brodowisko Google Colab. Konfiguruj\u0119...')\n",
    "\n",
    "    # 1. Pobieramy plik requirements.txt bezpo\u015brednio z repozytorium\n",
    "    !wget -q https://raw.githubusercontent.com/takzen/ai-engineering-handbook/main/requirements.txt -O requirements.txt\n",
    "\n",
    "    # 2. Instalujemy biblioteki\n",
    "    print('\u23f3 Instaluj\u0119 zale\u017cno\u015bci (to mo\u017ce chwil\u0119 potrwa\u0107)...')\n",
    "    !pip install -q -r requirements.txt\n",
    "\n",
    "    print('\u2705 Gotowe! \u015arodowisko jest zgodne z repozytorium.')\n",
    "else:\n",
    "    print('\ud83d\udcbb Wykryto \u015brodowisko lokalne. Zak\u0142adam, \u017ce masz ju\u017c uv/venv.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca7e775",
   "metadata": {},
   "source": [
    "# \ud83e\udd4b Lekcja 38: TensorBoard & Logging (Oczy In\u017cyniera)\n",
    "\n",
    "Kiedy trenujesz model przez 3 dni, nie chcesz patrze\u0107 na tekstowe logi w konsoli.\n",
    "Chcesz widzie\u0107 wykresy:\n",
    "*   Czy Loss spada?\n",
    "*   Czy Accuracy ro\u015bnie?\n",
    "*   Czy histogramy wag wygl\u0105daj\u0105 zdrowo (Gausowsko)?\n",
    "\n",
    "**TensorBoard** to narz\u0119dzie do wizualizacji, kt\u00f3re dzia\u0142a w przegl\u0105darce.\n",
    "PyTorch Lightning integruje si\u0119 z nim automatycznie. Wystarczy u\u017cy\u0107 metody `self.log()`.\n",
    "\n",
    "W tej lekcji nauczymy si\u0119 logowa\u0107 nie tylko liczby, ale te\u017c **Histogramy Wag** i **Graf Modelu**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e55dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalacja TensorBoard (je\u015bli nie masz)\n",
    "# !uv add tensorboard\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "# Konfiguracja\n",
    "BATCH_SIZE = 64\n",
    "torch.set_float32_matmul_precision('medium') # Fix dla Twojego RTX 4060!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8cbe27",
   "metadata": {},
   "source": [
    "## Rozbudowany Model z Logowaniem\n",
    "\n",
    "Zmodyfikujemy nasz model z poprzedniej lekcji.\n",
    "1.  Dodamy `log_graph=True` w loggerze.\n",
    "2.  U\u017cyjemy `self.logger.experiment.add_histogram`, \u017ceby \u015bledzi\u0107, czy wagi nie wybuchaj\u0105."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a2b175f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gotowy do obserwacji.\n"
     ]
    }
   ],
   "source": [
    "class VisModel(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(10, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        # Zapisujemy przyk\u0142adowe wej\u015bcie, \u017ceby TensorBoard m\u00f3g\u0142 narysowa\u0107 graf\n",
    "        self.example_input_array = torch.randn(1, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        \n",
    "        # 1. Logowanie Skalara (Wykres liniowy)\n",
    "        # on_step=True: Rysuj kropk\u0119 co ka\u017cdy batch (poszarpany wykres)\n",
    "        # on_epoch=True: Rysuj \u015bredni\u0105 co epok\u0119 (g\u0142adki wykres)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # 2. Logowanie Histogramu Wag (Co epok\u0119)\n",
    "        # Dost\u0119p do \"surowego\" obiektu TensorBoard\n",
    "        tensorboard = self.logger.experiment\n",
    "        \n",
    "        for name, params in self.named_parameters():\n",
    "            tensorboard.add_histogram(name, params, self.current_epoch)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Model gotowy do obserwacji.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a946586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params | Mode  | FLOPs | In sizes | Out sizes\n",
      "---------------------------------------------------------------------------\n",
      "0 | net  | Sequential | 4.9 K  | train | 9.6 K | [1, 10]  | [1, 1]   \n",
      "---------------------------------------------------------------------------\n",
      "4.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "9.6 K     Total Flops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\ude80 Start treningu z wizualizacj\u0105...\n",
      "Epoch 4: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 16/16 [00:00<00:00, 244.43it/s, v_num=1, train_loss=0.996]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 16/16 [00:00<00:00, 208.61it/s, v_num=1, train_loss=0.996]\n",
      "\u2705 Koniec. Logi zapisane w folderze: .\\moj_eksperyment\\version_1\n"
     ]
    }
   ],
   "source": [
    "# Dane (Szum)\n",
    "dataset = TensorDataset(torch.randn(1000, 10), torch.randn(1000, 1))\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=0)\n",
    "\n",
    "# Logger\n",
    "logger = TensorBoardLogger(save_dir=\".\", name=\"moj_eksperyment\")\n",
    "\n",
    "# Trener\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=5,\n",
    "    logger=logger,\n",
    "    enable_checkpointing=False,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    # --- POPRAWKA ---\n",
    "    # Loguj co 1 krok (bo mamy malutki dataset i kroki lec\u0105 szybko)\n",
    "    log_every_n_steps=1\n",
    ")\n",
    "\n",
    "print(\"\ud83d\ude80 Start treningu z wizualizacj\u0105...\")\n",
    "trainer.fit(model=VisModel(), train_dataloaders=loader)\n",
    "print(f\"\u2705 Koniec. Logi zapisane w folderze: {logger.log_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a8f1be",
   "metadata": {},
   "source": [
    "## Jak zobaczy\u0107 wyniki?\n",
    "\n",
    "TensorBoard to osobna aplikacja webowa. Aby j\u0105 uruchomi\u0107, masz dwie opcje:\n",
    "\n",
    "**Opcja A: Wewn\u0105trz Notebooka (Magic Command)**\n",
    "```python\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir .\n",
    "```\n",
    "**Opcja B: W terminalu (VS Code)**\n",
    "Otw\u00f3rz terminal w folderze projektu i wpisz:\n",
    "```python\n",
    "tensorboard --logdir .\n",
    "```\n",
    "A potem wejd\u017a w przegl\u0105darce na http://localhost:6006.\n",
    "Tam zobaczysz zak\u0142adki:\n",
    "Scalars: Wykres train_loss.\n",
    "Graphs: Schemat Twojej sieci neuronowej.\n",
    "Histograms: Rozk\u0142ad wag (czy s\u0105 \"zdrowe\", czy np. wszystkie zbieg\u0142y do zera)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8ec4550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 27028), started 0:01:26 ago. (Use '!kill 27028' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7c994e4e1b8502b7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7c994e4e1b8502b7\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pr\u00f3ba uruchomienia w notatniku (mo\u017ce wymaga\u0107 restartu kernela je\u015bli masz extensions issue)\n",
    "# Je\u015bli to nie zadzia\u0142a, u\u017cyj terminala!\n",
    "\n",
    "try:\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir .\n",
    "except Exception as e:\n",
    "    print(f\"Nie uda\u0142o si\u0119 uruchomi\u0107 w notatniku: {e}\")\n",
    "    print(\"Uruchom w terminalu: tensorboard --logdir .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb8adf1",
   "metadata": {},
   "source": [
    "## \ud83e\udd4b Black Belt Summary\n",
    "\n",
    "1.  **Logger:** W Lightning logger jest oddzielony od modelu. Mo\u017cesz zamieni\u0107 `TensorBoardLogger` na `WandbLogger` (Weights & Biases) lub `CSVLogger` jedn\u0105 linijk\u0105.\n",
    "2.  **Artifacts:** Opr\u00f3cz `loss`, warto logowa\u0107 histogramy wag.\n",
    "    *   Je\u015bli histogram \"rozlewa si\u0119\" bardzo szeroko -> Eksploduj\u0105ce gradienty.\n",
    "    *   Je\u015bli histogram kurczy si\u0119 do cienkiej szpilki na zerze -> Znikaj\u0105ce gradienty (albo za du\u017ce L2).\n",
    "3.  **Graf:** Dzi\u0119ki `example_input_array` TensorBoard narysuje Ci architektur\u0119 sieci. To super przydatne przy debugowaniu skomplikowanych modeli."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}