{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc8f0a15",
   "metadata": {},
   "source": [
    "# ü•ã Lekcja 28: Model Surgery (Przeszczepianie Warstw)\n",
    "\n",
    "Bierzemy gotowy model (`pretrained=True`), ale musimy go dostosowaƒá do naszych danych.\n",
    "\n",
    "1.  **Head Replacement (Proste):** Podmieniamy ostatniƒÖ warstwƒô liniowƒÖ (`fc` lub `classifier`), ≈ºeby zmieniƒá liczbƒô klas.\n",
    "2.  **Stem Replacement (Trudne):** Podmieniamy pierwszƒÖ warstwƒô konwolucyjnƒÖ (`conv1`), ≈ºeby zmieniƒá liczbƒô kana≈Ç√≥w wej≈õciowych.\n",
    "\n",
    "**Black Belt Trick:**\n",
    "Je≈õli zmieniamy wej≈õcie z 3 kana≈Ç√≥w (RGB) na 1 kana≈Ç (Grayscale), nie inicjalizujemy nowej warstwy losowo!\n",
    "Bierzemy wagi z oryginalnej warstwy RGB, **u≈õredniamy je** i wk≈Çadamy do nowej warstwy.\n",
    "Dziƒôki temu model od razu \"umie\" wykrywaƒá krawƒôdzie i kszta≈Çty, zamiast uczyƒá siƒô widzenia od nowa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d48ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ORYGINA≈Å ---\n",
      "Wej≈õcie (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "Wyj≈õcie (fc):    Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# 1. Pacjent: ResNet18 (Wytrenowany na ImageNet)\n",
    "# W nowych wersjach torchvision u≈ºywamy weights=...\n",
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "print(\"--- ORYGINA≈Å ---\")\n",
    "print(f\"Wej≈õcie (conv1): {model.conv1}\")\n",
    "print(f\"Wyj≈õcie (fc):    {model.fc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd618a4",
   "metadata": {},
   "source": [
    "## Operacja 1: Wymiana G≈Çowy (Output Layer)\n",
    "\n",
    "To standardowy Fine-Tuning.\n",
    "ResNet18 ma na ko≈Ñcu warstwƒô `Linear(512, 1000)`.\n",
    "My chcemy klasyfikowaƒá np. **2 klasy** (Kot vs Pies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e131457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- PO WYMIANIE G≈ÅOWY ---\n",
      "Linear(in_features=512, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Sprawdzamy ile cech wchodzi do ostatniej warstwy\n",
    "in_features = model.fc.in_features\n",
    "\n",
    "# Podmieniamy warstwƒô (Stara idzie do ≈õmieci, nowa jest losowa)\n",
    "model.fc = nn.Linear(in_features, 2)\n",
    "\n",
    "print(\"--- PO WYMIANIE G≈ÅOWY ---\")\n",
    "print(model.fc)\n",
    "# Teraz model zwraca 2 logity zamiast 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81e1512",
   "metadata": {},
   "source": [
    "## Operacja 2: Wymiana Oczu (Input Layer) + Przeszczep Wag\n",
    "\n",
    "To jest trudniejsze.\n",
    "Mamy zdjƒôcia Rentgenowskie (1 kana≈Ç). ResNet chce 3 kana≈Çy.\n",
    "Je≈õli zrobimy `nn.Conv2d(1, 64, ...)`, nowa warstwa bƒôdzie losowa. Zniszczymy ca≈ÇƒÖ wiedzƒô o wykrywaniu krawƒôdzi, kt√≥rƒÖ ResNet zdoby≈Ç na ImageNet.\n",
    "\n",
    "**Trik:**\n",
    "Wagi w `conv1` majƒÖ kszta≈Çt `[64, 3, 7, 7]` (64 filtry, 3 kana≈Çy, kernel 7x7).\n",
    "Mo≈ºemy zsumowaƒá (lub u≈õredniƒá) te 3 kana≈Çy, ≈ºeby dostaƒá `[64, 1, 7, 7]`.\n",
    "To zadzia≈Ça, bo krawƒôd≈∫ na zdjƒôciu czarno-bia≈Çym wyglƒÖda tak samo jak na kolorowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49c83e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stare wagi: torch.Size([64, 3, 7, 7])\n",
      "Nowe wagi (losowe): torch.Size([64, 1, 7, 7])\n",
      "\n",
      "‚úÖ Przeszczep udany. Wagi z ImageNet zosta≈Çy zachowane (jako Grayscale).\n"
     ]
    }
   ],
   "source": [
    "# 1. Zapisujemy starƒÖ warstwƒô\n",
    "old_conv = model.conv1\n",
    "\n",
    "# 2. Tworzymy nowƒÖ warstwƒô (1 kana≈Ç wej≈õciowy zamiast 3)\n",
    "# Musimy zachowaƒá te same parametry (kernel, stride, padding, bias)\n",
    "new_conv = nn.Conv2d(\n",
    "    in_channels=1, \n",
    "    out_channels=old_conv.out_channels, \n",
    "    kernel_size=old_conv.kernel_size, \n",
    "    stride=old_conv.stride, \n",
    "    padding=old_conv.padding,\n",
    "    bias=old_conv.bias is not None\n",
    ")\n",
    "\n",
    "print(f\"Stare wagi: {old_conv.weight.shape}\")\n",
    "print(f\"Nowe wagi (losowe): {new_conv.weight.shape}\")\n",
    "\n",
    "# 3. PRZESZCZEP WAG (Surgical Transplant)\n",
    "with torch.no_grad():\n",
    "    # Sumujemy wagi po wymiarze kana≈Ç√≥w (dim=1) i dzielimy przez 3 (≈õrednia)\n",
    "    # [64, 3, 7, 7] -> [64, 1, 7, 7]\n",
    "    weight_avg = old_conv.weight.mean(dim=1, keepdim=True)\n",
    "    \n",
    "    # Wstrzykujemy do nowej warstwy\n",
    "    new_conv.weight.copy_(weight_avg)\n",
    "\n",
    "# 4. Podmieniamy warstwƒô w modelu\n",
    "model.conv1 = new_conv\n",
    "\n",
    "print(\"\\n‚úÖ Przeszczep udany. Wagi z ImageNet zosta≈Çy zachowane (jako Grayscale).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cef1ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TEST PRZEP≈ÅYWU ---\n",
      "Wej≈õcie: torch.Size([1, 1, 224, 224])\n",
      "Wyj≈õcie: torch.Size([1, 2]) (Oczekiwane: [1, 2])\n",
      "Pacjent prze≈ºy≈Ç operacjƒô.\n"
     ]
    }
   ],
   "source": [
    "# TEST ≈ªYWY\n",
    "# Generujemy losowy obrazek w skali szaro≈õci (1 kana≈Ç)\n",
    "dummy_xray = torch.randn(1, 1, 224, 224)\n",
    "\n",
    "try:\n",
    "    output = model(dummy_xray)\n",
    "    print(\"\\n--- TEST PRZEP≈ÅYWU ---\")\n",
    "    print(f\"Wej≈õcie: {dummy_xray.shape}\")\n",
    "    print(f\"Wyj≈õcie: {output.shape} (Oczekiwane: [1, 2])\")\n",
    "    print(\"Pacjent prze≈ºy≈Ç operacjƒô.\")\n",
    "except Exception as e:\n",
    "    print(f\"üíÄ B≈ÇƒÖd: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7830536f",
   "metadata": {},
   "source": [
    "## ü•ã Black Belt Summary\n",
    "\n",
    "1.  **Nie trenuj od zera**, je≈õli nie musisz. Nawet je≈õli masz inny rozmiar wej≈õcia, mo≈ºesz zaadaptowaƒá wagi.\n",
    "2.  **Suma wag:** Je≈õli zmieniasz wej≈õcie z 3 kana≈Ç√≥w na 4 (np. RGB + Podczerwie≈Ñ), mo≈ºesz wziƒÖƒá wagi z RGB, a dla 4. kana≈Çu zainicjowaƒá zerami (lub ≈õredniƒÖ). Wtedy model na starcie dzia≈Ça jak zwyk≈Çy ResNet, a z czasem uczy siƒô u≈ºywaƒá podczerwieni.\n",
    "3.  **Model Surgery** to codzienno≈õƒá w pracy z obrazami medycznymi i satelitarnymi."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-black-belt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
